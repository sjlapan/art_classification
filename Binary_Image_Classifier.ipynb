{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras import layers\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"D:/DU_Bootcamp/artwork_styles/binary\"\n",
    "CATEGORIES = [\"paintings\", \"photos\"]\n",
    "# for category in CATEGORIES:\n",
    "#     path = os.path.join(DATADIR, category) \n",
    "#     for img in os.listdir(path):\n",
    "#         img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)\n",
    "#         plt.imshow(img_array, cmap=\"gray\")\n",
    "#         plt.show()\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n",
      "this one worked\n"
     ]
    }
   ],
   "source": [
    "# training_data = []\n",
    "new_data = []\n",
    "counter = 1\n",
    "\n",
    "def create_new_data():\n",
    "    counter = 1\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # path to art categories\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            while len(new_data) < 2000 * counter:\n",
    "                try:\n",
    "                    img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR) #\n",
    "                    new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                    new_data.append([new_array, class_num])\n",
    "                    print(\"this one worked\")\n",
    "                except Exception as e:\n",
    "                    print(\"Something went wrong\")\n",
    "        counter+= 1\n",
    "create_new_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(training_data)\n",
    "random.shuffle(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "# print(len(training_data))\n",
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[[ 83,  84,  81],\n",
       "          [ 92,  90,  89],\n",
       "          [ 86,  84,  83],\n",
       "          ...,\n",
       "          [100,  94,  89],\n",
       "          [ 85,  84,  75],\n",
       "          [ 89,  87,  86]],\n",
       "  \n",
       "         [[ 95,  93,  92],\n",
       "          [ 98,  95,  93],\n",
       "          [100, 100,  98],\n",
       "          ...,\n",
       "          [100,  99,  95],\n",
       "          [ 93,  96,  87],\n",
       "          [ 96,  91,  91]],\n",
       "  \n",
       "         [[ 87,  83,  82],\n",
       "          [ 96,  91,  89],\n",
       "          [108, 107, 106],\n",
       "          ...,\n",
       "          [ 98, 101,  99],\n",
       "          [ 89,  87,  81],\n",
       "          [ 88,  88,  87]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 45,  47,  52],\n",
       "          [ 24,  28,  29],\n",
       "          [ 92,  96, 100],\n",
       "          ...,\n",
       "          [133, 139, 144],\n",
       "          [117, 124, 127],\n",
       "          [ 67,  79,  91]],\n",
       "  \n",
       "         [[ 48,  52,  55],\n",
       "          [ 53,  52,  52],\n",
       "          [112, 118, 116],\n",
       "          ...,\n",
       "          [114, 123, 131],\n",
       "          [108, 113, 124],\n",
       "          [ 26,  40,  52]],\n",
       "  \n",
       "         [[ 56,  59,  63],\n",
       "          [ 91,  96, 103],\n",
       "          [127, 130, 128],\n",
       "          ...,\n",
       "          [ 81,  92, 106],\n",
       "          [ 72,  82,  90],\n",
       "          [ 21,  30,  40]]], dtype=uint8), 0], [array([[[178, 133,  96],\n",
       "          [174, 130,  92],\n",
       "          [167, 123,  83],\n",
       "          ...,\n",
       "          [161, 111,  75],\n",
       "          [160, 110,  78],\n",
       "          [173, 134, 106]],\n",
       "  \n",
       "         [[185, 140, 103],\n",
       "          [163, 117,  82],\n",
       "          [165, 119,  85],\n",
       "          ...,\n",
       "          [163, 107,  72],\n",
       "          [168, 123,  86],\n",
       "          [168, 126, 104]],\n",
       "  \n",
       "         [[168, 122,  88],\n",
       "          [175, 126,  92],\n",
       "          [171, 126,  92],\n",
       "          ...,\n",
       "          [157, 105,  69],\n",
       "          [172, 128,  92],\n",
       "          [157, 120,  93]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[163, 181, 189],\n",
       "          [131, 147, 159],\n",
       "          [156, 155, 167],\n",
       "          ...,\n",
       "          [131, 143, 137],\n",
       "          [118, 123, 111],\n",
       "          [104, 117,  97]],\n",
       "  \n",
       "         [[135, 156, 171],\n",
       "          [100, 134, 147],\n",
       "          [ 88,  97,  98],\n",
       "          ...,\n",
       "          [108, 125, 122],\n",
       "          [127, 151, 138],\n",
       "          [113, 125, 107]],\n",
       "  \n",
       "         [[111, 115, 120],\n",
       "          [118, 121, 133],\n",
       "          [110, 121, 137],\n",
       "          ...,\n",
       "          [110, 125, 114],\n",
       "          [118, 138, 121],\n",
       "          [ 98, 120, 102]]], dtype=uint8), 0], [array([[[ 67,  88,  88],\n",
       "          [ 44,  56,  52],\n",
       "          [137, 125, 110],\n",
       "          ...,\n",
       "          [178, 156, 144],\n",
       "          [177, 158, 143],\n",
       "          [161, 147, 132]],\n",
       "  \n",
       "         [[ 21,  36,  40],\n",
       "          [ 60,  76,  72],\n",
       "          [ 56,  78,  79],\n",
       "          ...,\n",
       "          [195, 172, 157],\n",
       "          [186, 163, 147],\n",
       "          [172, 148, 130]],\n",
       "  \n",
       "         [[ 89, 111, 108],\n",
       "          [ 44,  74,  73],\n",
       "          [ 59,  86,  83],\n",
       "          ...,\n",
       "          [195, 166, 150],\n",
       "          [192, 160, 147],\n",
       "          [184, 171, 166]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 53,  99, 116],\n",
       "          [ 48, 107, 118],\n",
       "          [ 38,  90, 100],\n",
       "          ...,\n",
       "          [ 88, 122, 131],\n",
       "          [ 61, 103, 116],\n",
       "          [ 62, 112, 125]],\n",
       "  \n",
       "         [[ 83, 133, 147],\n",
       "          [ 50, 103, 115],\n",
       "          [ 46, 100, 108],\n",
       "          ...,\n",
       "          [ 62,  95, 104],\n",
       "          [ 45,  83,  96],\n",
       "          [ 63, 111, 125]],\n",
       "  \n",
       "         [[ 65, 106, 115],\n",
       "          [ 37,  88, 104],\n",
       "          [109, 152, 157],\n",
       "          ...,\n",
       "          [100, 134, 144],\n",
       "          [ 85, 124, 132],\n",
       "          [ 64, 111, 126]]], dtype=uint8), 0], [array([[[188, 180, 165],\n",
       "          [187, 177, 159],\n",
       "          [184, 168, 145],\n",
       "          ...,\n",
       "          [161, 144, 124],\n",
       "          [147, 126, 105],\n",
       "          [153, 133, 115]],\n",
       "  \n",
       "         [[185, 177, 158],\n",
       "          [194, 187, 170],\n",
       "          [158, 154, 136],\n",
       "          ...,\n",
       "          [163, 135, 105],\n",
       "          [163, 141, 113],\n",
       "          [167, 142, 118]],\n",
       "  \n",
       "         [[195, 191, 172],\n",
       "          [195, 193, 182],\n",
       "          [200, 181, 166],\n",
       "          ...,\n",
       "          [154, 135, 108],\n",
       "          [150, 121,  90],\n",
       "          [162, 138, 116]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[121, 154, 139],\n",
       "          [123, 161, 149],\n",
       "          [ 71,  83,  55],\n",
       "          ...,\n",
       "          [  3,  20,  56],\n",
       "          [ 97, 125, 152],\n",
       "          [108, 127, 148]],\n",
       "  \n",
       "         [[ 62,  95,  85],\n",
       "          [ 89, 134, 117],\n",
       "          [ 54,  83,  57],\n",
       "          ...,\n",
       "          [ 15,  19,  68],\n",
       "          [116, 126, 166],\n",
       "          [101, 124, 145]],\n",
       "  \n",
       "         [[114, 147, 135],\n",
       "          [ 79,  99,  80],\n",
       "          [ 92, 123, 104],\n",
       "          ...,\n",
       "          [ 73, 106, 127],\n",
       "          [105, 129, 151],\n",
       "          [147, 172, 190]]], dtype=uint8), 0], [array([[[159, 170, 178],\n",
       "          [169, 169, 174],\n",
       "          [167, 168, 172],\n",
       "          ...,\n",
       "          [201, 195, 196],\n",
       "          [189, 189, 189],\n",
       "          [196, 196, 196]],\n",
       "  \n",
       "         [[168, 188, 196],\n",
       "          [171, 177, 184],\n",
       "          [167, 179, 183],\n",
       "          ...,\n",
       "          [186, 188, 188],\n",
       "          [185, 185, 185],\n",
       "          [184, 184, 184]],\n",
       "  \n",
       "         [[166, 190, 202],\n",
       "          [186, 198, 208],\n",
       "          [176, 189, 197],\n",
       "          ...,\n",
       "          [188, 188, 188],\n",
       "          [184, 184, 184],\n",
       "          [190, 190, 190]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 38,  95, 127],\n",
       "          [ 43, 111, 156],\n",
       "          [ 36,  96, 145],\n",
       "          ...,\n",
       "          [ 76,  99, 122],\n",
       "          [103, 154, 181],\n",
       "          [ 33,  99, 127]],\n",
       "  \n",
       "         [[ 56, 109, 146],\n",
       "          [ 17,  80, 118],\n",
       "          [ 48, 110, 148],\n",
       "          ...,\n",
       "          [ 74, 105, 130],\n",
       "          [ 55,  94, 116],\n",
       "          [ 30,  86, 123]],\n",
       "  \n",
       "         [[ 33,  88, 131],\n",
       "          [ 12,  65,  98],\n",
       "          [ 43,  87, 110],\n",
       "          ...,\n",
       "          [ 37,  73,  97],\n",
       "          [ 15,  50,  65],\n",
       "          [ 35,  82, 115]]], dtype=uint8), 0], [array([[[144, 153, 157],\n",
       "          [169, 177, 177],\n",
       "          [149, 153, 154],\n",
       "          ...,\n",
       "          [158, 164, 168],\n",
       "          [147, 155, 162],\n",
       "          [127, 138, 146]],\n",
       "  \n",
       "         [[155, 164, 168],\n",
       "          [158, 162, 164],\n",
       "          [152, 154, 154],\n",
       "          ...,\n",
       "          [162, 165, 170],\n",
       "          [149, 155, 160],\n",
       "          [124, 140, 147]],\n",
       "  \n",
       "         [[171, 177, 181],\n",
       "          [162, 168, 163],\n",
       "          [163, 164, 154],\n",
       "          ...,\n",
       "          [144, 147, 152],\n",
       "          [159, 169, 173],\n",
       "          [152, 165, 173]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[158, 171, 180],\n",
       "          [170, 186, 200],\n",
       "          [150, 175, 190],\n",
       "          ...,\n",
       "          [127, 129, 116],\n",
       "          [126, 134, 128],\n",
       "          [134, 149, 156]],\n",
       "  \n",
       "         [[145, 161, 168],\n",
       "          [149, 154, 157],\n",
       "          [112, 127, 137],\n",
       "          ...,\n",
       "          [139, 140, 124],\n",
       "          [136, 142, 145],\n",
       "          [140, 151, 159]],\n",
       "  \n",
       "         [[154, 169, 173],\n",
       "          [132, 137, 138],\n",
       "          [152, 162, 162],\n",
       "          ...,\n",
       "          [145, 156, 160],\n",
       "          [101, 111, 117],\n",
       "          [140, 161, 179]]], dtype=uint8), 0], [array([[[151, 163, 161],\n",
       "          [145, 142, 134],\n",
       "          [159, 151, 144],\n",
       "          ...,\n",
       "          [134, 146, 146],\n",
       "          [131, 141, 139],\n",
       "          [144, 158, 156]],\n",
       "  \n",
       "         [[158, 160, 156],\n",
       "          [139, 143, 138],\n",
       "          [155, 146, 141],\n",
       "          ...,\n",
       "          [147, 157, 157],\n",
       "          [140, 150, 150],\n",
       "          [142, 156, 154]],\n",
       "  \n",
       "         [[136, 143, 143],\n",
       "          [135, 138, 132],\n",
       "          [155, 142, 134],\n",
       "          ...,\n",
       "          [148, 156, 154],\n",
       "          [136, 149, 152],\n",
       "          [127, 146, 147]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[110, 138, 143],\n",
       "          [103, 128, 122],\n",
       "          [103, 128, 135],\n",
       "          ...,\n",
       "          [ 70, 120, 131],\n",
       "          [ 78, 127, 141],\n",
       "          [ 73, 119, 130]],\n",
       "  \n",
       "         [[103, 131, 125],\n",
       "          [ 90, 122, 132],\n",
       "          [ 89, 118, 125],\n",
       "          ...,\n",
       "          [ 94, 145, 157],\n",
       "          [ 65, 124, 134],\n",
       "          [ 58, 119, 132]],\n",
       "  \n",
       "         [[103, 134, 138],\n",
       "          [ 92, 130, 135],\n",
       "          [ 94, 129, 136],\n",
       "          ...,\n",
       "          [ 83, 129, 142],\n",
       "          [106, 147, 155],\n",
       "          [ 57, 117, 131]]], dtype=uint8), 0], [array([[[141, 144, 123],\n",
       "          [159, 148, 126],\n",
       "          [112, 106,  98],\n",
       "          ...,\n",
       "          [174, 162, 142],\n",
       "          [195, 183, 163],\n",
       "          [162, 157, 136]],\n",
       "  \n",
       "         [[158, 149, 129],\n",
       "          [162, 155, 132],\n",
       "          [141, 135, 127],\n",
       "          ...,\n",
       "          [193, 186, 166],\n",
       "          [199, 192, 172],\n",
       "          [173, 168, 147]],\n",
       "  \n",
       "         [[161, 147, 125],\n",
       "          [165, 145, 123],\n",
       "          [149, 143, 128],\n",
       "          ...,\n",
       "          [201, 204, 189],\n",
       "          [181, 184, 169],\n",
       "          [168, 161, 146]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[146, 174, 185],\n",
       "          [114, 140, 157],\n",
       "          [151, 176, 192],\n",
       "          ...,\n",
       "          [156, 176, 181],\n",
       "          [136, 156, 161],\n",
       "          [113, 127, 133]],\n",
       "  \n",
       "         [[129, 160, 175],\n",
       "          [122, 141, 156],\n",
       "          [151, 181, 192],\n",
       "          ...,\n",
       "          [120, 147, 151],\n",
       "          [104, 131, 135],\n",
       "          [123, 138, 137]],\n",
       "  \n",
       "         [[147, 171, 175],\n",
       "          [134, 156, 161],\n",
       "          [129, 148, 155],\n",
       "          ...,\n",
       "          [128, 148, 153],\n",
       "          [128, 148, 153],\n",
       "          [112, 125, 131]]], dtype=uint8), 0], [array([[[ 78,  94,  86],\n",
       "          [ 73,  91,  83],\n",
       "          [105, 115, 104],\n",
       "          ...,\n",
       "          [132, 183, 180],\n",
       "          [156, 200, 199],\n",
       "          [160, 201, 207]],\n",
       "  \n",
       "         [[ 84, 103,  88],\n",
       "          [ 96, 112, 105],\n",
       "          [114, 128, 116],\n",
       "          ...,\n",
       "          [167, 216, 204],\n",
       "          [168, 211, 208],\n",
       "          [139, 197, 198]],\n",
       "  \n",
       "         [[ 96, 111, 112],\n",
       "          [101, 113, 105],\n",
       "          [ 95, 114,  99],\n",
       "          ...,\n",
       "          [190, 232, 221],\n",
       "          [184, 228, 219],\n",
       "          [174, 220, 220]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[  6,   3,   3],\n",
       "          [ 13,  18,   7],\n",
       "          [  8,   8,   5],\n",
       "          ...,\n",
       "          [ 76, 145, 173],\n",
       "          [ 99, 163, 178],\n",
       "          [ 78, 146, 183]],\n",
       "  \n",
       "         [[  6,   7,   5],\n",
       "          [  9,   4,   1],\n",
       "          [  8,   5,   0],\n",
       "          ...,\n",
       "          [ 91, 158, 182],\n",
       "          [103, 173, 202],\n",
       "          [ 61, 126, 164]],\n",
       "  \n",
       "         [[  8,   4,   4],\n",
       "          [  8,   3,   4],\n",
       "          [ 12,   4,   4],\n",
       "          ...,\n",
       "          [ 76, 136, 177],\n",
       "          [ 56, 132, 166],\n",
       "          [ 42, 117, 155]]], dtype=uint8), 0], [array([[[ 57, 102,  85],\n",
       "          [ 60, 104,  94],\n",
       "          [ 33,  69,  56],\n",
       "          ...,\n",
       "          [199, 216, 204],\n",
       "          [207, 223, 219],\n",
       "          [166, 194, 199]],\n",
       "  \n",
       "         [[ 42, 107,  92],\n",
       "          [ 53, 106,  93],\n",
       "          [ 88, 137, 131],\n",
       "          ...,\n",
       "          [223, 234, 225],\n",
       "          [199, 214, 193],\n",
       "          [191, 210, 198]],\n",
       "  \n",
       "         [[ 35,  91,  80],\n",
       "          [ 60, 116,  94],\n",
       "          [ 76, 129, 122],\n",
       "          ...,\n",
       "          [225, 232, 217],\n",
       "          [215, 222, 206],\n",
       "          [214, 231, 221]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 90, 101,  62],\n",
       "          [118, 132,  53],\n",
       "          [169, 180, 151],\n",
       "          ...,\n",
       "          [206, 167, 123],\n",
       "          [218, 193, 147],\n",
       "          [215, 197, 156]],\n",
       "  \n",
       "         [[ 92, 114,  65],\n",
       "          [ 73, 108,  71],\n",
       "          [142, 160, 151],\n",
       "          ...,\n",
       "          [220, 200, 145],\n",
       "          [212, 186, 132],\n",
       "          [206, 171, 127]],\n",
       "  \n",
       "         [[ 93, 119,  66],\n",
       "          [108, 130,  98],\n",
       "          [ 73, 104,  93],\n",
       "          ...,\n",
       "          [193, 163, 110],\n",
       "          [204, 165, 121],\n",
       "          [186, 168, 127]]], dtype=uint8), 0]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = training_data[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for features, label in new_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "# for features, label in training_data:\n",
    "#     X.append(features)\n",
    "#     y.append(label)\n",
    "\n",
    "# for features, label in data_subset:\n",
    "#     X.append(features)\n",
    "#     y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(y).keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([2000, 2000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, img_size, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 120, 120, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e39a7eb0f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainX[1455,:,:], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make labels categorical\n",
    "num_classes = 2\n",
    "trainY = to_categorical(trainY, num_classes)\n",
    "testY = to_categorical(testY, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = img_size, img_size\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Stewart\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Stewart\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "cnn1 = Sequential()\n",
    "cnn1.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "cnn1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn1.add(Dropout(0.2))\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dense(128, activation=\"relu\"))\n",
    "cnn1.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "cnn1.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Stewart\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - ETA: 2:06 - loss: 9.2817 - acc: 0.375 - ETA: 1:17 - loss: 8.1667 - acc: 0.468 - ETA: 1:01 - loss: 8.2987 - acc: 0.468 - ETA: 52s - loss: 7.9869 - acc: 0.492 - ETA: 47s - loss: 7.3969 - acc: 0.53 - ETA: 44s - loss: 7.6752 - acc: 0.51 - ETA: 41s - loss: 8.0898 - acc: 0.49 - ETA: 39s - loss: 8.0230 - acc: 0.49 - ETA: 37s - loss: 7.9151 - acc: 0.50 - ETA: 36s - loss: 8.1309 - acc: 0.49 - ETA: 34s - loss: 8.0786 - acc: 0.49 - ETA: 33s - loss: 7.9930 - acc: 0.50 - ETA: 33s - loss: 7.9981 - acc: 0.50 - ETA: 32s - loss: 8.0744 - acc: 0.49 - ETA: 31s - loss: 8.1741 - acc: 0.48 - ETA: 30s - loss: 8.0725 - acc: 0.49 - ETA: 30s - loss: 8.0421 - acc: 0.49 - ETA: 29s - loss: 8.0150 - acc: 0.50 - ETA: 28s - loss: 8.2029 - acc: 0.48 - ETA: 28s - loss: 8.1705 - acc: 0.49 - ETA: 27s - loss: 8.1892 - acc: 0.48 - ETA: 27s - loss: 8.2978 - acc: 0.48 - ETA: 26s - loss: 8.3093 - acc: 0.48 - ETA: 26s - loss: 8.4038 - acc: 0.47 - ETA: 25s - loss: 8.3497 - acc: 0.48 - ETA: 25s - loss: 8.3385 - acc: 0.48 - ETA: 24s - loss: 8.3655 - acc: 0.47 - ETA: 24s - loss: 8.3725 - acc: 0.47 - ETA: 23s - loss: 8.3791 - acc: 0.47 - ETA: 23s - loss: 8.3852 - acc: 0.47 - ETA: 23s - loss: 8.3422 - acc: 0.48 - ETA: 22s - loss: 8.2704 - acc: 0.48 - ETA: 22s - loss: 8.2945 - acc: 0.48 - ETA: 21s - loss: 8.2728 - acc: 0.48 - ETA: 21s - loss: 8.2811 - acc: 0.48 - ETA: 21s - loss: 8.2469 - acc: 0.48 - ETA: 20s - loss: 8.1874 - acc: 0.49 - ETA: 20s - loss: 8.2105 - acc: 0.48 - ETA: 19s - loss: 8.1808 - acc: 0.49 - ETA: 19s - loss: 8.1148 - acc: 0.49 - ETA: 18s - loss: 8.1380 - acc: 0.49 - ETA: 18s - loss: 8.1002 - acc: 0.49 - ETA: 18s - loss: 8.1226 - acc: 0.49 - ETA: 17s - loss: 8.1326 - acc: 0.49 - ETA: 17s - loss: 8.1646 - acc: 0.49 - ETA: 16s - loss: 8.1732 - acc: 0.49 - ETA: 16s - loss: 8.2351 - acc: 0.48 - ETA: 16s - loss: 8.1999 - acc: 0.49 - ETA: 15s - loss: 8.2074 - acc: 0.48 - ETA: 15s - loss: 8.1742 - acc: 0.49 - ETA: 15s - loss: 8.1719 - acc: 0.49 - ETA: 14s - loss: 8.1310 - acc: 0.49 - ETA: 14s - loss: 8.1011 - acc: 0.49 - ETA: 14s - loss: 8.0817 - acc: 0.49 - ETA: 13s - loss: 8.0538 - acc: 0.49 - ETA: 13s - loss: 8.0179 - acc: 0.50 - ETA: 12s - loss: 8.0540 - acc: 0.49 - ETA: 12s - loss: 8.0801 - acc: 0.49 - ETA: 12s - loss: 8.1054 - acc: 0.49 - ETA: 11s - loss: 8.1214 - acc: 0.49 - ETA: 11s - loss: 8.1451 - acc: 0.49 - ETA: 11s - loss: 8.1356 - acc: 0.49 - ETA: 10s - loss: 8.1424 - acc: 0.49 - ETA: 10s - loss: 8.1569 - acc: 0.49 - ETA: 10s - loss: 8.1708 - acc: 0.49 - ETA: 9s - loss: 8.1844 - acc: 0.4915 - ETA: 9s - loss: 8.2126 - acc: 0.489 - ETA: 8s - loss: 8.2178 - acc: 0.489 - ETA: 8s - loss: 8.2228 - acc: 0.489 - ETA: 8s - loss: 8.2420 - acc: 0.487 - ETA: 7s - loss: 8.2323 - acc: 0.488 - ETA: 7s - loss: 8.1880 - acc: 0.491 - ETA: 7s - loss: 8.2069 - acc: 0.490 - ETA: 6s - loss: 8.2049 - acc: 0.490 - ETA: 6s - loss: 8.2298 - acc: 0.488 - ETA: 6s - loss: 8.2607 - acc: 0.486 - ETA: 5s - loss: 8.2450 - acc: 0.487 - ETA: 5s - loss: 8.2232 - acc: 0.489 - ETA: 5s - loss: 8.2339 - acc: 0.488 - ETA: 4s - loss: 8.2317 - acc: 0.488 - ETA: 4s - loss: 8.2109 - acc: 0.490 - ETA: 4s - loss: 8.2152 - acc: 0.489 - ETA: 3s - loss: 8.2376 - acc: 0.488 - ETA: 3s - loss: 8.2175 - acc: 0.489 - ETA: 3s - loss: 8.1682 - acc: 0.492 - ETA: 2s - loss: 8.1611 - acc: 0.493 - ETA: 2s - loss: 8.1715 - acc: 0.492 - ETA: 1s - loss: 8.1473 - acc: 0.494 - ETA: 1s - loss: 8.1633 - acc: 0.493 - ETA: 1s - loss: 8.1398 - acc: 0.494 - ETA: 0s - loss: 8.1500 - acc: 0.493 - ETA: 0s - loss: 8.1435 - acc: 0.494 - ETA: 0s - loss: 8.1426 - acc: 0.494 - 34s 11ms/step - loss: 8.1527 - acc: 0.4937 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - ETA: 31s - loss: 7.0517 - acc: 0.56 - ETA: 30s - loss: 7.5554 - acc: 0.53 - ETA: 30s - loss: 8.2269 - acc: 0.48 - ETA: 29s - loss: 8.0590 - acc: 0.50 - ETA: 29s - loss: 8.8650 - acc: 0.45 - ETA: 29s - loss: 8.6467 - acc: 0.46 - ETA: 28s - loss: 8.5627 - acc: 0.46 - ETA: 28s - loss: 8.6887 - acc: 0.46 - ETA: 28s - loss: 8.7306 - acc: 0.45 - ETA: 27s - loss: 8.4116 - acc: 0.47 - ETA: 27s - loss: 8.4254 - acc: 0.47 - ETA: 27s - loss: 8.3109 - acc: 0.48 - ETA: 26s - loss: 8.3690 - acc: 0.48 - ETA: 26s - loss: 8.3109 - acc: 0.48 - ETA: 26s - loss: 8.3613 - acc: 0.48 - ETA: 26s - loss: 8.2794 - acc: 0.48 - ETA: 25s - loss: 8.2072 - acc: 0.49 - ETA: 25s - loss: 8.1150 - acc: 0.49 - ETA: 25s - loss: 8.1651 - acc: 0.49 - ETA: 24s - loss: 8.1850 - acc: 0.49 - ETA: 24s - loss: 8.1790 - acc: 0.49 - ETA: 24s - loss: 8.2193 - acc: 0.49 - ETA: 23s - loss: 8.2999 - acc: 0.48 - ETA: 23s - loss: 8.3739 - acc: 0.48 - ETA: 23s - loss: 8.3411 - acc: 0.48 - ETA: 22s - loss: 8.3884 - acc: 0.47 - ETA: 22s - loss: 8.3016 - acc: 0.48 - ETA: 22s - loss: 8.2569 - acc: 0.48 - ETA: 21s - loss: 8.2327 - acc: 0.48 - ETA: 21s - loss: 8.1598 - acc: 0.49 - ETA: 21s - loss: 8.1240 - acc: 0.49 - ETA: 20s - loss: 8.1063 - acc: 0.49 - ETA: 20s - loss: 8.1812 - acc: 0.49 - ETA: 20s - loss: 8.1479 - acc: 0.49 - ETA: 19s - loss: 8.1598 - acc: 0.49 - ETA: 19s - loss: 8.1290 - acc: 0.49 - ETA: 19s - loss: 8.1135 - acc: 0.49 - ETA: 18s - loss: 8.0723 - acc: 0.49 - ETA: 18s - loss: 8.0203 - acc: 0.50 - ETA: 18s - loss: 8.0213 - acc: 0.50 - ETA: 17s - loss: 7.9853 - acc: 0.50 - ETA: 17s - loss: 7.9631 - acc: 0.50 - ETA: 17s - loss: 7.9653 - acc: 0.50 - ETA: 16s - loss: 7.9904 - acc: 0.50 - ETA: 16s - loss: 8.0255 - acc: 0.50 - ETA: 16s - loss: 8.0262 - acc: 0.50 - ETA: 15s - loss: 8.0376 - acc: 0.50 - ETA: 15s - loss: 8.0066 - acc: 0.50 - ETA: 15s - loss: 7.9974 - acc: 0.50 - ETA: 14s - loss: 7.9785 - acc: 0.50 - ETA: 14s - loss: 8.0195 - acc: 0.50 - ETA: 14s - loss: 8.0397 - acc: 0.50 - ETA: 13s - loss: 8.0971 - acc: 0.49 - ETA: 13s - loss: 8.1337 - acc: 0.49 - ETA: 13s - loss: 8.1506 - acc: 0.49 - ETA: 12s - loss: 8.1850 - acc: 0.49 - ETA: 12s - loss: 8.1651 - acc: 0.49 - ETA: 11s - loss: 8.1893 - acc: 0.49 - ETA: 11s - loss: 8.1700 - acc: 0.49 - ETA: 11s - loss: 8.1346 - acc: 0.49 - ETA: 10s - loss: 8.1416 - acc: 0.49 - ETA: 10s - loss: 8.1809 - acc: 0.49 - ETA: 10s - loss: 8.1630 - acc: 0.49 - ETA: 9s - loss: 8.1614 - acc: 0.4937 - ETA: 9s - loss: 8.1365 - acc: 0.495 - ETA: 9s - loss: 8.1506 - acc: 0.494 - ETA: 8s - loss: 8.1718 - acc: 0.493 - ETA: 8s - loss: 8.1627 - acc: 0.493 - ETA: 8s - loss: 8.1393 - acc: 0.495 - ETA: 7s - loss: 8.1382 - acc: 0.495 - ETA: 7s - loss: 8.1371 - acc: 0.495 - ETA: 7s - loss: 8.1500 - acc: 0.494 - ETA: 6s - loss: 8.1418 - acc: 0.494 - ETA: 6s - loss: 8.1203 - acc: 0.496 - ETA: 6s - loss: 8.1061 - acc: 0.497 - ETA: 5s - loss: 8.1320 - acc: 0.495 - ETA: 5s - loss: 8.1310 - acc: 0.495 - ETA: 5s - loss: 8.1301 - acc: 0.495 - ETA: 4s - loss: 8.1292 - acc: 0.495 - ETA: 4s - loss: 8.1409 - acc: 0.494 - ETA: 4s - loss: 8.1523 - acc: 0.494 - ETA: 3s - loss: 8.1635 - acc: 0.493 - ETA: 3s - loss: 8.1561 - acc: 0.494 - ETA: 3s - loss: 8.1430 - acc: 0.494 - ETA: 2s - loss: 8.1302 - acc: 0.495 - ETA: 2s - loss: 8.1293 - acc: 0.495 - ETA: 2s - loss: 8.1343 - acc: 0.495 - ETA: 1s - loss: 8.1220 - acc: 0.496 - ETA: 1s - loss: 8.1213 - acc: 0.496 - ETA: 1s - loss: 8.1374 - acc: 0.495 - ETA: 0s - loss: 8.1310 - acc: 0.495 - ETA: 0s - loss: 8.1466 - acc: 0.494 - ETA: 0s - loss: 8.1403 - acc: 0.495 - 33s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 32s - loss: 4.0295 - acc: 0.75 - ETA: 31s - loss: 6.2961 - acc: 0.60 - ETA: 31s - loss: 7.3875 - acc: 0.54 - ETA: 30s - loss: 7.1776 - acc: 0.55 - ETA: 29s - loss: 7.5554 - acc: 0.53 - ETA: 29s - loss: 7.8072 - acc: 0.51 - ETA: 29s - loss: 7.5554 - acc: 0.53 - ETA: 28s - loss: 7.4294 - acc: 0.53 - ETA: 28s - loss: 7.6113 - acc: 0.52 - ETA: 27s - loss: 7.5050 - acc: 0.53 - ETA: 27s - loss: 7.6927 - acc: 0.52 - ETA: 27s - loss: 7.8072 - acc: 0.51 - ETA: 26s - loss: 7.9428 - acc: 0.50 - ETA: 26s - loss: 8.0590 - acc: 0.50 - ETA: 26s - loss: 8.1262 - acc: 0.49 - ETA: 25s - loss: 8.2165 - acc: 0.49 - ETA: 25s - loss: 8.2664 - acc: 0.48 - ETA: 25s - loss: 8.3109 - acc: 0.48 - ETA: 24s - loss: 8.1916 - acc: 0.49 - ETA: 24s - loss: 8.2605 - acc: 0.48 - ETA: 24s - loss: 8.2989 - acc: 0.48 - ETA: 23s - loss: 8.3796 - acc: 0.48 - ETA: 23s - loss: 8.4094 - acc: 0.47 - ETA: 23s - loss: 8.2899 - acc: 0.48 - ETA: 22s - loss: 8.3210 - acc: 0.48 - ETA: 22s - loss: 8.3496 - acc: 0.48 - ETA: 22s - loss: 8.3016 - acc: 0.48 - ETA: 21s - loss: 8.2929 - acc: 0.48 - ETA: 21s - loss: 8.2154 - acc: 0.49 - ETA: 21s - loss: 8.1598 - acc: 0.49 - ETA: 20s - loss: 8.1403 - acc: 0.49 - ETA: 20s - loss: 8.1692 - acc: 0.49 - ETA: 20s - loss: 8.1506 - acc: 0.49 - ETA: 19s - loss: 8.0739 - acc: 0.49 - ETA: 19s - loss: 8.0447 - acc: 0.50 - ETA: 19s - loss: 8.0451 - acc: 0.50 - ETA: 18s - loss: 8.0727 - acc: 0.49 - ETA: 18s - loss: 8.0590 - acc: 0.50 - ETA: 18s - loss: 8.0720 - acc: 0.49 - ETA: 17s - loss: 8.0968 - acc: 0.49 - ETA: 17s - loss: 8.1205 - acc: 0.49 - ETA: 17s - loss: 8.1430 - acc: 0.49 - ETA: 16s - loss: 8.1059 - acc: 0.49 - ETA: 16s - loss: 8.1048 - acc: 0.49 - ETA: 16s - loss: 8.1150 - acc: 0.49 - ETA: 15s - loss: 8.1247 - acc: 0.49 - ETA: 15s - loss: 8.0376 - acc: 0.50 - ETA: 15s - loss: 8.0381 - acc: 0.50 - ETA: 14s - loss: 7.9768 - acc: 0.50 - ETA: 14s - loss: 7.9583 - acc: 0.50 - ETA: 14s - loss: 7.9208 - acc: 0.50 - ETA: 13s - loss: 7.9234 - acc: 0.50 - ETA: 13s - loss: 7.8975 - acc: 0.51 - ETA: 13s - loss: 7.8538 - acc: 0.51 - ETA: 12s - loss: 7.8209 - acc: 0.51 - ETA: 12s - loss: 7.8072 - acc: 0.51 - ETA: 12s - loss: 7.7939 - acc: 0.51 - ETA: 11s - loss: 7.7898 - acc: 0.51 - ETA: 11s - loss: 7.8029 - acc: 0.51 - ETA: 11s - loss: 7.8408 - acc: 0.51 - ETA: 10s - loss: 7.8444 - acc: 0.51 - ETA: 10s - loss: 7.8884 - acc: 0.51 - ETA: 10s - loss: 7.9071 - acc: 0.50 - ETA: 9s - loss: 7.8859 - acc: 0.5107 - ETA: 9s - loss: 7.9041 - acc: 0.509 - ETA: 9s - loss: 7.9369 - acc: 0.507 - ETA: 8s - loss: 7.9688 - acc: 0.505 - ETA: 8s - loss: 7.9628 - acc: 0.506 - ETA: 8s - loss: 7.9714 - acc: 0.505 - ETA: 7s - loss: 8.0087 - acc: 0.503 - ETA: 7s - loss: 8.0094 - acc: 0.503 - ETA: 7s - loss: 8.0311 - acc: 0.501 - ETA: 6s - loss: 8.0107 - acc: 0.503 - ETA: 6s - loss: 8.0454 - acc: 0.500 - ETA: 6s - loss: 8.0523 - acc: 0.500 - ETA: 5s - loss: 8.0590 - acc: 0.500 - ETA: 5s - loss: 8.0983 - acc: 0.497 - ETA: 5s - loss: 8.1043 - acc: 0.497 - ETA: 4s - loss: 8.1292 - acc: 0.495 - ETA: 4s - loss: 8.1535 - acc: 0.494 - ETA: 4s - loss: 8.1461 - acc: 0.494 - ETA: 3s - loss: 8.1328 - acc: 0.495 - ETA: 3s - loss: 8.1258 - acc: 0.495 - ETA: 3s - loss: 8.1190 - acc: 0.496 - ETA: 2s - loss: 8.1420 - acc: 0.494 - ETA: 2s - loss: 8.1469 - acc: 0.494 - ETA: 2s - loss: 8.1343 - acc: 0.495 - ETA: 1s - loss: 8.1564 - acc: 0.494 - ETA: 1s - loss: 8.1326 - acc: 0.495 - ETA: 1s - loss: 8.1318 - acc: 0.495 - ETA: 0s - loss: 8.1531 - acc: 0.494 - ETA: 0s - loss: 8.1466 - acc: 0.494 - ETA: 0s - loss: 8.1295 - acc: 0.495 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - ETA: 32s - loss: 8.5627 - acc: 0.46 - ETA: 30s - loss: 8.0590 - acc: 0.50 - ETA: 30s - loss: 8.2269 - acc: 0.48 - ETA: 29s - loss: 8.5627 - acc: 0.46 - ETA: 29s - loss: 8.0590 - acc: 0.50 - ETA: 28s - loss: 8.1430 - acc: 0.49 - ETA: 28s - loss: 8.2030 - acc: 0.49 - ETA: 28s - loss: 8.2479 - acc: 0.48 - ETA: 27s - loss: 8.1150 - acc: 0.49 - ETA: 27s - loss: 8.1094 - acc: 0.49 - ETA: 27s - loss: 8.1048 - acc: 0.49 - ETA: 26s - loss: 7.8912 - acc: 0.51 - ETA: 26s - loss: 8.0590 - acc: 0.50 - ETA: 26s - loss: 7.9151 - acc: 0.50 - ETA: 25s - loss: 7.8576 - acc: 0.51 - ETA: 25s - loss: 7.7757 - acc: 0.51 - ETA: 25s - loss: 7.7035 - acc: 0.52 - ETA: 24s - loss: 7.7512 - acc: 0.51 - ETA: 24s - loss: 7.7409 - acc: 0.51 - ETA: 24s - loss: 7.7820 - acc: 0.51 - ETA: 23s - loss: 7.7952 - acc: 0.51 - ETA: 23s - loss: 7.7614 - acc: 0.51 - ETA: 23s - loss: 7.7744 - acc: 0.51 - ETA: 22s - loss: 7.7862 - acc: 0.51 - ETA: 22s - loss: 7.8173 - acc: 0.51 - ETA: 22s - loss: 7.8459 - acc: 0.51 - ETA: 21s - loss: 7.9285 - acc: 0.50 - ETA: 21s - loss: 8.0590 - acc: 0.50 - ETA: 21s - loss: 8.1459 - acc: 0.49 - ETA: 20s - loss: 8.1430 - acc: 0.49 - ETA: 20s - loss: 8.1890 - acc: 0.49 - ETA: 20s - loss: 8.2479 - acc: 0.48 - ETA: 19s - loss: 8.2422 - acc: 0.48 - ETA: 19s - loss: 8.1776 - acc: 0.49 - ETA: 19s - loss: 8.1742 - acc: 0.49 - ETA: 18s - loss: 8.1710 - acc: 0.49 - ETA: 18s - loss: 8.1680 - acc: 0.49 - ETA: 18s - loss: 8.1783 - acc: 0.49 - ETA: 17s - loss: 8.2140 - acc: 0.49 - ETA: 17s - loss: 8.1976 - acc: 0.49 - ETA: 17s - loss: 8.2188 - acc: 0.49 - ETA: 16s - loss: 8.1670 - acc: 0.49 - ETA: 16s - loss: 8.1645 - acc: 0.49 - ETA: 16s - loss: 8.1621 - acc: 0.49 - ETA: 15s - loss: 8.2046 - acc: 0.49 - ETA: 15s - loss: 8.1466 - acc: 0.49 - ETA: 15s - loss: 8.1876 - acc: 0.49 - ETA: 14s - loss: 8.1955 - acc: 0.49 - ETA: 14s - loss: 8.1413 - acc: 0.49 - ETA: 14s - loss: 8.1396 - acc: 0.49 - ETA: 13s - loss: 8.1282 - acc: 0.49 - ETA: 13s - loss: 8.1462 - acc: 0.49 - ETA: 13s - loss: 8.0971 - acc: 0.49 - ETA: 12s - loss: 8.1150 - acc: 0.49 - ETA: 12s - loss: 8.0865 - acc: 0.49 - ETA: 12s - loss: 8.0411 - acc: 0.50 - ETA: 11s - loss: 8.0502 - acc: 0.50 - ETA: 11s - loss: 8.0330 - acc: 0.50 - ETA: 11s - loss: 8.0590 - acc: 0.50 - ETA: 11s - loss: 8.0590 - acc: 0.50 - ETA: 10s - loss: 8.1086 - acc: 0.49 - ETA: 10s - loss: 8.1565 - acc: 0.49 - ETA: 10s - loss: 8.1470 - acc: 0.49 - ETA: 9s - loss: 8.1614 - acc: 0.4937 - ETA: 9s - loss: 8.1520 - acc: 0.494 - ETA: 9s - loss: 8.1201 - acc: 0.496 - ETA: 8s - loss: 8.1417 - acc: 0.494 - ETA: 8s - loss: 8.1183 - acc: 0.496 - ETA: 8s - loss: 8.1101 - acc: 0.496 - ETA: 7s - loss: 8.1382 - acc: 0.495 - ETA: 7s - loss: 8.1371 - acc: 0.495 - ETA: 7s - loss: 8.1570 - acc: 0.493 - ETA: 6s - loss: 8.1832 - acc: 0.492 - ETA: 6s - loss: 8.1475 - acc: 0.494 - ETA: 6s - loss: 8.1531 - acc: 0.494 - ETA: 5s - loss: 8.1783 - acc: 0.492 - ETA: 5s - loss: 8.2160 - acc: 0.490 - ETA: 5s - loss: 8.2269 - acc: 0.489 - ETA: 4s - loss: 8.2121 - acc: 0.490 - ETA: 4s - loss: 8.2039 - acc: 0.491 - ETA: 4s - loss: 8.2021 - acc: 0.491 - ETA: 3s - loss: 8.1942 - acc: 0.491 - ETA: 3s - loss: 8.1744 - acc: 0.492 - ETA: 3s - loss: 8.1610 - acc: 0.493 - ETA: 2s - loss: 8.1657 - acc: 0.493 - ETA: 2s - loss: 8.1528 - acc: 0.494 - ETA: 2s - loss: 8.1575 - acc: 0.493 - ETA: 1s - loss: 8.1564 - acc: 0.494 - ETA: 1s - loss: 8.1722 - acc: 0.493 - ETA: 1s - loss: 8.1766 - acc: 0.492 - ETA: 0s - loss: 8.1531 - acc: 0.494 - ETA: 0s - loss: 8.1576 - acc: 0.493 - ETA: 0s - loss: 8.1511 - acc: 0.494 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 30s - loss: 8.5627 - acc: 0.46 - ETA: 30s - loss: 7.8072 - acc: 0.51 - ETA: 29s - loss: 7.3875 - acc: 0.54 - ETA: 29s - loss: 7.8072 - acc: 0.51 - ETA: 28s - loss: 7.8576 - acc: 0.51 - ETA: 28s - loss: 7.9751 - acc: 0.50 - ETA: 28s - loss: 8.2030 - acc: 0.49 - ETA: 27s - loss: 7.9331 - acc: 0.50 - ETA: 27s - loss: 8.2269 - acc: 0.48 - ETA: 27s - loss: 8.2605 - acc: 0.48 - ETA: 27s - loss: 8.2422 - acc: 0.48 - ETA: 26s - loss: 8.3948 - acc: 0.47 - ETA: 26s - loss: 8.2915 - acc: 0.48 - ETA: 26s - loss: 8.2030 - acc: 0.49 - ETA: 25s - loss: 8.0590 - acc: 0.50 - ETA: 25s - loss: 8.2165 - acc: 0.49 - ETA: 25s - loss: 8.2368 - acc: 0.48 - ETA: 24s - loss: 8.0870 - acc: 0.49 - ETA: 24s - loss: 8.1651 - acc: 0.49 - ETA: 24s - loss: 8.1850 - acc: 0.49 - ETA: 23s - loss: 8.1550 - acc: 0.49 - ETA: 23s - loss: 8.2651 - acc: 0.48 - ETA: 23s - loss: 8.2999 - acc: 0.48 - ETA: 22s - loss: 8.2899 - acc: 0.48 - ETA: 22s - loss: 8.2404 - acc: 0.48 - ETA: 22s - loss: 8.1947 - acc: 0.49 - ETA: 21s - loss: 8.2643 - acc: 0.48 - ETA: 21s - loss: 8.2569 - acc: 0.48 - ETA: 21s - loss: 8.3196 - acc: 0.48 - ETA: 20s - loss: 8.1934 - acc: 0.49 - ETA: 20s - loss: 8.1565 - acc: 0.49 - ETA: 20s - loss: 8.1535 - acc: 0.49 - ETA: 19s - loss: 8.1354 - acc: 0.49 - ETA: 19s - loss: 8.1331 - acc: 0.49 - ETA: 19s - loss: 8.1454 - acc: 0.49 - ETA: 18s - loss: 8.1570 - acc: 0.49 - ETA: 18s - loss: 8.1407 - acc: 0.49 - ETA: 18s - loss: 8.1783 - acc: 0.49 - ETA: 17s - loss: 8.1753 - acc: 0.49 - ETA: 17s - loss: 8.1850 - acc: 0.49 - ETA: 17s - loss: 8.2065 - acc: 0.49 - ETA: 16s - loss: 8.2030 - acc: 0.49 - ETA: 16s - loss: 8.1996 - acc: 0.49 - ETA: 16s - loss: 8.2079 - acc: 0.49 - ETA: 15s - loss: 8.2158 - acc: 0.49 - ETA: 15s - loss: 8.1795 - acc: 0.49 - ETA: 15s - loss: 8.1876 - acc: 0.49 - ETA: 14s - loss: 8.1745 - acc: 0.49 - ETA: 14s - loss: 8.1721 - acc: 0.49 - ETA: 14s - loss: 8.1900 - acc: 0.49 - ETA: 13s - loss: 8.1874 - acc: 0.49 - ETA: 13s - loss: 8.1947 - acc: 0.49 - ETA: 13s - loss: 8.1921 - acc: 0.49 - ETA: 12s - loss: 8.2363 - acc: 0.48 - ETA: 12s - loss: 8.2056 - acc: 0.49 - ETA: 12s - loss: 8.2120 - acc: 0.49 - ETA: 12s - loss: 8.2004 - acc: 0.49 - ETA: 11s - loss: 8.1719 - acc: 0.49 - ETA: 11s - loss: 8.1444 - acc: 0.49 - ETA: 11s - loss: 8.1682 - acc: 0.49 - ETA: 10s - loss: 8.1581 - acc: 0.49 - ETA: 10s - loss: 8.1809 - acc: 0.49 - ETA: 10s - loss: 8.1870 - acc: 0.49 - ETA: 9s - loss: 8.2243 - acc: 0.4897 - ETA: 9s - loss: 8.2063 - acc: 0.490 - ETA: 9s - loss: 8.2193 - acc: 0.490 - ETA: 8s - loss: 8.2094 - acc: 0.490 - ETA: 8s - loss: 8.1998 - acc: 0.491 - ETA: 8s - loss: 8.1977 - acc: 0.491 - ETA: 7s - loss: 8.1814 - acc: 0.492 - ETA: 7s - loss: 8.1938 - acc: 0.491 - ETA: 7s - loss: 8.1990 - acc: 0.491 - ETA: 6s - loss: 8.1832 - acc: 0.492 - ETA: 6s - loss: 8.1611 - acc: 0.493 - ETA: 6s - loss: 8.1665 - acc: 0.493 - ETA: 5s - loss: 8.1651 - acc: 0.493 - ETA: 5s - loss: 8.1375 - acc: 0.495 - ETA: 5s - loss: 8.1624 - acc: 0.493 - ETA: 4s - loss: 8.1611 - acc: 0.493 - ETA: 4s - loss: 8.1598 - acc: 0.493 - ETA: 4s - loss: 8.1461 - acc: 0.494 - ETA: 3s - loss: 8.1635 - acc: 0.493 - ETA: 3s - loss: 8.1561 - acc: 0.494 - ETA: 3s - loss: 8.1490 - acc: 0.494 - ETA: 2s - loss: 8.1242 - acc: 0.496 - ETA: 2s - loss: 8.1352 - acc: 0.495 - ETA: 2s - loss: 8.1343 - acc: 0.495 - ETA: 1s - loss: 8.1621 - acc: 0.493 - ETA: 1s - loss: 8.1609 - acc: 0.493 - ETA: 1s - loss: 8.1374 - acc: 0.495 - ETA: 0s - loss: 8.1365 - acc: 0.495 - ETA: 0s - loss: 8.1247 - acc: 0.495 - ETA: 0s - loss: 8.1132 - acc: 0.496 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - ETA: 30s - loss: 7.5554 - acc: 0.53 - ETA: 30s - loss: 7.3035 - acc: 0.54 - ETA: 29s - loss: 7.2196 - acc: 0.55 - ETA: 29s - loss: 7.0517 - acc: 0.56 - ETA: 28s - loss: 7.2531 - acc: 0.55 - ETA: 28s - loss: 7.2196 - acc: 0.55 - ETA: 28s - loss: 7.2675 - acc: 0.54 - ETA: 27s - loss: 7.3035 - acc: 0.54 - ETA: 27s - loss: 7.1636 - acc: 0.55 - ETA: 27s - loss: 7.2531 - acc: 0.55 - ETA: 26s - loss: 7.2806 - acc: 0.54 - ETA: 26s - loss: 7.4294 - acc: 0.53 - ETA: 26s - loss: 7.8266 - acc: 0.51 - ETA: 25s - loss: 7.7712 - acc: 0.51 - ETA: 25s - loss: 7.7568 - acc: 0.51 - ETA: 25s - loss: 7.6813 - acc: 0.52 - ETA: 25s - loss: 7.7035 - acc: 0.52 - ETA: 24s - loss: 7.7233 - acc: 0.52 - ETA: 24s - loss: 7.6614 - acc: 0.52 - ETA: 24s - loss: 7.6057 - acc: 0.52 - ETA: 23s - loss: 7.7952 - acc: 0.51 - ETA: 23s - loss: 7.8301 - acc: 0.51 - ETA: 23s - loss: 7.7087 - acc: 0.52 - ETA: 22s - loss: 7.7652 - acc: 0.51 - ETA: 22s - loss: 7.8374 - acc: 0.51 - ETA: 22s - loss: 7.8459 - acc: 0.51 - ETA: 21s - loss: 7.7606 - acc: 0.51 - ETA: 21s - loss: 7.8252 - acc: 0.51 - ETA: 21s - loss: 7.8506 - acc: 0.51 - ETA: 20s - loss: 7.8744 - acc: 0.51 - ETA: 20s - loss: 7.8803 - acc: 0.51 - ETA: 20s - loss: 7.8702 - acc: 0.51 - ETA: 19s - loss: 7.8912 - acc: 0.51 - ETA: 19s - loss: 7.9109 - acc: 0.50 - ETA: 19s - loss: 7.9151 - acc: 0.50 - ETA: 18s - loss: 7.9191 - acc: 0.50 - ETA: 18s - loss: 7.9093 - acc: 0.50 - ETA: 18s - loss: 7.9398 - acc: 0.50 - ETA: 17s - loss: 8.0203 - acc: 0.50 - ETA: 17s - loss: 8.0590 - acc: 0.50 - ETA: 17s - loss: 8.0099 - acc: 0.50 - ETA: 16s - loss: 8.0111 - acc: 0.50 - ETA: 16s - loss: 8.0473 - acc: 0.50 - ETA: 16s - loss: 8.0362 - acc: 0.50 - ETA: 15s - loss: 8.0031 - acc: 0.50 - ETA: 15s - loss: 7.9824 - acc: 0.50 - ETA: 15s - loss: 7.9626 - acc: 0.50 - ETA: 14s - loss: 7.9961 - acc: 0.50 - ETA: 14s - loss: 7.9768 - acc: 0.50 - ETA: 14s - loss: 7.9986 - acc: 0.50 - ETA: 13s - loss: 7.9998 - acc: 0.50 - ETA: 13s - loss: 8.0106 - acc: 0.50 - ETA: 13s - loss: 7.9735 - acc: 0.50 - ETA: 12s - loss: 7.9378 - acc: 0.50 - ETA: 12s - loss: 7.9583 - acc: 0.50 - ETA: 12s - loss: 7.9421 - acc: 0.50 - ETA: 11s - loss: 7.9265 - acc: 0.50 - ETA: 11s - loss: 7.9548 - acc: 0.50 - ETA: 11s - loss: 7.9822 - acc: 0.50 - ETA: 10s - loss: 7.9919 - acc: 0.50 - ETA: 10s - loss: 8.0095 - acc: 0.50 - ETA: 10s - loss: 8.0184 - acc: 0.50 - ETA: 10s - loss: 8.0111 - acc: 0.50 - ETA: 9s - loss: 8.0040 - acc: 0.5034 - ETA: 9s - loss: 8.0048 - acc: 0.503 - ETA: 9s - loss: 8.0056 - acc: 0.503 - ETA: 8s - loss: 8.0064 - acc: 0.503 - ETA: 8s - loss: 8.0368 - acc: 0.501 - ETA: 8s - loss: 8.0736 - acc: 0.499 - ETA: 7s - loss: 8.0375 - acc: 0.501 - ETA: 7s - loss: 8.0661 - acc: 0.499 - ETA: 7s - loss: 8.0660 - acc: 0.499 - ETA: 6s - loss: 8.0659 - acc: 0.499 - ETA: 6s - loss: 8.0931 - acc: 0.497 - ETA: 6s - loss: 8.0859 - acc: 0.498 - ETA: 5s - loss: 8.0856 - acc: 0.498 - ETA: 5s - loss: 8.1179 - acc: 0.496 - ETA: 5s - loss: 8.1301 - acc: 0.495 - ETA: 4s - loss: 8.1228 - acc: 0.496 - ETA: 4s - loss: 8.1094 - acc: 0.496 - ETA: 4s - loss: 8.1150 - acc: 0.496 - ETA: 3s - loss: 8.1266 - acc: 0.495 - ETA: 3s - loss: 8.1379 - acc: 0.495 - ETA: 3s - loss: 8.1310 - acc: 0.495 - ETA: 2s - loss: 8.1361 - acc: 0.495 - ETA: 2s - loss: 8.1352 - acc: 0.495 - ETA: 2s - loss: 8.1227 - acc: 0.496 - ETA: 1s - loss: 8.1392 - acc: 0.495 - ETA: 1s - loss: 8.1383 - acc: 0.495 - ETA: 1s - loss: 8.1318 - acc: 0.495 - ETA: 0s - loss: 8.1144 - acc: 0.496 - ETA: 0s - loss: 8.1247 - acc: 0.495 - ETA: 0s - loss: 8.1457 - acc: 0.494 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 32s - loss: 8.0590 - acc: 0.50 - ETA: 31s - loss: 7.5554 - acc: 0.53 - ETA: 30s - loss: 6.8838 - acc: 0.57 - ETA: 30s - loss: 7.6813 - acc: 0.52 - ETA: 29s - loss: 7.6561 - acc: 0.52 - ETA: 29s - loss: 8.1430 - acc: 0.49 - ETA: 28s - loss: 7.9871 - acc: 0.50 - ETA: 28s - loss: 8.3109 - acc: 0.48 - ETA: 27s - loss: 8.0590 - acc: 0.50 - ETA: 27s - loss: 7.7568 - acc: 0.51 - ETA: 27s - loss: 7.8301 - acc: 0.51 - ETA: 26s - loss: 8.0171 - acc: 0.50 - ETA: 26s - loss: 8.0590 - acc: 0.50 - ETA: 26s - loss: 8.0590 - acc: 0.50 - ETA: 25s - loss: 8.1262 - acc: 0.49 - ETA: 25s - loss: 8.0905 - acc: 0.49 - ETA: 25s - loss: 8.0887 - acc: 0.49 - ETA: 24s - loss: 8.0590 - acc: 0.50 - ETA: 24s - loss: 8.0856 - acc: 0.49 - ETA: 24s - loss: 8.0842 - acc: 0.49 - ETA: 23s - loss: 8.1550 - acc: 0.49 - ETA: 23s - loss: 8.1048 - acc: 0.49 - ETA: 23s - loss: 8.1247 - acc: 0.49 - ETA: 22s - loss: 8.0800 - acc: 0.49 - ETA: 22s - loss: 8.0389 - acc: 0.50 - ETA: 22s - loss: 8.0397 - acc: 0.50 - ETA: 21s - loss: 8.0031 - acc: 0.50 - ETA: 21s - loss: 7.9331 - acc: 0.50 - ETA: 21s - loss: 7.9027 - acc: 0.50 - ETA: 20s - loss: 7.8744 - acc: 0.51 - ETA: 20s - loss: 7.8966 - acc: 0.51 - ETA: 20s - loss: 7.9331 - acc: 0.50 - ETA: 19s - loss: 7.9827 - acc: 0.50 - ETA: 19s - loss: 7.9702 - acc: 0.50 - ETA: 19s - loss: 8.0590 - acc: 0.50 - ETA: 18s - loss: 8.1290 - acc: 0.49 - ETA: 18s - loss: 8.1271 - acc: 0.49 - ETA: 18s - loss: 8.1121 - acc: 0.49 - ETA: 17s - loss: 8.1236 - acc: 0.49 - ETA: 17s - loss: 8.1094 - acc: 0.49 - ETA: 17s - loss: 8.1205 - acc: 0.49 - ETA: 16s - loss: 8.1910 - acc: 0.49 - ETA: 16s - loss: 8.1879 - acc: 0.49 - ETA: 16s - loss: 8.1621 - acc: 0.49 - ETA: 15s - loss: 8.1486 - acc: 0.49 - ETA: 15s - loss: 8.2233 - acc: 0.48 - ETA: 15s - loss: 8.2520 - acc: 0.48 - ETA: 14s - loss: 8.2584 - acc: 0.48 - ETA: 14s - loss: 8.2338 - acc: 0.48 - ETA: 14s - loss: 8.2001 - acc: 0.49 - ETA: 13s - loss: 8.1282 - acc: 0.49 - ETA: 13s - loss: 8.1075 - acc: 0.49 - ETA: 13s - loss: 8.1066 - acc: 0.49 - ETA: 12s - loss: 8.1057 - acc: 0.49 - ETA: 12s - loss: 8.1506 - acc: 0.49 - ETA: 12s - loss: 8.2120 - acc: 0.49 - ETA: 12s - loss: 8.2181 - acc: 0.49 - ETA: 11s - loss: 8.2154 - acc: 0.49 - ETA: 11s - loss: 8.2213 - acc: 0.48 - ETA: 11s - loss: 8.1850 - acc: 0.49 - ETA: 10s - loss: 8.1499 - acc: 0.49 - ETA: 10s - loss: 8.1972 - acc: 0.49 - ETA: 10s - loss: 8.1790 - acc: 0.49 - ETA: 9s - loss: 8.1928 - acc: 0.4917 - ETA: 9s - loss: 8.1753 - acc: 0.492 - ETA: 9s - loss: 8.1888 - acc: 0.492 - ETA: 8s - loss: 8.1868 - acc: 0.492 - ETA: 8s - loss: 8.1776 - acc: 0.492 - ETA: 8s - loss: 8.1904 - acc: 0.491 - ETA: 7s - loss: 8.1886 - acc: 0.492 - ETA: 7s - loss: 8.1796 - acc: 0.492 - ETA: 7s - loss: 8.1640 - acc: 0.493 - ETA: 6s - loss: 8.1349 - acc: 0.495 - ETA: 6s - loss: 8.1067 - acc: 0.497 - ETA: 6s - loss: 8.1195 - acc: 0.496 - ETA: 5s - loss: 8.1320 - acc: 0.495 - ETA: 5s - loss: 8.1572 - acc: 0.493 - ETA: 5s - loss: 8.1753 - acc: 0.492 - ETA: 4s - loss: 8.1802 - acc: 0.492 - ETA: 4s - loss: 8.1913 - acc: 0.491 - ETA: 4s - loss: 8.2083 - acc: 0.490 - ETA: 3s - loss: 8.2065 - acc: 0.490 - ETA: 3s - loss: 8.2108 - acc: 0.490 - ETA: 3s - loss: 8.2269 - acc: 0.489 - ETA: 2s - loss: 8.2190 - acc: 0.490 - ETA: 2s - loss: 8.1879 - acc: 0.492 - ETA: 2s - loss: 8.1690 - acc: 0.493 - ETA: 1s - loss: 8.1392 - acc: 0.495 - ETA: 1s - loss: 8.1496 - acc: 0.494 - ETA: 1s - loss: 8.1374 - acc: 0.495 - ETA: 0s - loss: 8.1476 - acc: 0.494 - ETA: 0s - loss: 8.1412 - acc: 0.494 - ETA: 0s - loss: 8.1457 - acc: 0.494 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - ETA: 30s - loss: 8.0590 - acc: 0.50 - ETA: 30s - loss: 7.8072 - acc: 0.51 - ETA: 29s - loss: 7.8912 - acc: 0.51 - ETA: 29s - loss: 7.4294 - acc: 0.53 - ETA: 28s - loss: 7.0517 - acc: 0.56 - ETA: 28s - loss: 6.8838 - acc: 0.57 - ETA: 28s - loss: 7.1236 - acc: 0.55 - ETA: 28s - loss: 7.1146 - acc: 0.55 - ETA: 27s - loss: 7.2755 - acc: 0.54 - ETA: 27s - loss: 7.6057 - acc: 0.52 - ETA: 27s - loss: 7.7843 - acc: 0.51 - ETA: 26s - loss: 7.7652 - acc: 0.51 - ETA: 26s - loss: 7.8653 - acc: 0.51 - ETA: 26s - loss: 7.8072 - acc: 0.51 - ETA: 25s - loss: 7.9583 - acc: 0.50 - ETA: 25s - loss: 8.0590 - acc: 0.50 - ETA: 24s - loss: 7.9702 - acc: 0.50 - ETA: 24s - loss: 8.1430 - acc: 0.49 - ETA: 24s - loss: 8.1651 - acc: 0.49 - ETA: 23s - loss: 8.1850 - acc: 0.49 - ETA: 23s - loss: 8.2030 - acc: 0.49 - ETA: 23s - loss: 8.0590 - acc: 0.50 - ETA: 22s - loss: 8.0371 - acc: 0.50 - ETA: 22s - loss: 7.9541 - acc: 0.50 - ETA: 22s - loss: 7.9382 - acc: 0.50 - ETA: 22s - loss: 7.9234 - acc: 0.50 - ETA: 21s - loss: 7.9658 - acc: 0.50 - ETA: 21s - loss: 8.0051 - acc: 0.50 - ETA: 21s - loss: 8.0417 - acc: 0.50 - ETA: 20s - loss: 8.0590 - acc: 0.50 - ETA: 20s - loss: 8.0103 - acc: 0.50 - ETA: 20s - loss: 7.9803 - acc: 0.50 - ETA: 19s - loss: 8.0133 - acc: 0.50 - ETA: 19s - loss: 8.0442 - acc: 0.50 - ETA: 19s - loss: 7.9871 - acc: 0.50 - ETA: 18s - loss: 7.9051 - acc: 0.50 - ETA: 18s - loss: 7.9229 - acc: 0.50 - ETA: 18s - loss: 7.9530 - acc: 0.50 - ETA: 17s - loss: 7.9686 - acc: 0.50 - ETA: 17s - loss: 7.9709 - acc: 0.50 - ETA: 17s - loss: 7.9116 - acc: 0.50 - ETA: 16s - loss: 7.9031 - acc: 0.50 - ETA: 16s - loss: 7.8716 - acc: 0.51 - ETA: 16s - loss: 7.8530 - acc: 0.51 - ETA: 15s - loss: 7.8464 - acc: 0.51 - ETA: 15s - loss: 7.9167 - acc: 0.50 - ETA: 15s - loss: 7.9519 - acc: 0.50 - ETA: 14s - loss: 8.0066 - acc: 0.50 - ETA: 14s - loss: 7.9768 - acc: 0.50 - ETA: 14s - loss: 7.9684 - acc: 0.50 - ETA: 13s - loss: 8.0097 - acc: 0.50 - ETA: 13s - loss: 7.9719 - acc: 0.50 - ETA: 13s - loss: 8.0210 - acc: 0.50 - ETA: 12s - loss: 8.0590 - acc: 0.50 - ETA: 12s - loss: 8.0407 - acc: 0.50 - ETA: 12s - loss: 8.0950 - acc: 0.49 - ETA: 11s - loss: 8.1297 - acc: 0.49 - ETA: 11s - loss: 8.1546 - acc: 0.49 - ETA: 11s - loss: 8.1615 - acc: 0.49 - ETA: 10s - loss: 8.2018 - acc: 0.49 - ETA: 10s - loss: 8.1746 - acc: 0.49 - ETA: 10s - loss: 8.2215 - acc: 0.48 - ETA: 10s - loss: 8.1950 - acc: 0.49 - ETA: 9s - loss: 8.2243 - acc: 0.4897 - ETA: 9s - loss: 8.2528 - acc: 0.488 - ETA: 9s - loss: 8.2422 - acc: 0.488 - ETA: 8s - loss: 8.2545 - acc: 0.487 - ETA: 8s - loss: 8.2442 - acc: 0.488 - ETA: 8s - loss: 8.2488 - acc: 0.488 - ETA: 7s - loss: 8.2317 - acc: 0.489 - ETA: 7s - loss: 8.2364 - acc: 0.489 - ETA: 7s - loss: 8.2269 - acc: 0.489 - ETA: 6s - loss: 8.2384 - acc: 0.488 - ETA: 6s - loss: 8.2564 - acc: 0.487 - ETA: 6s - loss: 8.2269 - acc: 0.489 - ETA: 5s - loss: 8.2115 - acc: 0.490 - ETA: 5s - loss: 8.2160 - acc: 0.490 - ETA: 5s - loss: 8.2011 - acc: 0.491 - ETA: 4s - loss: 8.1866 - acc: 0.492 - ETA: 4s - loss: 8.1661 - acc: 0.493 - ETA: 4s - loss: 8.1772 - acc: 0.492 - ETA: 3s - loss: 8.1819 - acc: 0.492 - ETA: 3s - loss: 8.2047 - acc: 0.491 - ETA: 3s - loss: 8.1970 - acc: 0.491 - ETA: 2s - loss: 8.1894 - acc: 0.491 - ETA: 2s - loss: 8.1703 - acc: 0.493 - ETA: 2s - loss: 8.1806 - acc: 0.492 - ETA: 1s - loss: 8.1678 - acc: 0.493 - ETA: 1s - loss: 8.1666 - acc: 0.493 - ETA: 1s - loss: 8.1430 - acc: 0.494 - ETA: 0s - loss: 8.1531 - acc: 0.494 - ETA: 0s - loss: 8.1576 - acc: 0.493 - ETA: 0s - loss: 8.1511 - acc: 0.494 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 31s - loss: 9.0664 - acc: 0.43 - ETA: 30s - loss: 9.0664 - acc: 0.43 - ETA: 30s - loss: 8.3948 - acc: 0.47 - ETA: 30s - loss: 8.1850 - acc: 0.49 - ETA: 29s - loss: 8.4620 - acc: 0.47 - ETA: 29s - loss: 8.5627 - acc: 0.46 - ETA: 28s - loss: 8.2030 - acc: 0.49 - ETA: 28s - loss: 8.1850 - acc: 0.49 - ETA: 28s - loss: 8.3389 - acc: 0.48 - ETA: 27s - loss: 8.3109 - acc: 0.48 - ETA: 27s - loss: 8.1964 - acc: 0.49 - ETA: 27s - loss: 8.1010 - acc: 0.49 - ETA: 26s - loss: 8.0978 - acc: 0.49 - ETA: 26s - loss: 8.0950 - acc: 0.49 - ETA: 26s - loss: 8.0255 - acc: 0.50 - ETA: 25s - loss: 7.9016 - acc: 0.50 - ETA: 25s - loss: 7.9405 - acc: 0.50 - ETA: 24s - loss: 7.8632 - acc: 0.51 - ETA: 24s - loss: 7.8470 - acc: 0.51 - ETA: 24s - loss: 7.7568 - acc: 0.51 - ETA: 23s - loss: 7.7472 - acc: 0.51 - ETA: 23s - loss: 7.7385 - acc: 0.51 - ETA: 23s - loss: 7.8182 - acc: 0.51 - ETA: 22s - loss: 7.8492 - acc: 0.51 - ETA: 22s - loss: 7.9382 - acc: 0.50 - ETA: 22s - loss: 7.9816 - acc: 0.50 - ETA: 21s - loss: 7.9285 - acc: 0.50 - ETA: 21s - loss: 7.9331 - acc: 0.50 - ETA: 21s - loss: 7.9548 - acc: 0.50 - ETA: 20s - loss: 7.9919 - acc: 0.50 - ETA: 20s - loss: 8.0266 - acc: 0.50 - ETA: 20s - loss: 8.0433 - acc: 0.50 - ETA: 19s - loss: 8.0590 - acc: 0.50 - ETA: 19s - loss: 8.0739 - acc: 0.49 - ETA: 19s - loss: 8.1166 - acc: 0.49 - ETA: 18s - loss: 8.0730 - acc: 0.49 - ETA: 18s - loss: 8.0590 - acc: 0.50 - ETA: 18s - loss: 8.0325 - acc: 0.50 - ETA: 17s - loss: 8.0332 - acc: 0.50 - ETA: 17s - loss: 8.0339 - acc: 0.50 - ETA: 17s - loss: 8.0468 - acc: 0.50 - ETA: 16s - loss: 8.0830 - acc: 0.49 - ETA: 16s - loss: 8.1176 - acc: 0.49 - ETA: 16s - loss: 8.1392 - acc: 0.49 - ETA: 15s - loss: 8.1150 - acc: 0.49 - ETA: 15s - loss: 8.1247 - acc: 0.49 - ETA: 15s - loss: 8.1341 - acc: 0.49 - ETA: 14s - loss: 8.1220 - acc: 0.49 - ETA: 14s - loss: 8.1721 - acc: 0.49 - ETA: 14s - loss: 8.1699 - acc: 0.49 - ETA: 13s - loss: 8.1578 - acc: 0.49 - ETA: 13s - loss: 8.1365 - acc: 0.49 - ETA: 13s - loss: 8.1256 - acc: 0.49 - ETA: 12s - loss: 8.0777 - acc: 0.49 - ETA: 12s - loss: 8.0499 - acc: 0.50 - ETA: 12s - loss: 8.0590 - acc: 0.50 - ETA: 12s - loss: 8.1121 - acc: 0.49 - ETA: 11s - loss: 8.0677 - acc: 0.49 - ETA: 11s - loss: 8.0761 - acc: 0.49 - ETA: 11s - loss: 8.0339 - acc: 0.50 - ETA: 10s - loss: 8.0178 - acc: 0.50 - ETA: 10s - loss: 7.9778 - acc: 0.50 - ETA: 10s - loss: 8.0191 - acc: 0.50 - ETA: 9s - loss: 8.0276 - acc: 0.5020 - ETA: 9s - loss: 8.0281 - acc: 0.501 - ETA: 9s - loss: 8.0209 - acc: 0.502 - ETA: 8s - loss: 8.0515 - acc: 0.500 - ETA: 8s - loss: 8.0739 - acc: 0.499 - ETA: 8s - loss: 8.0955 - acc: 0.497 - ETA: 7s - loss: 8.0878 - acc: 0.498 - ETA: 7s - loss: 8.0945 - acc: 0.497 - ETA: 7s - loss: 8.1500 - acc: 0.494 - ETA: 6s - loss: 8.1487 - acc: 0.494 - ETA: 6s - loss: 8.1475 - acc: 0.494 - ETA: 6s - loss: 8.1128 - acc: 0.496 - ETA: 5s - loss: 8.0988 - acc: 0.497 - ETA: 5s - loss: 8.0983 - acc: 0.497 - ETA: 5s - loss: 8.1107 - acc: 0.496 - ETA: 4s - loss: 8.1101 - acc: 0.496 - ETA: 4s - loss: 8.1094 - acc: 0.496 - ETA: 4s - loss: 8.1150 - acc: 0.496 - ETA: 3s - loss: 8.0959 - acc: 0.497 - ETA: 3s - loss: 8.0712 - acc: 0.499 - ETA: 3s - loss: 8.0950 - acc: 0.497 - ETA: 2s - loss: 8.0946 - acc: 0.497 - ETA: 2s - loss: 8.1176 - acc: 0.496 - ETA: 2s - loss: 8.1054 - acc: 0.497 - ETA: 1s - loss: 8.1048 - acc: 0.497 - ETA: 1s - loss: 8.1326 - acc: 0.495 - ETA: 1s - loss: 8.1542 - acc: 0.494 - ETA: 0s - loss: 8.1531 - acc: 0.494 - ETA: 0s - loss: 8.1466 - acc: 0.494 - ETA: 0s - loss: 8.1511 - acc: 0.494 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - ETA: 32s - loss: 8.5627 - acc: 0.46 - ETA: 31s - loss: 7.8072 - acc: 0.51 - ETA: 30s - loss: 8.5627 - acc: 0.46 - ETA: 29s - loss: 8.8146 - acc: 0.45 - ETA: 29s - loss: 8.9657 - acc: 0.44 - ETA: 28s - loss: 8.6467 - acc: 0.46 - ETA: 28s - loss: 8.6347 - acc: 0.46 - ETA: 28s - loss: 8.4368 - acc: 0.47 - ETA: 27s - loss: 8.2829 - acc: 0.48 - ETA: 27s - loss: 8.4620 - acc: 0.47 - ETA: 27s - loss: 8.6085 - acc: 0.46 - ETA: 26s - loss: 8.4368 - acc: 0.47 - ETA: 26s - loss: 8.3690 - acc: 0.48 - ETA: 25s - loss: 8.3109 - acc: 0.48 - ETA: 25s - loss: 8.3613 - acc: 0.48 - ETA: 25s - loss: 8.1850 - acc: 0.49 - ETA: 24s - loss: 8.2368 - acc: 0.48 - ETA: 24s - loss: 8.2549 - acc: 0.48 - ETA: 24s - loss: 8.2446 - acc: 0.48 - ETA: 24s - loss: 8.2857 - acc: 0.48 - ETA: 23s - loss: 8.2749 - acc: 0.48 - ETA: 23s - loss: 8.3567 - acc: 0.48 - ETA: 23s - loss: 8.3218 - acc: 0.48 - ETA: 22s - loss: 8.2899 - acc: 0.48 - ETA: 22s - loss: 8.3008 - acc: 0.48 - ETA: 22s - loss: 8.3884 - acc: 0.47 - ETA: 21s - loss: 8.3762 - acc: 0.48 - ETA: 21s - loss: 8.3828 - acc: 0.47 - ETA: 21s - loss: 8.3022 - acc: 0.48 - ETA: 20s - loss: 8.2605 - acc: 0.48 - ETA: 20s - loss: 8.2215 - acc: 0.48 - ETA: 20s - loss: 8.2637 - acc: 0.48 - ETA: 19s - loss: 8.1354 - acc: 0.49 - ETA: 19s - loss: 8.0887 - acc: 0.49 - ETA: 19s - loss: 8.0734 - acc: 0.49 - ETA: 18s - loss: 8.0451 - acc: 0.50 - ETA: 18s - loss: 8.0454 - acc: 0.50 - ETA: 18s - loss: 8.0060 - acc: 0.50 - ETA: 17s - loss: 8.0074 - acc: 0.50 - ETA: 17s - loss: 8.0339 - acc: 0.50 - ETA: 17s - loss: 8.0468 - acc: 0.50 - ETA: 16s - loss: 8.0471 - acc: 0.50 - ETA: 16s - loss: 8.1059 - acc: 0.49 - ETA: 16s - loss: 8.0934 - acc: 0.49 - ETA: 15s - loss: 8.0814 - acc: 0.49 - ETA: 15s - loss: 8.0700 - acc: 0.49 - ETA: 15s - loss: 8.0162 - acc: 0.50 - ETA: 14s - loss: 7.9856 - acc: 0.50 - ETA: 14s - loss: 8.0077 - acc: 0.50 - ETA: 14s - loss: 7.9986 - acc: 0.50 - ETA: 13s - loss: 7.9800 - acc: 0.50 - ETA: 13s - loss: 7.9816 - acc: 0.50 - ETA: 13s - loss: 7.9450 - acc: 0.50 - ETA: 12s - loss: 8.0124 - acc: 0.50 - ETA: 12s - loss: 7.9858 - acc: 0.50 - ETA: 12s - loss: 7.9871 - acc: 0.50 - ETA: 11s - loss: 7.9795 - acc: 0.50 - ETA: 11s - loss: 7.9635 - acc: 0.50 - ETA: 11s - loss: 7.9993 - acc: 0.50 - ETA: 10s - loss: 8.0590 - acc: 0.50 - ETA: 10s - loss: 8.0673 - acc: 0.49 - ETA: 10s - loss: 8.0834 - acc: 0.49 - ETA: 9s - loss: 8.0910 - acc: 0.4980 - ETA: 9s - loss: 8.1220 - acc: 0.496 - ETA: 9s - loss: 8.1520 - acc: 0.494 - ETA: 9s - loss: 8.1812 - acc: 0.492 - ETA: 8s - loss: 8.1643 - acc: 0.493 - ETA: 8s - loss: 8.1331 - acc: 0.495 - ETA: 8s - loss: 8.1101 - acc: 0.496 - ETA: 7s - loss: 8.1022 - acc: 0.497 - ETA: 7s - loss: 8.1371 - acc: 0.495 - ETA: 7s - loss: 8.1290 - acc: 0.495 - ETA: 6s - loss: 8.1487 - acc: 0.494 - ETA: 6s - loss: 8.1816 - acc: 0.492 - ETA: 6s - loss: 8.1598 - acc: 0.493 - ETA: 5s - loss: 8.1320 - acc: 0.495 - ETA: 5s - loss: 8.1048 - acc: 0.497 - ETA: 5s - loss: 8.1301 - acc: 0.495 - ETA: 4s - loss: 8.1547 - acc: 0.494 - ETA: 4s - loss: 8.1283 - acc: 0.495 - ETA: 4s - loss: 8.1337 - acc: 0.495 - ETA: 3s - loss: 8.1082 - acc: 0.497 - ETA: 3s - loss: 8.0894 - acc: 0.498 - ETA: 3s - loss: 8.0890 - acc: 0.498 - ETA: 2s - loss: 8.0946 - acc: 0.497 - ETA: 2s - loss: 8.1000 - acc: 0.497 - ETA: 2s - loss: 8.0938 - acc: 0.497 - ETA: 1s - loss: 8.1048 - acc: 0.497 - ETA: 1s - loss: 8.1270 - acc: 0.495 - ETA: 1s - loss: 8.0982 - acc: 0.497 - ETA: 0s - loss: 8.1255 - acc: 0.495 - ETA: 0s - loss: 8.1247 - acc: 0.495 - ETA: 0s - loss: 8.1457 - acc: 0.494 - 32s 11ms/step - loss: 8.1396 - acc: 0.4950 - val_loss: 7.8173 - val_acc: 0.5150\n"
     ]
    }
   ],
   "source": [
    "history1 = cnn1.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "         #batch_size=250,\n",
    "        # verbose=1,\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cnn1, to_file=\"cnn1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5gU9Z3v8fdHQMcBBAIkRlAHL6sCchknBMUIinE1xuuaCEK8RBdxTbztniPHmERNfNYoRwnGo7LZmKwgxCWSsMZEk5WEmOyiw1UusqAgjhAdUPACRge/548qJs3QM9PDDPRM8Xk9Tz/T/atfVX+rGj5d/evqKkUEZmaWXfsVuwAzM9uzHPRmZhnnoDczyzgHvZlZxjnozcwyzkFvZpZxDnprMkntJL0n6bCW7FtMko6S1OLHGks6XdLanMcrJX2ukL678Vw/lHTL7s7fwHK/K+nHLb1c23vaF7sA2/MkvZfzsBT4C7A9fXx1RExryvIiYjvQqaX77gsi4piWWI6kq4CxETEiZ9lXtcSyLXsc9PuAiKgN2nSP8aqI+G19/SW1j4iavVGbme15HrqxHR/NfyppuqR3gbGSTpT035I2S9ogabKkDmn/9pJCUln6eGo6/VeS3pX0X5L6NLVvOv0sSf8jaYuk+yX9UdLl9dRdSI1XS1ot6W1Jk3PmbSfpPkmbJL0MnNnA9rlV0ow6bQ9Iuje9f5WkFen6vJzubde3rCpJI9L7pZIeTWtbBpyQ53lfSZe7TNK5afvxwA+Az6XDYhtztu1tOfOPT9d9k6SfS/p0IdumMZLOT+vZLOlZScfkTLtF0npJ70h6KWddh0pakLa/IemeQp/PWkBE+LYP3YC1wOl12r4LfAicQ/LmfyDwGeCzJJ/6jgD+B/ha2r89EEBZ+ngqsBGoADoAPwWm7kbfTwLvAuel024CPgIur2ddCqnxF0AXoAx4a8e6A18DlgG9ge7A3OS/Q97nOQJ4D+iYs+w3gYr08TlpHwGnAduAAem004G1OcuqAkak9ycCvwO6AYcDy+v0/TLw6fQ1uSSt4VPptKuA39WpcypwW3r/jLTGQUAJ8P+AZwvZNnnW/7vAj9P7x6V1nJa+Rrek270D0A94FTg47dsHOCK9/wIwOr3fGfhssf8v7Es379HbDs9FxH9ExMcRsS0iXoiIeRFRExGvAFOA4Q3MPzMiKiPiI2AaScA0te8XgUUR8Yt02n0kbwp5FVjjP0fElohYSxKqO57ry8B9EVEVEZuAuxp4nleApSRvQACfBzZHRGU6/T8i4pVIPAv8J5D3C9c6vgx8NyLejohXSfbSc5/38YjYkL4mj5G8SVcUsFyAMcAPI2JRRHwATACGS+qd06e+bdOQUcDsiHg2fY3uAg4iecOtIXlT6ZcO/61Jtx0kb9hHS+oeEe9GxLwC18NagIPedngt94GkYyX9UtKfJb0D3AH0aGD+P+fc30rDX8DW1/eQ3DoiIkj2gPMqsMaCnotkT7QhjwGj0/uXkLxB7ajji5LmSXpL0maSvemGttUOn26oBkmXS1qcDpFsBo4tcLmQrF/t8iLiHeBtoFdOn6a8ZvUt92OS16hXRKwE/pHkdXgzHQo8OO16BdAXWCnpeUlfKHA9rAU46G2HuocWPkyyF3tURBwEfItkaGJP2kAylAKAJLFzMNXVnBo3AIfmPG7s8M+fAqene8TnkQQ/kg4EZgL/TDKs0hV4psA6/lxfDZKOAB4ErgG6p8t9KWe5jR0Kup5kOGjH8jqTDBG9XkBdTVnufiSv2esAETE1IoaRDNu0I9kuRMTKiBhFMjz3f4GfSSppZi1WIAe91aczsAV4X9JxwNV74TmfBMolnSOpPXA90HMP1fg4cIOkXpK6Azc31Dki3gCeAx4BVkbEqnTSAcD+QDWwXdIXgZFNqOEWSV2V/M7gaznTOpGEeTXJe95VJHv0O7wB9N7x5XMe04ErJQ2QdABJ4P4hIur9hNSEms+VNCJ97v9F8r3KPEnHSTo1fb5t6W07yQp8RVKP9BPAlnTdPm5mLVYgB73V5x+By0j+Ez9Mske7R6VhejFwL7AJOBJYSHLcf0vX+CDJWPqLJF8UzixgnsdIvlx9LKfmzcCNwCySLzQvInnDKsS3ST5ZrAV+BfxbznKXAJOB59M+xwK549q/AVYBb0jKHYLZMf+vSYZQZqXzH0Yybt8sEbGMZJs/SPImdCZwbjpefwBwN8n3Kn8m+QRxazrrF4AVSo7qmghcHBEfNrceK4ySYVCz1kdSO5Khgosi4g/FrsesrfIevbUqks6U1CX9+P9NkiM5ni9yWWZtmoPeWpuTgVdIPv6fCZwfEfUN3ZhZATx0Y2aWcd6jNzPLuFZ5UrMePXpEWVlZscswM2sz5s+fvzEi8h6O3CqDvqysjMrKymKXYWbWZkiq99fdHroxM8s4B72ZWcY56M3MMs5Bb2aWcQ56M7OMy0zQT5sGZWWw337J32lNuty1mVl2tcrDK5tq2jQYNw62bk0ev/pq8hhgTLPP12dm1rYVtEcv6cb0YsBL06vGlNSZfkp64d8aSRfVmbZd0qL0Nrsli9/hG9/4a8jvsHVr0m5mtq9rNOgl9QKuI7kQcn+Sq8aMqtNtHXA5OefpzrEtIgalt3ObWW9e69Y1rd3MbF9S6Bh9e+DA9Ko/pSTnCK8VEWvTCyUU5Yoxh9VzEbj62s3M9iWNBn1EvE5yRZh1JFeq2RIRzzThOUokVUr6b0nn19dJ0ri0X2V1dXUTFg933gmlpTu3lZYm7WZm+7pChm66kVwMuQ/JFeA7ShrbhOc4LCIqgEuASZKOzNcpIqZEREVEVPTs2dBlQnc1ZgxMmQKHHw5S8nfKFH8Ra2YGhR11czqwJiKqASQ9AZwETC3kCSJiffr3FUm/AwYDL+9WtQ0YM8bBbmaWTyFj9OuAoZJKJYnkCvcrClm4pG7pJeGQ1AMYBizf3WLbgtZwPH9rqMF1uI62UEdrqGGv1BERjd6A24GXgKXAoyRXe7+D5OrvAJ8BqoD3gU3AsrT9JOBFYHH698pCnu+EE06Itmjq1IjS0gj46620NGnfl2pwHa6jLdTRGmpoyTqAyqgvw+ubUMxbWw36ww/f+cXacTv88H2rBtfhOtpCHa2hhpaso6Ggb5XXjK2oqIi2eOGR/fZLXqK6JPh4Lx142hpqcB2uoy3U0RpqaMk6JM2P5MCXXZ9jd4uzXbWG4/lbQw2uw3W0hTpaQw17qw4HfQtqDcfzt4YaXIfraAt1tIYa9lod9Y3pFPPWVsfoI5IvUA4/PEJK/u7tL3ZaSw2uw3W0hTpaQw0tVQceozczyzaP0ZuZ7cMc9GZmGeegNzPLOAe9mVnGOejNzDLOQW9mlnEOejOzjHPQm5llnIPezCzjHPRmZhnnoDczyzgHvZlZxjnozcwyzkFvZpZxDnozs4wrKOgl3ShpmaSlkqZLKqkz/RRJCyTVSLqozrTLJK1Kb5e1ZPFmZta4RoNeUi/gOqAiIvoD7YBRdbqtAy4HHqsz7yeAbwOfBYYA35bUrfllm5lZoQodumkPHCipPVAKrM+dGBFrI2IJUPea5X8L/CYi3oqIt4HfAGc2s2YzM2uCRoM+Il4HJpLstW8AtkTEMwUuvxfwWs7jqrRtF5LGSaqUVFldXV3g4s3MrDGFDN10A84D+gCHAB0ljS1w+crTlvcitRExJSIqIqKiZ8+eBS7ezMwaU8jQzenAmoiojoiPgCeAkwpcfhVwaM7j3tQZ9jEzsz2rkKBfBwyVVCpJwEhgRYHLfxo4Q1K39JPBGWmbmZntJYWM0c8DZgILgBfTeaZIukPSuQCSPiOpCvgS8LCkZem8bwHfAV5Ib3ekbWZmtpcoIu+QeVFVVFREZWVlscswM2szJM2PiIp80/zLWDOzjHPQm5llnIPezCzjHPRmZhnnoDczyzgHvZlZxjnozcwyzkFvZpZxDnozs4xz0JuZZZyD3sws4xz0ZmYZ56A3M8s4B72ZWcY56M3MMs5Bb2aWcQ56M7OMc9CbmWWcg97MLOMc9GZmGeegNzPLuIKCXtKNkpZJWippuqSSOtMPkPRTSaslzZNUlraXSdomaVF6e6jlV8HMzBrSaNBL6gVcB1RERH+gHTCqTrcrgbcj4ijgPuB7OdNejohB6W18C9VtZmYFKnTopj1woKT2QCmwvs7084CfpPdnAiMlqWVKNDOz5mg06CPidWAisA7YAGyJiGfqdOsFvJb2rwG2AN3TaX0kLZT0e0mfq+95JI2TVCmpsrq6ejdWxczM8ilk6KYbyR57H+AQoKOksXW75Zk1SN4YDouIwcBNwGOSDsr3PBExJSIqIqKiZ8+eTVkHMzNrQCFDN6cDayKiOiI+Ap4ATqrTpwo4FCAd3ukCvBURf4mITQARMR94GfiblirezMwaV0jQrwOGSipNx91HAivq9JkNXJbevwh4NiJCUk9J7QAkHQEcDbzSMqWbmVkh2jfWISLmSZoJLABqgIXAFEl3AJURMRv4V+BRSauBt/jrUTmnAHdIqgG2A+Mj4q09sB5mZlYPRUSxa9hFRUVFVFZWFrsMM7M2Q9L8iKjIN82/jDUzyzgHvZlZxjnozcwyzkFvZpZxDnozs4xz0JuZZZyD3sws4xz0ZmYZ56A3M8s4B72ZWcY56M3MMs5Bb2aWcQ56M7OMc9CbmWWcg97MLOMc9GZmGdfoFabMLPs++ugjqqqq+OCDD4pdijWipKSE3r1706FDh4LncdCbGVVVVXTu3JmysjKSS0NbaxQRbNq0iaqqKvr06VPwfB66MTM++OADunfv7pBv5STRvXv3Jn/yctCbGYBDvo3YndepoKCXdKOkZZKWSpouqaTO9AMk/VTSaknzJJXlTPs/aftKSX/b5ArNLNM2bdrEoEGDGDRoEAcffDC9evWqffzhhx8WtIwrrriClStXNtjngQceYNq0aS1RMieffDKLFi1qkWXtDY2O0UvqBVwH9I2IbZIeB0YBP87pdiXwdkQcJWkU8D3gYkl90779gEOA30r6m4jY3sLrYWZ70bRp8I1vwLp1cNhhcOedMGbM7i2re/futaF522230alTJ/7pn/5ppz4RQUSw3375900feeSRRp/n2muv3b0CM6DQoZv2wIGS2gOlwPo6088DfpLenwmMVPL54jxgRkT8JSLWAKuBIc0v28yKZdo0GDcOXn0VIpK/48Yl7S1p9erV9O/fn/Hjx1NeXs6GDRsYN24cFRUV9OvXjzvuuKO274497JqaGrp27cqECRMYOHAgJ554Im+++SYAt956K5MmTartP2HCBIYMGcIxxxzDn/70JwDef/99/u7v/o6BAwcyevRoKioqGt1znzp1Kscffzz9+/fnlltuAaCmpoavfOUrte2TJ08G4L777qNv374MHDiQsWPHtuwGa0CjQR8RrwMTgXXABmBLRDxTp1sv4LW0fw2wBeie256qStt2IWmcpEpJldXV1U1dDzPbS77xDdi6dee2rVuT9pa2fPlyrrzyShYuXEivXr246667qKysZPHixfzmN79h+fLlu8yzZcsWhg8fzuLFiznxxBP50Y9+lHfZEcHzzz/PPffcU/umcf/993PwwQezePFiJkyYwMKFCxusr6qqiltvvZU5c+awcOFC/vjHP/Lkk08yf/58Nm7cyIsvvsjSpUu59NJLAbj77rtZtGgRixcv5gc/+EEzt07hGg16Sd1I9sz7kAy/dJRU960o37cD0UD7ro0RUyKiIiIqevbs2VhZZlYk69Y1rb05jjzySD7zmc/UPp4+fTrl5eWUl5ezYsWKvEF/4IEHctZZZwFwwgknsHbt2rzLvvDCC3fp89xzzzFq1CgABg4cSL9+/Rqsb968eZx22mn06NGDDh06cMkllzB37lyOOuooVq5cyfXXX8/TTz9Nly5dAOjXrx9jx45l2rRpTToOvrkKGbo5HVgTEdUR8RHwBHBSnT5VwKEA6fBOF+Ct3PZUb3Yd9jGzNuSww5rW3hwdO3asvb9q1Sq+//3v8+yzz7JkyRLOPPPMvIcZ7r///rX327VrR01NTd5lH3DAAbv0ici7H1qv+vp3796dJUuWcPLJJzN58mSuvvpqAJ5++mnGjx/P888/T0VFBdu3752vKwsJ+nXAUEml6bj7SGBFnT6zgcvS+xcBz0ayBWYDo9KjcvoARwPPt0zpZlYMd94JpaU7t5WWJu170jvvvEPnzp056KCD2LBhA08//XSLP8fJJ5/M448/DsCLL76Y9xNDrqFDhzJnzhw2bdpETU0NM2bMYPjw4VRXVxMRfOlLX+L2229nwYIFbN++naqqKk477TTuueceqqur2Vp3DGwPafSom4iYJ2kmsACoARYCUyTdAVRGxGzgX4FHJa0m2ZMflc67LD1KZ3k677U+4sasbdtxdE1LHXVTqPLycvr27Uv//v054ogjGDZsWIs/x9e//nUuvfRSBgwYQHl5Of37968ddsmnd+/e3HHHHYwYMYKI4JxzzuHss89mwYIFXHnllUQEkvje975HTU0Nl1xyCe+++y4ff/wxN998M507d27xdchHTf2osjdUVFREZWVlscsw22esWLGC4447rthlFF1NTQ01NTWUlJSwatUqzjjjDFatWkX79q3rbDH5Xi9J8yOiIl//1lW9mVkRvffee4wcOZKamhoigocffrjVhfzuaPtrYGbWQrp27cr8+fOLXUaL87luzMwyzkFvZpZxDnozs4xz0JuZZZyD3syKbsSIEbv8AGrSpEn8wz/8Q4PzderUCYD169dz0UUX1bvsxg7XnjRp0k4/XvrCF77A5s2bCym9QbfddhsTJ05s9nKay0FvZkU3evRoZsyYsVPbjBkzGD16dEHzH3LIIcycOXO3n79u0D/11FN07dp1t5fX2jjozazoLrroIp588kn+8pe/ALB27VrWr1/PySefXHtse3l5Occffzy/+MUvdpl/7dq19O/fH4Bt27YxatQoBgwYwMUXX8y2bdtq+11zzTW1pzn+9re/DcDkyZNZv349p556KqeeeioAZWVlbNy4EYB7772X/v37079//9rTHK9du5bjjjuOv//7v6dfv36cccYZOz1PPosWLWLo0KEMGDCACy64gLfffrv2+fv27cuAAQNqT6j2+9//vvbiK4MHD+bdd9/d7W0LPo7ezOq44QZo6YsnDRoEaUbm1b17d4YMGcKvf/1rzjvvPGbMmMHFF1+MJEpKSpg1axYHHXQQGzduZOjQoZx77rn1XlLvwQcfpLS0lCVLlrBkyRLKy8trp91555184hOfYPv27YwcOZIlS5Zw3XXXce+99zJnzhx69Oix07Lmz5/PI488wrx584gIPvvZzzJ8+HC6devGqlWrmD59Ov/yL//Cl7/8ZX72s581eI75Sy+9lPvvv5/hw4fzrW99i9tvv51JkyZx1113sWbNGg444IDa4aKJEyfywAMPMGzYMN577z1KSkrqXW4hvEdvZq1C7vBN7rBNRHDLLbcwYMAATj/9dF5//XXeeOONepczd+7c2sAdMGAAAwYMqJ32+OOPU15ezuDBg1m2bFmjJy177rnnuOCCC+jYsSOdOnXiwgsv5A9/+AMAffr0YdCgQUDDp0OG5Bz5mzdvZvjw4QBcdtllzJ07t7bGMWPGMHXq1Npf4Q4bNoybbrqJyZMns3nz5mb/Otd79Ga2k4b2vPek888/n5tuuokFCxawbdu22j3xadOmUV1dzfz58+nQoQNlZWV5T0+cK9/e/po1a5g4cSIvvPAC3bp14/LLL290OQ2dC2zHaY4hOdVxY0M39fnlL3/J3LlzmT17Nt/5zndYtmwZEyZM4Oyzz+app55i6NCh/Pa3v+XYY4/dreWD9+jNrJXo1KkTI0aM4Ktf/epOX8Ju2bKFT37yk3To0IE5c+bw6quvNricU045pfYi4EuXLmXJkiVAcprjjh070qVLF9544w1+9atf1c7TuXPnvOPgp5xyCj//+c/ZunUr77//PrNmzeJzn/tck9etS5cudOvWrfbTwKOPPsrw4cP5+OOPee211zj11FO5++672bx5M++99x4vv/wyxx9/PDfffDMVFRW89NJLTX7OXN6jN7NWY/To0Vx44YU7HYEzZswYzjnnHCoqKhg0aFCje7bXXHMNV1xxBQMGDGDQoEEMGZJcpnrgwIEMHjyYfv367XKa43HjxnHWWWfx6U9/mjlz5tS2l5eXc/nll9cu46qrrmLw4MENDtPU5yc/+Qnjx49n69atHHHEETzyyCNs376dsWPHsmXLFiKCG2+8ka5du/LNb36TOXPm0K5dO/r27Vt7xazd5dMUm5lPU9zGNPU0xR66MTPLOAe9mVnGOejNzDLOQW9mQMOHElrrsTuvk4PezCgpKWHTpk0O+1YuIti0aVOTfynrwyvNjN69e1NVVUV1dXWxS7FGlJSU0Lt37ybN02jQSzoG+GlO0xHAtyJiUk6fbsCPgCOBD4CvRsTSdNpa4F1gO1BT3+E/ZlY8HTp0oE+fPsUuw/aQRoM+IlYCgwAktQNeB2bV6XYLsCgiLpB0LPAAMDJn+qkRsbFlSjYzs6Zo6hj9SODliKj7G+S+wH8CRMRLQJmkT7VAfWZm1kxNDfpRwPQ87YuBCwEkDQEOB3YMIgXwjKT5ksbVt2BJ4yRVSqr0OKGZWcspOOgl7Q+cC/x7nsl3Ad0kLQK+DiwEatJpwyKiHDgLuFbSKfmWHxFTIqIiIip69uzZlHUwM7MGNOWom7OABRGxy4mgI+Id4AoAJecHXZPeiIj16d83Jc0ChgBzm1m3mZkVqClDN6PJP2yDpK7pHj/AVcDciHhHUkdJndM+HYEzgKXNKdjMzJqmoD16SaXA54Grc9rGA0TEQ8BxwL9J2g4sB65Mu30KmJVeBKA98FhE/LrFqjczs0YVFPQRsRXoXqftoZz7/wUcnWe+V4CBzazRzMyawadAMDPLOAe9mVnGOejNzDLOQW9mlnEOejOzjHPQm5llnIPezCzjHPRmZhnnoDczyzgHvZlZxjnozcwyzkFvZpZxDnozs4xz0JuZZZyD3sws4xz0ZmYZ56A3M8s4B72ZWcY56M3MMs5Bb2aWcY0GvaRjJC3Kub0j6YY6fbpJmiVpiaTnJfXPmXampJWSVkuasCdWwszM6te+sQ4RsRIYBCCpHfA6MKtOt1uARRFxgaRjgQeAkWn/B4DPA1XAC5JmR8TyFlwHMzNrQFOHbkYCL0fEq3Xa+wL/CRARLwFlkj4FDAFWR8QrEfEhMAM4r5k1m5lZEzQ16EcB0/O0LwYuBJA0BDgc6A30Al7L6VeVtu1C0jhJlZIqq6urm1iWmZnVp+Cgl7Q/cC7w73km3wV0k7QI+DqwEKgBlKdv5Ft+REyJiIqIqOjZs2ehZZmZWSMaHaPPcRawICLeqDshIt4BrgCQJGBNeisFDs3p2htYv9vVmplZkzVl6GY0+YdtkNQ13eMHuAqYm4b/C8DRkvqk00cBs5tTsJmZNU1Be/SSSkmOnLk6p208QEQ8BBwH/Juk7cBy4Mp0Wo2krwFPA+2AH0XEshZdAzMza1BBQR8RW4Huddoeyrn/X8DR9cz7FPBUM2o0M7Nm8C9jzcwyzkFvZpZxDnozs4xz0JuZZZyD3sws4xz0ZmYZ56A3M8s4B72ZWcY56M3MMs5Bb2aWcQ56M7OMc9CbmWWcg97MLOMc9GZmGeegNzPLOAe9mVnGOejNzDLOQW9mlnEOejOzjHPQm5llXKNBL+kYSYtybu9IuqFOny6S/kPSYknLJF2RM217zryz98RKmJlZ/do31iEiVgKDACS1A14HZtXpdi2wPCLOkdQTWClpWkR8CGyLiEEtXLeZmRWoqUM3I4GXI+LVOu0BdJYkoBPwFlDTAvWZmVkzNTXoRwHT87T/ADgOWA+8CFwfER+n00okVUr6b0nn736pZma2OwoOekn7A+cC/55n8t8Ci4BDSIZ5fiDpoHTaYRFRAVwCTJJ0ZD3LH5e+IVRWV1c3ZR3MzKwBTdmjPwtYEBFv5Jl2BfBEJFYDa4BjASJiffr3FeB3wOB8C4+IKRFREREVPXv2bEJZZmbWkKYE/WjyD9sArCMZv0fSp4BjgFckdZN0QNreAxgGLN/9cs3MrKkaPeoGQFIp8Hng6py28QAR8RDwHeDHkl4EBNwcERslnQQ8LOljkjeVuyLCQW9mthcVFPQRsRXoXqftoZz764Ez8sz3J+D4ZtZoZmbN4F/GmpllnIPezCzjHPRmZhnnoDczyzgHvZlZxjnozcwyzkFvZpZxDnozs4xz0JuZZZyD3sws4xz0ZmYZ56A3M8s4B72ZWcYVdPbKtuKGG2DRomJXYWa2ewYNgkmTWn653qM3M8u4TO3R74l3QjOzts579GZmGeegNzPLOAe9mVnGOejNzDLOQW9mlnEOejOzjHPQm5llnIPezCzjFBHFrmEXkqqBV3dz9h7AxhYspy3zttiZt8fOvD3+Kgvb4vCI6JlvQqsM+uaQVBkRFcWuozXwttiZt8fOvD3+KuvbwkM3ZmYZ56A3M8u4LAb9lGIX0Ip4W+zM22Nn3h5/leltkbkxejMz21kW9+jNzCyHg97MLOMyE/SSzpS0UtJqSROKXU8xSTpU0hxJKyQtk3R9sWsqNkntJC2U9GSxayk2SV0lzZT0Uvpv5MRi11RMkm5M/58slTRdUkmxa2ppmQh6Se2AB4CzgL7AaEl9i1tVUdUA/xgRxwFDgWv38e0BcD2wothFtBLfB34dEccCA9mHt4ukXsB1QEVE9AfaAaOKW1XLy0TQA0OA1RHxSkR8CMwAzityTUUTERsiYkF6/12S/8i9iltV8UjqDZwN/LDYtRSbpIOAU4B/BYiIDyNic3GrKrr2wIGS2gOlwPoi19PishL0vYDXch5XsQ8HWy5JZcBgYF5xKymqScD/Bj4udiGtwBFANfBIOpT1Q0kdi11UsUTE68BEYB2wAdgSEc8Ut6qWl5WgV562ff64UUmdgJ8BN0TEO8WupxgkfRF4MyLmF7uWVqI9UA48GBGDgfeBffY7LUndSD799wEOATpKGlvcqlpeVoK+Cjg053FvMvjxqykkdQ2Y/pUAAAECSURBVCAJ+WkR8USx6ymiYcC5ktaSDOmdJmlqcUsqqiqgKiJ2fMKbSRL8+6rTgTURUR0RHwFPACcVuaYWl5WgfwE4WlIfSfuTfJkyu8g1FY0kkYzBroiIe4tdTzFFxP+JiN4RUUby7+LZiMjcHluhIuLPwGuSjkmbRgLLi1hSsa0DhkoqTf/fjCSDX063L3YBLSEiaiR9DXia5FvzH0XEsiKXVUzDgK8AL0palLbdEhFPFbEmaz2+DkxLd4peAa4ocj1FExHzJM0EFpAcrbaQDJ4OwadAMDPLuKwM3ZiZWT0c9GZmGeegNzPLOAe9mVnGOejNzDLOQW9mlnEOejOzjPv/yCOEyobyQnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "%matplotlib inline\n",
    "\n",
    "accuracy = history1.history['acc']\n",
    "val_accuracy = history1.history['val_acc']\n",
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.817276390075683 0.515\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = cnn1.evaluate(testX, testY, verbose=2)\n",
    "print(model_loss, model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - ETA: 4:02 - loss: 8.5627 - acc: 0.468 - ETA: 2:16 - loss: 7.0517 - acc: 0.562 - ETA: 1:40 - loss: 8.0590 - acc: 0.500 - ETA: 1:22 - loss: 7.9331 - acc: 0.507 - ETA: 1:11 - loss: 8.2605 - acc: 0.487 - ETA: 1:04 - loss: 8.5627 - acc: 0.468 - ETA: 59s - loss: 8.8506 - acc: 0.450 - ETA: 55s - loss: 8.7516 - acc: 0.45 - ETA: 51s - loss: 8.5068 - acc: 0.47 - ETA: 49s - loss: 8.4116 - acc: 0.47 - ETA: 46s - loss: 8.4712 - acc: 0.47 - ETA: 45s - loss: 8.3948 - acc: 0.47 - ETA: 43s - loss: 8.5627 - acc: 0.46 - ETA: 41s - loss: 8.4548 - acc: 0.47 - ETA: 40s - loss: 8.3948 - acc: 0.47 - ETA: 39s - loss: 8.4683 - acc: 0.47 - ETA: 38s - loss: 8.5924 - acc: 0.46 - ETA: 37s - loss: 8.6467 - acc: 0.46 - ETA: 36s - loss: 8.6423 - acc: 0.46 - ETA: 35s - loss: 8.5124 - acc: 0.47 - ETA: 34s - loss: 8.6107 - acc: 0.46 - ETA: 33s - loss: 8.6085 - acc: 0.46 - ETA: 32s - loss: 8.7160 - acc: 0.45 - ETA: 31s - loss: 8.7096 - acc: 0.45 - ETA: 31s - loss: 8.6836 - acc: 0.46 - ETA: 30s - loss: 8.6015 - acc: 0.46 - ETA: 29s - loss: 8.6000 - acc: 0.46 - ETA: 29s - loss: 8.6347 - acc: 0.46 - ETA: 28s - loss: 8.5627 - acc: 0.46 - ETA: 27s - loss: 8.5292 - acc: 0.47 - ETA: 27s - loss: 8.4490 - acc: 0.47 - ETA: 26s - loss: 8.4368 - acc: 0.47 - ETA: 26s - loss: 8.4559 - acc: 0.47 - ETA: 25s - loss: 8.3702 - acc: 0.48 - ETA: 25s - loss: 8.3181 - acc: 0.48 - ETA: 24s - loss: 8.3249 - acc: 0.48 - ETA: 23s - loss: 8.2905 - acc: 0.48 - ETA: 23s - loss: 8.2976 - acc: 0.48 - ETA: 22s - loss: 8.2657 - acc: 0.48 - ETA: 22s - loss: 8.2857 - acc: 0.48 - ETA: 21s - loss: 8.3048 - acc: 0.48 - ETA: 21s - loss: 8.2030 - acc: 0.49 - ETA: 20s - loss: 8.1176 - acc: 0.49 - ETA: 20s - loss: 8.1277 - acc: 0.49 - ETA: 19s - loss: 8.1262 - acc: 0.49 - ETA: 19s - loss: 8.1028 - acc: 0.49 - ETA: 19s - loss: 8.1233 - acc: 0.49 - ETA: 18s - loss: 8.1220 - acc: 0.49 - ETA: 18s - loss: 8.0796 - acc: 0.49 - ETA: 17s - loss: 8.0288 - acc: 0.50 - ETA: 17s - loss: 8.0195 - acc: 0.50 - ETA: 16s - loss: 7.9525 - acc: 0.50 - ETA: 16s - loss: 7.9450 - acc: 0.50 - ETA: 15s - loss: 7.9751 - acc: 0.50 - ETA: 15s - loss: 7.9675 - acc: 0.50 - ETA: 15s - loss: 8.0051 - acc: 0.50 - ETA: 14s - loss: 8.0414 - acc: 0.50 - ETA: 14s - loss: 8.0851 - acc: 0.49 - ETA: 13s - loss: 8.0590 - acc: 0.50 - ETA: 13s - loss: 8.0674 - acc: 0.49 - ETA: 13s - loss: 8.0343 - acc: 0.50 - ETA: 12s - loss: 8.0428 - acc: 0.50 - ETA: 12s - loss: 8.0271 - acc: 0.50 - ETA: 11s - loss: 8.0354 - acc: 0.50 - ETA: 11s - loss: 8.0590 - acc: 0.50 - ETA: 10s - loss: 8.0438 - acc: 0.50 - ETA: 10s - loss: 8.0666 - acc: 0.49 - ETA: 10s - loss: 8.0368 - acc: 0.50 - ETA: 9s - loss: 8.0152 - acc: 0.5027 - ETA: 9s - loss: 8.0015 - acc: 0.503 - ETA: 8s - loss: 7.9810 - acc: 0.504 - ETA: 8s - loss: 7.9821 - acc: 0.504 - ETA: 8s - loss: 7.9693 - acc: 0.505 - ETA: 7s - loss: 7.9433 - acc: 0.507 - ETA: 7s - loss: 7.9449 - acc: 0.507 - ETA: 6s - loss: 7.9398 - acc: 0.507 - ETA: 6s - loss: 7.9413 - acc: 0.507 - ETA: 6s - loss: 7.9364 - acc: 0.507 - ETA: 5s - loss: 7.9507 - acc: 0.506 - ETA: 5s - loss: 7.9394 - acc: 0.507 - ETA: 4s - loss: 7.9222 - acc: 0.508 - ETA: 4s - loss: 7.9178 - acc: 0.508 - ETA: 4s - loss: 7.9073 - acc: 0.509 - ETA: 3s - loss: 7.8971 - acc: 0.510 - ETA: 3s - loss: 7.9109 - acc: 0.509 - ETA: 3s - loss: 7.9536 - acc: 0.506 - ETA: 2s - loss: 7.9433 - acc: 0.507 - ETA: 2s - loss: 7.9446 - acc: 0.507 - ETA: 1s - loss: 7.9289 - acc: 0.508 - ETA: 1s - loss: 7.9359 - acc: 0.507 - ETA: 1s - loss: 7.9483 - acc: 0.506 - ETA: 0s - loss: 7.9714 - acc: 0.505 - ETA: 0s - loss: 7.9778 - acc: 0.505 - 39s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - ETA: 34s - loss: 7.0517 - acc: 0.56 - ETA: 33s - loss: 8.3109 - acc: 0.48 - ETA: 32s - loss: 7.7233 - acc: 0.52 - ETA: 32s - loss: 8.4368 - acc: 0.47 - ETA: 32s - loss: 8.3613 - acc: 0.48 - ETA: 31s - loss: 8.3948 - acc: 0.47 - ETA: 31s - loss: 8.5627 - acc: 0.46 - ETA: 31s - loss: 8.3739 - acc: 0.48 - ETA: 30s - loss: 8.2829 - acc: 0.48 - ETA: 30s - loss: 8.2605 - acc: 0.48 - ETA: 30s - loss: 8.2422 - acc: 0.48 - ETA: 29s - loss: 8.2269 - acc: 0.48 - ETA: 29s - loss: 8.1365 - acc: 0.49 - ETA: 28s - loss: 8.2389 - acc: 0.48 - ETA: 28s - loss: 8.3277 - acc: 0.48 - ETA: 28s - loss: 8.3109 - acc: 0.48 - ETA: 27s - loss: 8.3850 - acc: 0.47 - ETA: 27s - loss: 8.4508 - acc: 0.47 - ETA: 27s - loss: 8.5362 - acc: 0.47 - ETA: 26s - loss: 8.6131 - acc: 0.46 - ETA: 26s - loss: 8.5627 - acc: 0.46 - ETA: 26s - loss: 8.4941 - acc: 0.47 - ETA: 25s - loss: 8.5846 - acc: 0.46 - ETA: 25s - loss: 8.4788 - acc: 0.47 - ETA: 24s - loss: 8.4016 - acc: 0.47 - ETA: 24s - loss: 8.3690 - acc: 0.48 - ETA: 24s - loss: 8.3762 - acc: 0.48 - ETA: 23s - loss: 8.3469 - acc: 0.48 - ETA: 23s - loss: 8.3891 - acc: 0.47 - ETA: 23s - loss: 8.2773 - acc: 0.48 - ETA: 22s - loss: 8.2540 - acc: 0.48 - ETA: 22s - loss: 8.1692 - acc: 0.49 - ETA: 22s - loss: 8.1812 - acc: 0.49 - ETA: 21s - loss: 8.1035 - acc: 0.49 - ETA: 21s - loss: 8.0734 - acc: 0.49 - ETA: 21s - loss: 8.1150 - acc: 0.49 - ETA: 20s - loss: 8.1135 - acc: 0.49 - ETA: 20s - loss: 8.1518 - acc: 0.49 - ETA: 19s - loss: 8.1365 - acc: 0.49 - ETA: 19s - loss: 8.1094 - acc: 0.49 - ETA: 19s - loss: 8.1696 - acc: 0.49 - ETA: 18s - loss: 8.1910 - acc: 0.49 - ETA: 18s - loss: 8.1410 - acc: 0.49 - ETA: 18s - loss: 8.1850 - acc: 0.49 - ETA: 17s - loss: 8.1598 - acc: 0.49 - ETA: 17s - loss: 8.2014 - acc: 0.49 - ETA: 17s - loss: 8.2305 - acc: 0.48 - ETA: 16s - loss: 8.2374 - acc: 0.48 - ETA: 16s - loss: 8.2544 - acc: 0.48 - ETA: 15s - loss: 8.2505 - acc: 0.48 - ETA: 15s - loss: 8.2467 - acc: 0.48 - ETA: 15s - loss: 8.2431 - acc: 0.48 - ETA: 14s - loss: 8.1921 - acc: 0.49 - ETA: 14s - loss: 8.1990 - acc: 0.49 - ETA: 14s - loss: 8.1964 - acc: 0.49 - ETA: 13s - loss: 8.1850 - acc: 0.49 - ETA: 13s - loss: 8.2004 - acc: 0.49 - ETA: 13s - loss: 8.1806 - acc: 0.49 - ETA: 12s - loss: 8.1530 - acc: 0.49 - ETA: 12s - loss: 8.1682 - acc: 0.49 - ETA: 11s - loss: 8.1416 - acc: 0.49 - ETA: 11s - loss: 8.1159 - acc: 0.49 - ETA: 11s - loss: 8.0750 - acc: 0.49 - ETA: 10s - loss: 8.0590 - acc: 0.50 - ETA: 10s - loss: 8.0203 - acc: 0.50 - ETA: 10s - loss: 8.0438 - acc: 0.50 - ETA: 9s - loss: 8.0741 - acc: 0.4991 - ETA: 9s - loss: 8.0665 - acc: 0.499 - ETA: 9s - loss: 8.1028 - acc: 0.497 - ETA: 8s - loss: 8.0806 - acc: 0.498 - ETA: 8s - loss: 8.0803 - acc: 0.498 - ETA: 7s - loss: 8.1220 - acc: 0.496 - ETA: 7s - loss: 8.1280 - acc: 0.495 - ETA: 7s - loss: 8.1135 - acc: 0.496 - ETA: 6s - loss: 8.0993 - acc: 0.497 - ETA: 6s - loss: 8.0988 - acc: 0.497 - ETA: 6s - loss: 8.0852 - acc: 0.498 - ETA: 5s - loss: 8.0526 - acc: 0.500 - ETA: 5s - loss: 8.0208 - acc: 0.502 - ETA: 5s - loss: 8.0276 - acc: 0.502 - ETA: 4s - loss: 8.0155 - acc: 0.502 - ETA: 4s - loss: 8.0160 - acc: 0.502 - ETA: 3s - loss: 8.0166 - acc: 0.502 - ETA: 3s - loss: 7.9931 - acc: 0.504 - ETA: 3s - loss: 7.9939 - acc: 0.504 - ETA: 2s - loss: 7.9771 - acc: 0.505 - ETA: 2s - loss: 7.9664 - acc: 0.505 - ETA: 2s - loss: 7.9617 - acc: 0.506 - ETA: 1s - loss: 7.9572 - acc: 0.506 - ETA: 1s - loss: 7.9807 - acc: 0.504 - ETA: 1s - loss: 7.9982 - acc: 0.503 - ETA: 0s - loss: 7.9824 - acc: 0.504 - ETA: 0s - loss: 7.9886 - acc: 0.504 - 37s 12ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 34s - loss: 5.0369 - acc: 0.68 - ETA: 33s - loss: 6.7998 - acc: 0.57 - ETA: 32s - loss: 6.7159 - acc: 0.58 - ETA: 32s - loss: 6.9257 - acc: 0.57 - ETA: 32s - loss: 6.8502 - acc: 0.57 - ETA: 32s - loss: 7.2196 - acc: 0.55 - ETA: 31s - loss: 7.3395 - acc: 0.54 - ETA: 31s - loss: 7.6183 - acc: 0.52 - ETA: 31s - loss: 7.4994 - acc: 0.53 - ETA: 30s - loss: 7.6561 - acc: 0.52 - ETA: 30s - loss: 7.8759 - acc: 0.51 - ETA: 29s - loss: 7.8072 - acc: 0.51 - ETA: 29s - loss: 7.8266 - acc: 0.51 - ETA: 29s - loss: 7.8792 - acc: 0.51 - ETA: 28s - loss: 7.9583 - acc: 0.50 - ETA: 28s - loss: 7.9331 - acc: 0.50 - ETA: 28s - loss: 7.9998 - acc: 0.50 - ETA: 27s - loss: 8.0311 - acc: 0.50 - ETA: 27s - loss: 8.1916 - acc: 0.49 - ETA: 27s - loss: 8.1346 - acc: 0.49 - ETA: 26s - loss: 8.1550 - acc: 0.49 - ETA: 26s - loss: 8.1506 - acc: 0.49 - ETA: 25s - loss: 8.0590 - acc: 0.50 - ETA: 25s - loss: 8.1010 - acc: 0.49 - ETA: 25s - loss: 8.0993 - acc: 0.49 - ETA: 24s - loss: 8.0590 - acc: 0.50 - ETA: 24s - loss: 8.0964 - acc: 0.49 - ETA: 23s - loss: 8.0770 - acc: 0.49 - ETA: 23s - loss: 8.1285 - acc: 0.49 - ETA: 23s - loss: 8.0926 - acc: 0.49 - ETA: 22s - loss: 8.0428 - acc: 0.50 - ETA: 22s - loss: 7.9646 - acc: 0.50 - ETA: 21s - loss: 7.9064 - acc: 0.50 - ETA: 21s - loss: 7.9702 - acc: 0.50 - ETA: 21s - loss: 7.9871 - acc: 0.50 - ETA: 20s - loss: 8.0171 - acc: 0.50 - ETA: 20s - loss: 8.0318 - acc: 0.50 - ETA: 20s - loss: 8.0458 - acc: 0.50 - ETA: 19s - loss: 8.0720 - acc: 0.49 - ETA: 19s - loss: 8.1220 - acc: 0.49 - ETA: 19s - loss: 8.1082 - acc: 0.49 - ETA: 18s - loss: 8.0710 - acc: 0.49 - ETA: 18s - loss: 8.1059 - acc: 0.49 - ETA: 17s - loss: 8.1163 - acc: 0.49 - ETA: 17s - loss: 8.1262 - acc: 0.49 - ETA: 17s - loss: 8.1357 - acc: 0.49 - ETA: 16s - loss: 8.1341 - acc: 0.49 - ETA: 16s - loss: 8.1220 - acc: 0.49 - ETA: 16s - loss: 8.1721 - acc: 0.49 - ETA: 15s - loss: 8.1497 - acc: 0.49 - ETA: 15s - loss: 8.1479 - acc: 0.49 - ETA: 14s - loss: 8.1656 - acc: 0.49 - ETA: 14s - loss: 8.1731 - acc: 0.49 - ETA: 14s - loss: 8.1990 - acc: 0.49 - ETA: 13s - loss: 8.1506 - acc: 0.49 - ETA: 13s - loss: 8.1310 - acc: 0.49 - ETA: 13s - loss: 8.1386 - acc: 0.49 - ETA: 12s - loss: 8.1112 - acc: 0.49 - ETA: 12s - loss: 8.1017 - acc: 0.49 - ETA: 12s - loss: 8.0926 - acc: 0.49 - ETA: 11s - loss: 8.0756 - acc: 0.49 - ETA: 11s - loss: 8.0997 - acc: 0.49 - ETA: 11s - loss: 8.1150 - acc: 0.49 - ETA: 10s - loss: 8.1220 - acc: 0.49 - ETA: 10s - loss: 8.1055 - acc: 0.49 - ETA: 9s - loss: 8.0819 - acc: 0.4986 - ETA: 9s - loss: 8.0966 - acc: 0.497 - ETA: 9s - loss: 8.1109 - acc: 0.496 - ETA: 8s - loss: 8.1028 - acc: 0.497 - ETA: 8s - loss: 8.0519 - acc: 0.500 - ETA: 8s - loss: 8.0590 - acc: 0.500 - ETA: 7s - loss: 8.0800 - acc: 0.498 - ETA: 7s - loss: 8.0590 - acc: 0.500 - ETA: 7s - loss: 8.0318 - acc: 0.501 - ETA: 6s - loss: 8.0188 - acc: 0.502 - ETA: 6s - loss: 7.9928 - acc: 0.504 - ETA: 5s - loss: 7.9936 - acc: 0.504 - ETA: 5s - loss: 7.9945 - acc: 0.504 - ETA: 5s - loss: 7.9825 - acc: 0.504 - ETA: 4s - loss: 7.9709 - acc: 0.505 - ETA: 4s - loss: 7.9782 - acc: 0.505 - ETA: 4s - loss: 7.9976 - acc: 0.503 - ETA: 3s - loss: 7.9984 - acc: 0.503 - ETA: 3s - loss: 8.0051 - acc: 0.503 - ETA: 3s - loss: 7.9879 - acc: 0.504 - ETA: 2s - loss: 7.9771 - acc: 0.505 - ETA: 2s - loss: 7.9780 - acc: 0.505 - ETA: 2s - loss: 7.9617 - acc: 0.506 - ETA: 1s - loss: 7.9459 - acc: 0.507 - ETA: 1s - loss: 7.9415 - acc: 0.507 - ETA: 0s - loss: 7.9262 - acc: 0.508 - ETA: 0s - loss: 7.9331 - acc: 0.507 - ETA: 0s - loss: 7.9561 - acc: 0.506 - 36s 12ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 8.0590 - acc: 0.50 - ETA: 32s - loss: 9.0664 - acc: 0.43 - ETA: 32s - loss: 8.8985 - acc: 0.44 - ETA: 31s - loss: 8.1850 - acc: 0.49 - ETA: 31s - loss: 8.3613 - acc: 0.48 - ETA: 30s - loss: 8.1430 - acc: 0.49 - ETA: 30s - loss: 7.8432 - acc: 0.51 - ETA: 30s - loss: 7.9961 - acc: 0.50 - ETA: 29s - loss: 7.8912 - acc: 0.51 - ETA: 29s - loss: 7.8576 - acc: 0.51 - ETA: 29s - loss: 7.7385 - acc: 0.51 - ETA: 28s - loss: 7.7233 - acc: 0.52 - ETA: 28s - loss: 7.9041 - acc: 0.50 - ETA: 28s - loss: 7.8072 - acc: 0.51 - ETA: 27s - loss: 7.8576 - acc: 0.51 - ETA: 27s - loss: 7.6813 - acc: 0.52 - ETA: 27s - loss: 7.6146 - acc: 0.52 - ETA: 26s - loss: 7.6113 - acc: 0.52 - ETA: 26s - loss: 7.5023 - acc: 0.53 - ETA: 26s - loss: 7.6561 - acc: 0.52 - ETA: 25s - loss: 7.7233 - acc: 0.52 - ETA: 25s - loss: 7.6240 - acc: 0.52 - ETA: 25s - loss: 7.6868 - acc: 0.52 - ETA: 24s - loss: 7.7233 - acc: 0.52 - ETA: 24s - loss: 7.6762 - acc: 0.52 - ETA: 24s - loss: 7.7297 - acc: 0.52 - ETA: 23s - loss: 7.7979 - acc: 0.51 - ETA: 23s - loss: 7.7712 - acc: 0.51 - ETA: 23s - loss: 7.8159 - acc: 0.51 - ETA: 22s - loss: 7.8576 - acc: 0.51 - ETA: 22s - loss: 7.7503 - acc: 0.51 - ETA: 21s - loss: 7.7128 - acc: 0.52 - ETA: 21s - loss: 7.7233 - acc: 0.52 - ETA: 21s - loss: 7.6887 - acc: 0.52 - ETA: 20s - loss: 7.7137 - acc: 0.52 - ETA: 20s - loss: 7.7652 - acc: 0.51 - ETA: 20s - loss: 7.8004 - acc: 0.51 - ETA: 19s - loss: 7.7542 - acc: 0.51 - ETA: 19s - loss: 7.6974 - acc: 0.52 - ETA: 19s - loss: 7.7568 - acc: 0.51 - ETA: 18s - loss: 7.7642 - acc: 0.51 - ETA: 18s - loss: 7.7233 - acc: 0.52 - ETA: 18s - loss: 7.7662 - acc: 0.51 - ETA: 17s - loss: 7.7729 - acc: 0.51 - ETA: 17s - loss: 7.8016 - acc: 0.51 - ETA: 16s - loss: 7.8182 - acc: 0.51 - ETA: 16s - loss: 7.8018 - acc: 0.51 - ETA: 16s - loss: 7.8177 - acc: 0.51 - ETA: 15s - loss: 7.7712 - acc: 0.51 - ETA: 15s - loss: 7.7871 - acc: 0.51 - ETA: 15s - loss: 7.8023 - acc: 0.51 - ETA: 14s - loss: 7.8847 - acc: 0.51 - ETA: 14s - loss: 7.8595 - acc: 0.51 - ETA: 14s - loss: 7.8632 - acc: 0.51 - ETA: 13s - loss: 7.8850 - acc: 0.51 - ETA: 13s - loss: 7.9241 - acc: 0.50 - ETA: 13s - loss: 7.9442 - acc: 0.50 - ETA: 12s - loss: 7.9548 - acc: 0.50 - ETA: 12s - loss: 7.9822 - acc: 0.50 - ETA: 12s - loss: 7.9751 - acc: 0.50 - ETA: 11s - loss: 7.9600 - acc: 0.50 - ETA: 11s - loss: 7.9453 - acc: 0.50 - ETA: 10s - loss: 7.9471 - acc: 0.50 - ETA: 10s - loss: 7.9489 - acc: 0.50 - ETA: 10s - loss: 7.9583 - acc: 0.50 - ETA: 9s - loss: 7.9598 - acc: 0.5062 - ETA: 9s - loss: 7.9688 - acc: 0.505 - ETA: 9s - loss: 7.9479 - acc: 0.506 - ETA: 8s - loss: 7.9714 - acc: 0.505 - ETA: 8s - loss: 7.9799 - acc: 0.504 - ETA: 8s - loss: 7.9739 - acc: 0.505 - ETA: 7s - loss: 8.0171 - acc: 0.502 - ETA: 7s - loss: 8.0245 - acc: 0.502 - ETA: 7s - loss: 8.0182 - acc: 0.502 - ETA: 6s - loss: 7.9986 - acc: 0.503 - ETA: 6s - loss: 8.0060 - acc: 0.503 - ETA: 5s - loss: 8.0133 - acc: 0.502 - ETA: 5s - loss: 8.0397 - acc: 0.501 - ETA: 5s - loss: 8.0144 - acc: 0.502 - ETA: 4s - loss: 8.0339 - acc: 0.501 - ETA: 4s - loss: 8.0280 - acc: 0.501 - ETA: 4s - loss: 7.9915 - acc: 0.504 - ETA: 3s - loss: 7.9255 - acc: 0.508 - ETA: 3s - loss: 7.9211 - acc: 0.508 - ETA: 3s - loss: 7.9228 - acc: 0.508 - ETA: 2s - loss: 7.9361 - acc: 0.507 - ETA: 2s - loss: 7.9490 - acc: 0.506 - ETA: 2s - loss: 7.9446 - acc: 0.507 - ETA: 1s - loss: 7.9289 - acc: 0.508 - ETA: 1s - loss: 7.9359 - acc: 0.507 - ETA: 0s - loss: 7.9207 - acc: 0.508 - ETA: 0s - loss: 7.9386 - acc: 0.507 - ETA: 0s - loss: 7.9561 - acc: 0.506 - 36s 12ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 32s - loss: 8.5627 - acc: 0.46 - ETA: 32s - loss: 7.0517 - acc: 0.56 - ETA: 31s - loss: 7.7233 - acc: 0.52 - ETA: 31s - loss: 8.1850 - acc: 0.49 - ETA: 31s - loss: 8.0590 - acc: 0.50 - ETA: 30s - loss: 7.9751 - acc: 0.50 - ETA: 30s - loss: 7.8432 - acc: 0.51 - ETA: 30s - loss: 7.9331 - acc: 0.50 - ETA: 29s - loss: 8.0590 - acc: 0.50 - ETA: 29s - loss: 8.0590 - acc: 0.50 - ETA: 29s - loss: 8.1048 - acc: 0.49 - ETA: 28s - loss: 8.0171 - acc: 0.50 - ETA: 28s - loss: 8.0978 - acc: 0.49 - ETA: 28s - loss: 8.1310 - acc: 0.49 - ETA: 27s - loss: 8.1598 - acc: 0.49 - ETA: 27s - loss: 8.1850 - acc: 0.49 - ETA: 27s - loss: 8.1479 - acc: 0.49 - ETA: 26s - loss: 8.2549 - acc: 0.48 - ETA: 26s - loss: 8.2446 - acc: 0.48 - ETA: 25s - loss: 8.2605 - acc: 0.48 - ETA: 25s - loss: 8.2509 - acc: 0.48 - ETA: 25s - loss: 8.3567 - acc: 0.48 - ETA: 24s - loss: 8.3875 - acc: 0.47 - ETA: 24s - loss: 8.4368 - acc: 0.47 - ETA: 24s - loss: 8.5627 - acc: 0.46 - ETA: 24s - loss: 8.5240 - acc: 0.47 - ETA: 23s - loss: 8.4881 - acc: 0.47 - ETA: 23s - loss: 8.4908 - acc: 0.47 - ETA: 23s - loss: 8.4238 - acc: 0.47 - ETA: 22s - loss: 8.4956 - acc: 0.47 - ETA: 22s - loss: 8.4815 - acc: 0.47 - ETA: 22s - loss: 8.4368 - acc: 0.47 - ETA: 21s - loss: 8.3948 - acc: 0.47 - ETA: 21s - loss: 8.3850 - acc: 0.47 - ETA: 21s - loss: 8.3469 - acc: 0.48 - ETA: 20s - loss: 8.4088 - acc: 0.47 - ETA: 20s - loss: 8.4266 - acc: 0.47 - ETA: 20s - loss: 8.3639 - acc: 0.48 - ETA: 19s - loss: 8.2915 - acc: 0.48 - ETA: 19s - loss: 8.2605 - acc: 0.48 - ETA: 19s - loss: 8.3048 - acc: 0.48 - ETA: 18s - loss: 8.2869 - acc: 0.48 - ETA: 18s - loss: 8.3167 - acc: 0.48 - ETA: 18s - loss: 8.3681 - acc: 0.48 - ETA: 17s - loss: 8.3389 - acc: 0.48 - ETA: 17s - loss: 8.3218 - acc: 0.48 - ETA: 16s - loss: 8.3484 - acc: 0.48 - ETA: 16s - loss: 8.3109 - acc: 0.48 - ETA: 16s - loss: 8.2955 - acc: 0.48 - ETA: 15s - loss: 8.2505 - acc: 0.48 - ETA: 15s - loss: 8.2171 - acc: 0.49 - ETA: 15s - loss: 8.1850 - acc: 0.49 - ETA: 14s - loss: 8.1636 - acc: 0.49 - ETA: 14s - loss: 8.1523 - acc: 0.49 - ETA: 14s - loss: 8.2239 - acc: 0.48 - ETA: 13s - loss: 8.2299 - acc: 0.48 - ETA: 13s - loss: 8.1739 - acc: 0.49 - ETA: 12s - loss: 8.1546 - acc: 0.49 - ETA: 12s - loss: 8.1188 - acc: 0.49 - ETA: 12s - loss: 8.1010 - acc: 0.49 - ETA: 11s - loss: 8.1168 - acc: 0.49 - ETA: 11s - loss: 8.1078 - acc: 0.49 - ETA: 11s - loss: 8.1070 - acc: 0.49 - ETA: 10s - loss: 8.1141 - acc: 0.49 - ETA: 10s - loss: 8.1133 - acc: 0.49 - ETA: 10s - loss: 8.0743 - acc: 0.49 - ETA: 9s - loss: 8.0966 - acc: 0.4977 - ETA: 9s - loss: 8.0665 - acc: 0.499 - ETA: 8s - loss: 8.0882 - acc: 0.498 - ETA: 8s - loss: 8.0878 - acc: 0.498 - ETA: 8s - loss: 8.0874 - acc: 0.498 - ETA: 7s - loss: 8.0660 - acc: 0.499 - ETA: 7s - loss: 8.1004 - acc: 0.497 - ETA: 7s - loss: 8.1067 - acc: 0.497 - ETA: 6s - loss: 8.1061 - acc: 0.497 - ETA: 6s - loss: 8.1121 - acc: 0.496 - ETA: 6s - loss: 8.1310 - acc: 0.495 - ETA: 5s - loss: 8.1043 - acc: 0.497 - ETA: 5s - loss: 8.0718 - acc: 0.499 - ETA: 4s - loss: 8.0528 - acc: 0.500 - ETA: 4s - loss: 8.0280 - acc: 0.501 - ETA: 4s - loss: 7.9915 - acc: 0.504 - ETA: 3s - loss: 7.9802 - acc: 0.504 - ETA: 3s - loss: 7.9751 - acc: 0.505 - ETA: 3s - loss: 7.9465 - acc: 0.507 - ETA: 2s - loss: 7.9653 - acc: 0.505 - ETA: 2s - loss: 7.9780 - acc: 0.505 - ETA: 2s - loss: 7.9732 - acc: 0.505 - ETA: 1s - loss: 7.9855 - acc: 0.504 - ETA: 1s - loss: 7.9695 - acc: 0.505 - ETA: 0s - loss: 7.9926 - acc: 0.504 - ETA: 0s - loss: 7.9769 - acc: 0.505 - ETA: 0s - loss: 7.9724 - acc: 0.505 - 36s 12ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 7.5554 - acc: 0.53 - ETA: 33s - loss: 7.0517 - acc: 0.56 - ETA: 32s - loss: 7.3875 - acc: 0.54 - ETA: 32s - loss: 6.9257 - acc: 0.57 - ETA: 31s - loss: 7.7568 - acc: 0.51 - ETA: 31s - loss: 7.3875 - acc: 0.54 - ETA: 30s - loss: 7.7712 - acc: 0.51 - ETA: 30s - loss: 7.4924 - acc: 0.53 - ETA: 30s - loss: 7.4994 - acc: 0.53 - ETA: 29s - loss: 7.6057 - acc: 0.52 - ETA: 29s - loss: 7.5096 - acc: 0.53 - ETA: 29s - loss: 7.5973 - acc: 0.52 - ETA: 28s - loss: 7.4779 - acc: 0.53 - ETA: 28s - loss: 7.3755 - acc: 0.54 - ETA: 28s - loss: 7.3539 - acc: 0.54 - ETA: 27s - loss: 7.3665 - acc: 0.54 - ETA: 27s - loss: 7.3776 - acc: 0.54 - ETA: 27s - loss: 7.4154 - acc: 0.53 - ETA: 26s - loss: 7.3698 - acc: 0.54 - ETA: 26s - loss: 7.4043 - acc: 0.54 - ETA: 26s - loss: 7.5074 - acc: 0.53 - ETA: 25s - loss: 7.5325 - acc: 0.53 - ETA: 25s - loss: 7.7087 - acc: 0.52 - ETA: 25s - loss: 7.5973 - acc: 0.52 - ETA: 24s - loss: 7.5957 - acc: 0.52 - ETA: 24s - loss: 7.6135 - acc: 0.52 - ETA: 24s - loss: 7.6486 - acc: 0.52 - ETA: 23s - loss: 7.6093 - acc: 0.52 - ETA: 23s - loss: 7.5901 - acc: 0.52 - ETA: 23s - loss: 7.6225 - acc: 0.52 - ETA: 23s - loss: 7.6691 - acc: 0.52 - ETA: 22s - loss: 7.6970 - acc: 0.52 - ETA: 22s - loss: 7.6927 - acc: 0.52 - ETA: 22s - loss: 7.7331 - acc: 0.52 - ETA: 21s - loss: 7.7137 - acc: 0.52 - ETA: 21s - loss: 7.7652 - acc: 0.51 - ETA: 21s - loss: 7.7323 - acc: 0.52 - ETA: 20s - loss: 7.7144 - acc: 0.52 - ETA: 20s - loss: 7.7362 - acc: 0.52 - ETA: 19s - loss: 7.7694 - acc: 0.51 - ETA: 19s - loss: 7.7765 - acc: 0.51 - ETA: 19s - loss: 7.8192 - acc: 0.51 - ETA: 19s - loss: 7.8248 - acc: 0.51 - ETA: 18s - loss: 7.8644 - acc: 0.51 - ETA: 18s - loss: 7.8912 - acc: 0.51 - ETA: 17s - loss: 7.8620 - acc: 0.51 - ETA: 17s - loss: 7.8769 - acc: 0.51 - ETA: 17s - loss: 7.9016 - acc: 0.50 - ETA: 16s - loss: 7.9151 - acc: 0.50 - ETA: 16s - loss: 7.8878 - acc: 0.51 - ETA: 16s - loss: 7.9208 - acc: 0.50 - ETA: 15s - loss: 7.9719 - acc: 0.50 - ETA: 15s - loss: 7.9450 - acc: 0.50 - ETA: 15s - loss: 7.9378 - acc: 0.50 - ETA: 14s - loss: 7.9583 - acc: 0.50 - ETA: 14s - loss: 7.9871 - acc: 0.50 - ETA: 14s - loss: 7.9795 - acc: 0.50 - ETA: 13s - loss: 7.9462 - acc: 0.50 - ETA: 13s - loss: 7.9310 - acc: 0.50 - ETA: 13s - loss: 7.9163 - acc: 0.50 - ETA: 12s - loss: 7.9187 - acc: 0.50 - ETA: 12s - loss: 7.9128 - acc: 0.50 - ETA: 11s - loss: 7.9231 - acc: 0.50 - ETA: 11s - loss: 7.9489 - acc: 0.50 - ETA: 11s - loss: 7.9506 - acc: 0.50 - ETA: 10s - loss: 7.9446 - acc: 0.50 - ETA: 10s - loss: 7.9914 - acc: 0.50 - ETA: 9s - loss: 8.0146 - acc: 0.5028 - ETA: 9s - loss: 8.0225 - acc: 0.502 - ETA: 9s - loss: 7.9943 - acc: 0.504 - ETA: 8s - loss: 7.9881 - acc: 0.504 - ETA: 8s - loss: 7.9821 - acc: 0.504 - ETA: 8s - loss: 7.9969 - acc: 0.503 - ETA: 7s - loss: 7.9774 - acc: 0.505 - ETA: 7s - loss: 7.9650 - acc: 0.505 - ETA: 6s - loss: 7.9530 - acc: 0.506 - ETA: 6s - loss: 7.9348 - acc: 0.507 - ETA: 6s - loss: 7.8976 - acc: 0.510 - ETA: 5s - loss: 7.9188 - acc: 0.508 - ETA: 5s - loss: 7.9394 - acc: 0.507 - ETA: 4s - loss: 7.9471 - acc: 0.506 - ETA: 4s - loss: 7.9423 - acc: 0.507 - ETA: 4s - loss: 7.9437 - acc: 0.507 - ETA: 3s - loss: 7.9331 - acc: 0.507 - ETA: 3s - loss: 7.9465 - acc: 0.507 - ETA: 3s - loss: 7.9536 - acc: 0.506 - ETA: 2s - loss: 7.9375 - acc: 0.507 - ETA: 2s - loss: 7.9274 - acc: 0.508 - ETA: 1s - loss: 7.9402 - acc: 0.507 - ETA: 1s - loss: 7.9359 - acc: 0.507 - ETA: 1s - loss: 7.9428 - acc: 0.507 - ETA: 0s - loss: 7.9386 - acc: 0.507 - ETA: 0s - loss: 7.9561 - acc: 0.506 - 39s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 39s - loss: 7.0517 - acc: 0.56 - ETA: 38s - loss: 6.2961 - acc: 0.60 - ETA: 38s - loss: 6.8838 - acc: 0.57 - ETA: 38s - loss: 6.4221 - acc: 0.60 - ETA: 38s - loss: 6.9509 - acc: 0.56 - ETA: 36s - loss: 7.1356 - acc: 0.55 - ETA: 35s - loss: 7.1236 - acc: 0.55 - ETA: 35s - loss: 6.9257 - acc: 0.57 - ETA: 34s - loss: 7.2196 - acc: 0.55 - ETA: 33s - loss: 7.2531 - acc: 0.55 - ETA: 33s - loss: 7.3722 - acc: 0.54 - ETA: 33s - loss: 7.3035 - acc: 0.54 - ETA: 32s - loss: 7.3229 - acc: 0.54 - ETA: 32s - loss: 7.4834 - acc: 0.53 - ETA: 32s - loss: 7.4546 - acc: 0.53 - ETA: 31s - loss: 7.3350 - acc: 0.54 - ETA: 31s - loss: 7.3183 - acc: 0.54 - ETA: 30s - loss: 7.2196 - acc: 0.55 - ETA: 30s - loss: 7.2637 - acc: 0.54 - ETA: 29s - loss: 7.2280 - acc: 0.55 - ETA: 28s - loss: 7.3635 - acc: 0.54 - ETA: 28s - loss: 7.3722 - acc: 0.54 - ETA: 27s - loss: 7.4678 - acc: 0.53 - ETA: 27s - loss: 7.4294 - acc: 0.53 - ETA: 27s - loss: 7.4345 - acc: 0.53 - ETA: 26s - loss: 7.5360 - acc: 0.53 - ETA: 26s - loss: 7.5554 - acc: 0.53 - ETA: 25s - loss: 7.5014 - acc: 0.53 - ETA: 25s - loss: 7.5206 - acc: 0.53 - ETA: 24s - loss: 7.5554 - acc: 0.53 - ETA: 24s - loss: 7.5391 - acc: 0.53 - ETA: 23s - loss: 7.4767 - acc: 0.53 - ETA: 23s - loss: 7.4943 - acc: 0.53 - ETA: 23s - loss: 7.4961 - acc: 0.53 - ETA: 22s - loss: 7.5122 - acc: 0.53 - ETA: 22s - loss: 7.4854 - acc: 0.53 - ETA: 21s - loss: 7.5690 - acc: 0.53 - ETA: 21s - loss: 7.5288 - acc: 0.53 - ETA: 20s - loss: 7.5295 - acc: 0.53 - ETA: 20s - loss: 7.5428 - acc: 0.53 - ETA: 20s - loss: 7.5062 - acc: 0.53 - ETA: 19s - loss: 7.5314 - acc: 0.53 - ETA: 19s - loss: 7.5554 - acc: 0.53 - ETA: 18s - loss: 7.5554 - acc: 0.53 - ETA: 18s - loss: 7.5442 - acc: 0.53 - ETA: 18s - loss: 7.5882 - acc: 0.52 - ETA: 17s - loss: 7.6197 - acc: 0.52 - ETA: 17s - loss: 7.6288 - acc: 0.52 - ETA: 16s - loss: 7.6376 - acc: 0.52 - ETA: 16s - loss: 7.6662 - acc: 0.52 - ETA: 16s - loss: 7.6837 - acc: 0.52 - ETA: 15s - loss: 7.7297 - acc: 0.52 - ETA: 15s - loss: 7.7739 - acc: 0.51 - ETA: 15s - loss: 7.7699 - acc: 0.51 - ETA: 14s - loss: 7.7385 - acc: 0.51 - ETA: 14s - loss: 7.7352 - acc: 0.52 - ETA: 14s - loss: 7.7233 - acc: 0.52 - ETA: 13s - loss: 7.7638 - acc: 0.51 - ETA: 13s - loss: 7.7859 - acc: 0.51 - ETA: 13s - loss: 7.8072 - acc: 0.51 - ETA: 12s - loss: 7.8031 - acc: 0.51 - ETA: 12s - loss: 7.8153 - acc: 0.51 - ETA: 11s - loss: 7.8352 - acc: 0.51 - ETA: 11s - loss: 7.8387 - acc: 0.51 - ETA: 11s - loss: 7.8653 - acc: 0.51 - ETA: 10s - loss: 7.8988 - acc: 0.50 - ETA: 10s - loss: 7.8786 - acc: 0.51 - ETA: 10s - loss: 7.9183 - acc: 0.50 - ETA: 9s - loss: 7.9204 - acc: 0.5086 - ETA: 9s - loss: 7.9655 - acc: 0.505 - ETA: 8s - loss: 7.9739 - acc: 0.505 - ETA: 8s - loss: 8.0031 - acc: 0.503 - ETA: 8s - loss: 8.0245 - acc: 0.502 - ETA: 7s - loss: 8.0182 - acc: 0.502 - ETA: 7s - loss: 8.0188 - acc: 0.502 - ETA: 7s - loss: 8.0259 - acc: 0.502 - ETA: 6s - loss: 8.0002 - acc: 0.503 - ETA: 6s - loss: 8.0332 - acc: 0.501 - ETA: 5s - loss: 8.0208 - acc: 0.502 - ETA: 5s - loss: 8.0213 - acc: 0.502 - ETA: 5s - loss: 8.0217 - acc: 0.502 - ETA: 4s - loss: 8.0283 - acc: 0.501 - ETA: 4s - loss: 8.0226 - acc: 0.502 - ETA: 3s - loss: 8.0231 - acc: 0.502 - ETA: 3s - loss: 7.9998 - acc: 0.503 - ETA: 3s - loss: 7.9771 - acc: 0.505 - ETA: 2s - loss: 7.9722 - acc: 0.505 - ETA: 2s - loss: 7.9675 - acc: 0.505 - ETA: 1s - loss: 7.9515 - acc: 0.506 - ETA: 1s - loss: 7.9695 - acc: 0.505 - ETA: 1s - loss: 7.9816 - acc: 0.504 - ETA: 0s - loss: 7.9769 - acc: 0.505 - ETA: 0s - loss: 7.9778 - acc: 0.505 - 41s 14ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - ETA: 38s - loss: 7.0517 - acc: 0.56 - ETA: 41s - loss: 7.8072 - acc: 0.51 - ETA: 42s - loss: 8.3948 - acc: 0.47 - ETA: 41s - loss: 8.1850 - acc: 0.49 - ETA: 40s - loss: 8.5627 - acc: 0.46 - ETA: 39s - loss: 8.0590 - acc: 0.50 - ETA: 40s - loss: 7.9871 - acc: 0.50 - ETA: 39s - loss: 7.8072 - acc: 0.51 - ETA: 38s - loss: 7.8352 - acc: 0.51 - ETA: 38s - loss: 7.8072 - acc: 0.51 - ETA: 37s - loss: 7.9217 - acc: 0.50 - ETA: 37s - loss: 7.8072 - acc: 0.51 - ETA: 36s - loss: 7.9816 - acc: 0.50 - ETA: 35s - loss: 8.1310 - acc: 0.49 - ETA: 35s - loss: 8.0926 - acc: 0.49 - ETA: 34s - loss: 8.0276 - acc: 0.50 - ETA: 34s - loss: 8.0294 - acc: 0.50 - ETA: 34s - loss: 8.1150 - acc: 0.49 - ETA: 34s - loss: 8.1916 - acc: 0.49 - ETA: 34s - loss: 8.1346 - acc: 0.49 - ETA: 33s - loss: 8.0830 - acc: 0.49 - ETA: 33s - loss: 8.1048 - acc: 0.49 - ETA: 33s - loss: 8.1028 - acc: 0.49 - ETA: 32s - loss: 8.2269 - acc: 0.48 - ETA: 32s - loss: 8.1396 - acc: 0.49 - ETA: 31s - loss: 8.1172 - acc: 0.49 - ETA: 31s - loss: 8.0777 - acc: 0.49 - ETA: 30s - loss: 8.0411 - acc: 0.50 - ETA: 30s - loss: 8.0069 - acc: 0.50 - ETA: 30s - loss: 7.9247 - acc: 0.50 - ETA: 29s - loss: 7.8641 - acc: 0.51 - ETA: 29s - loss: 7.8387 - acc: 0.51 - ETA: 28s - loss: 7.8454 - acc: 0.51 - ETA: 28s - loss: 7.8516 - acc: 0.51 - ETA: 27s - loss: 7.8288 - acc: 0.51 - ETA: 27s - loss: 7.8772 - acc: 0.51 - ETA: 26s - loss: 7.8276 - acc: 0.51 - ETA: 26s - loss: 7.8470 - acc: 0.51 - ETA: 25s - loss: 7.7878 - acc: 0.51 - ETA: 25s - loss: 7.8072 - acc: 0.51 - ETA: 24s - loss: 7.7888 - acc: 0.51 - ETA: 23s - loss: 7.8072 - acc: 0.51 - ETA: 23s - loss: 7.7662 - acc: 0.51 - ETA: 22s - loss: 7.7729 - acc: 0.51 - ETA: 22s - loss: 7.8016 - acc: 0.51 - ETA: 21s - loss: 7.8291 - acc: 0.51 - ETA: 21s - loss: 7.8126 - acc: 0.51 - ETA: 20s - loss: 7.8177 - acc: 0.51 - ETA: 20s - loss: 7.8226 - acc: 0.51 - ETA: 19s - loss: 7.7669 - acc: 0.51 - ETA: 19s - loss: 7.7825 - acc: 0.51 - ETA: 18s - loss: 7.7685 - acc: 0.51 - ETA: 18s - loss: 7.8405 - acc: 0.51 - ETA: 17s - loss: 7.8632 - acc: 0.51 - ETA: 17s - loss: 7.8576 - acc: 0.51 - ETA: 16s - loss: 7.8432 - acc: 0.51 - ETA: 16s - loss: 7.8470 - acc: 0.51 - ETA: 15s - loss: 7.8854 - acc: 0.51 - ETA: 15s - loss: 7.8883 - acc: 0.51 - ETA: 14s - loss: 7.8576 - acc: 0.51 - ETA: 14s - loss: 7.8361 - acc: 0.51 - ETA: 13s - loss: 7.8803 - acc: 0.51 - ETA: 13s - loss: 7.8912 - acc: 0.51 - ETA: 13s - loss: 7.8859 - acc: 0.51 - ETA: 12s - loss: 7.8886 - acc: 0.51 - ETA: 12s - loss: 7.8683 - acc: 0.51 - ETA: 11s - loss: 7.8561 - acc: 0.51 - ETA: 11s - loss: 7.8887 - acc: 0.51 - ETA: 10s - loss: 7.9204 - acc: 0.50 - ETA: 10s - loss: 7.9223 - acc: 0.50 - ETA: 9s - loss: 7.9243 - acc: 0.5084 - ETA: 9s - loss: 7.9331 - acc: 0.507 - ETA: 8s - loss: 7.9486 - acc: 0.506 - ETA: 8s - loss: 7.9569 - acc: 0.506 - ETA: 8s - loss: 7.9180 - acc: 0.508 - ETA: 7s - loss: 7.9066 - acc: 0.509 - ETA: 7s - loss: 7.9151 - acc: 0.508 - ETA: 6s - loss: 7.9299 - acc: 0.508 - ETA: 6s - loss: 7.9315 - acc: 0.507 - ETA: 5s - loss: 7.9268 - acc: 0.508 - ETA: 5s - loss: 7.9409 - acc: 0.507 - ETA: 4s - loss: 7.9239 - acc: 0.508 - ETA: 4s - loss: 7.9255 - acc: 0.508 - ETA: 4s - loss: 7.9391 - acc: 0.507 - ETA: 3s - loss: 7.9346 - acc: 0.507 - ETA: 3s - loss: 7.9243 - acc: 0.508 - ETA: 2s - loss: 7.8969 - acc: 0.510 - ETA: 2s - loss: 7.9217 - acc: 0.508 - ETA: 2s - loss: 7.9176 - acc: 0.508 - ETA: 1s - loss: 7.9191 - acc: 0.508 - ETA: 1s - loss: 7.9262 - acc: 0.508 - ETA: 0s - loss: 7.9386 - acc: 0.507 - ETA: 0s - loss: 7.9616 - acc: 0.506 - 42s 14ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 42s - loss: 9.0664 - acc: 0.43 - ETA: 38s - loss: 8.3109 - acc: 0.48 - ETA: 35s - loss: 8.7306 - acc: 0.45 - ETA: 34s - loss: 8.4368 - acc: 0.47 - ETA: 33s - loss: 8.9657 - acc: 0.44 - ETA: 33s - loss: 8.8146 - acc: 0.45 - ETA: 32s - loss: 8.2749 - acc: 0.48 - ETA: 32s - loss: 8.3109 - acc: 0.48 - ETA: 31s - loss: 8.1150 - acc: 0.49 - ETA: 31s - loss: 8.0087 - acc: 0.50 - ETA: 30s - loss: 8.2422 - acc: 0.48 - ETA: 30s - loss: 8.2269 - acc: 0.48 - ETA: 29s - loss: 8.2528 - acc: 0.48 - ETA: 29s - loss: 8.2389 - acc: 0.48 - ETA: 28s - loss: 8.2941 - acc: 0.48 - ETA: 28s - loss: 8.2479 - acc: 0.48 - ETA: 28s - loss: 8.0887 - acc: 0.49 - ETA: 27s - loss: 8.1150 - acc: 0.49 - ETA: 27s - loss: 8.1916 - acc: 0.49 - ETA: 26s - loss: 8.1850 - acc: 0.49 - ETA: 26s - loss: 8.1790 - acc: 0.49 - ETA: 26s - loss: 8.1735 - acc: 0.49 - ETA: 25s - loss: 8.0809 - acc: 0.49 - ETA: 25s - loss: 8.1010 - acc: 0.49 - ETA: 25s - loss: 8.0792 - acc: 0.49 - ETA: 25s - loss: 8.1947 - acc: 0.49 - ETA: 25s - loss: 8.1523 - acc: 0.49 - ETA: 25s - loss: 8.1130 - acc: 0.49 - ETA: 25s - loss: 8.0938 - acc: 0.49 - ETA: 25s - loss: 8.1094 - acc: 0.49 - ETA: 24s - loss: 8.0428 - acc: 0.50 - ETA: 24s - loss: 7.9803 - acc: 0.50 - ETA: 23s - loss: 7.9522 - acc: 0.50 - ETA: 23s - loss: 7.9850 - acc: 0.50 - ETA: 22s - loss: 7.9871 - acc: 0.50 - ETA: 22s - loss: 8.0031 - acc: 0.50 - ETA: 22s - loss: 7.9774 - acc: 0.50 - ETA: 21s - loss: 7.9928 - acc: 0.50 - ETA: 21s - loss: 7.9428 - acc: 0.50 - ETA: 20s - loss: 7.9331 - acc: 0.50 - ETA: 20s - loss: 7.9485 - acc: 0.50 - ETA: 19s - loss: 7.9511 - acc: 0.50 - ETA: 19s - loss: 7.9302 - acc: 0.50 - ETA: 19s - loss: 7.8988 - acc: 0.50 - ETA: 18s - loss: 7.8912 - acc: 0.51 - ETA: 18s - loss: 7.9058 - acc: 0.50 - ETA: 17s - loss: 7.9626 - acc: 0.50 - ETA: 17s - loss: 7.9751 - acc: 0.50 - ETA: 17s - loss: 7.9665 - acc: 0.50 - ETA: 16s - loss: 7.9482 - acc: 0.50 - ETA: 16s - loss: 7.9702 - acc: 0.50 - ETA: 15s - loss: 7.9331 - acc: 0.50 - ETA: 15s - loss: 7.8880 - acc: 0.51 - ETA: 15s - loss: 7.8725 - acc: 0.51 - ETA: 14s - loss: 7.8301 - acc: 0.51 - ETA: 14s - loss: 7.8522 - acc: 0.51 - ETA: 13s - loss: 7.8558 - acc: 0.51 - ETA: 13s - loss: 7.8419 - acc: 0.51 - ETA: 13s - loss: 7.8029 - acc: 0.51 - ETA: 12s - loss: 7.8156 - acc: 0.51 - ETA: 12s - loss: 7.8196 - acc: 0.51 - ETA: 11s - loss: 7.7828 - acc: 0.51 - ETA: 11s - loss: 7.7872 - acc: 0.51 - ETA: 11s - loss: 7.8151 - acc: 0.51 - ETA: 10s - loss: 7.8033 - acc: 0.51 - ETA: 10s - loss: 7.8530 - acc: 0.51 - ETA: 10s - loss: 7.8786 - acc: 0.51 - ETA: 9s - loss: 7.8813 - acc: 0.5110 - ETA: 9s - loss: 7.8766 - acc: 0.511 - ETA: 8s - loss: 7.8648 - acc: 0.512 - ETA: 8s - loss: 7.8675 - acc: 0.511 - ETA: 8s - loss: 7.8772 - acc: 0.511 - ETA: 7s - loss: 7.9004 - acc: 0.509 - ETA: 7s - loss: 7.9161 - acc: 0.508 - ETA: 7s - loss: 7.9180 - acc: 0.508 - ETA: 6s - loss: 7.9265 - acc: 0.508 - ETA: 6s - loss: 7.9478 - acc: 0.506 - ETA: 6s - loss: 7.9428 - acc: 0.507 - ETA: 5s - loss: 7.9570 - acc: 0.506 - ETA: 5s - loss: 7.9268 - acc: 0.508 - ETA: 4s - loss: 7.9471 - acc: 0.506 - ETA: 4s - loss: 7.9608 - acc: 0.506 - ETA: 4s - loss: 7.9437 - acc: 0.507 - ETA: 3s - loss: 7.9151 - acc: 0.508 - ETA: 3s - loss: 7.9228 - acc: 0.508 - ETA: 2s - loss: 7.9068 - acc: 0.509 - ETA: 2s - loss: 7.9317 - acc: 0.507 - ETA: 2s - loss: 7.9446 - acc: 0.507 - ETA: 1s - loss: 7.9402 - acc: 0.507 - ETA: 1s - loss: 7.9527 - acc: 0.506 - ETA: 1s - loss: 7.9373 - acc: 0.507 - ETA: 0s - loss: 7.9714 - acc: 0.505 - ETA: 0s - loss: 7.9941 - acc: 0.504 - 39s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - ETA: 35s - loss: 8.0590 - acc: 0.50 - ETA: 33s - loss: 7.3035 - acc: 0.54 - ETA: 33s - loss: 6.7159 - acc: 0.58 - ETA: 32s - loss: 7.6813 - acc: 0.52 - ETA: 32s - loss: 8.3613 - acc: 0.48 - ETA: 31s - loss: 8.5627 - acc: 0.46 - ETA: 31s - loss: 8.4188 - acc: 0.47 - ETA: 31s - loss: 8.3739 - acc: 0.48 - ETA: 30s - loss: 8.2269 - acc: 0.48 - ETA: 30s - loss: 8.0590 - acc: 0.50 - ETA: 29s - loss: 8.0590 - acc: 0.50 - ETA: 29s - loss: 8.1430 - acc: 0.49 - ETA: 29s - loss: 8.0203 - acc: 0.50 - ETA: 28s - loss: 7.9151 - acc: 0.50 - ETA: 28s - loss: 7.7904 - acc: 0.51 - ETA: 27s - loss: 7.7757 - acc: 0.51 - ETA: 27s - loss: 7.9109 - acc: 0.50 - ETA: 27s - loss: 8.0870 - acc: 0.49 - ETA: 26s - loss: 8.1386 - acc: 0.49 - ETA: 26s - loss: 8.2102 - acc: 0.49 - ETA: 26s - loss: 8.0830 - acc: 0.49 - ETA: 25s - loss: 8.0362 - acc: 0.50 - ETA: 25s - loss: 8.0371 - acc: 0.50 - ETA: 24s - loss: 8.0171 - acc: 0.50 - ETA: 24s - loss: 8.0389 - acc: 0.50 - ETA: 24s - loss: 8.0590 - acc: 0.50 - ETA: 23s - loss: 8.0404 - acc: 0.50 - ETA: 23s - loss: 8.0231 - acc: 0.50 - ETA: 23s - loss: 7.9896 - acc: 0.50 - ETA: 22s - loss: 7.9415 - acc: 0.50 - ETA: 22s - loss: 7.9941 - acc: 0.50 - ETA: 22s - loss: 7.9489 - acc: 0.50 - ETA: 21s - loss: 7.9217 - acc: 0.50 - ETA: 21s - loss: 7.9850 - acc: 0.50 - ETA: 20s - loss: 7.9727 - acc: 0.50 - ETA: 20s - loss: 7.9331 - acc: 0.50 - ETA: 20s - loss: 7.9501 - acc: 0.50 - ETA: 19s - loss: 7.9132 - acc: 0.50 - ETA: 19s - loss: 7.9428 - acc: 0.50 - ETA: 19s - loss: 7.9583 - acc: 0.50 - ETA: 18s - loss: 7.9485 - acc: 0.50 - ETA: 18s - loss: 7.9631 - acc: 0.50 - ETA: 18s - loss: 7.9302 - acc: 0.50 - ETA: 17s - loss: 7.9102 - acc: 0.50 - ETA: 17s - loss: 7.8912 - acc: 0.51 - ETA: 17s - loss: 7.9058 - acc: 0.50 - ETA: 16s - loss: 7.8876 - acc: 0.51 - ETA: 16s - loss: 7.8912 - acc: 0.51 - ETA: 16s - loss: 7.8740 - acc: 0.51 - ETA: 15s - loss: 7.9180 - acc: 0.50 - ETA: 15s - loss: 7.9603 - acc: 0.50 - ETA: 15s - loss: 7.9234 - acc: 0.50 - ETA: 14s - loss: 7.9165 - acc: 0.50 - ETA: 14s - loss: 7.8912 - acc: 0.51 - ETA: 13s - loss: 7.8850 - acc: 0.51 - ETA: 13s - loss: 7.8882 - acc: 0.51 - ETA: 13s - loss: 7.8646 - acc: 0.51 - ETA: 12s - loss: 7.9027 - acc: 0.50 - ETA: 12s - loss: 7.9225 - acc: 0.50 - ETA: 12s - loss: 7.9499 - acc: 0.50 - ETA: 11s - loss: 7.9269 - acc: 0.50 - ETA: 11s - loss: 7.9047 - acc: 0.50 - ETA: 11s - loss: 7.8991 - acc: 0.50 - ETA: 10s - loss: 7.9174 - acc: 0.50 - ETA: 10s - loss: 7.8963 - acc: 0.51 - ETA: 10s - loss: 7.8835 - acc: 0.51 - ETA: 9s - loss: 7.9162 - acc: 0.5089 - ETA: 9s - loss: 7.9331 - acc: 0.507 - ETA: 9s - loss: 7.9131 - acc: 0.509 - ETA: 8s - loss: 7.9079 - acc: 0.509 - ETA: 8s - loss: 7.9243 - acc: 0.508 - ETA: 8s - loss: 7.9261 - acc: 0.508 - ETA: 7s - loss: 7.9280 - acc: 0.508 - ETA: 7s - loss: 7.9229 - acc: 0.508 - ETA: 7s - loss: 7.9247 - acc: 0.508 - ETA: 6s - loss: 7.9132 - acc: 0.509 - ETA: 6s - loss: 7.8955 - acc: 0.510 - ETA: 6s - loss: 7.8912 - acc: 0.510 - ETA: 5s - loss: 7.8869 - acc: 0.510 - ETA: 5s - loss: 7.9142 - acc: 0.509 - ETA: 4s - loss: 7.9222 - acc: 0.508 - ETA: 4s - loss: 7.9546 - acc: 0.506 - ETA: 4s - loss: 7.9377 - acc: 0.507 - ETA: 3s - loss: 7.9331 - acc: 0.507 - ETA: 3s - loss: 7.9405 - acc: 0.507 - ETA: 3s - loss: 7.9595 - acc: 0.506 - ETA: 2s - loss: 7.9433 - acc: 0.507 - ETA: 2s - loss: 7.9217 - acc: 0.508 - ETA: 1s - loss: 7.9459 - acc: 0.507 - ETA: 1s - loss: 7.9751 - acc: 0.505 - ETA: 1s - loss: 7.9760 - acc: 0.505 - ETA: 0s - loss: 7.9824 - acc: 0.504 - ETA: 0s - loss: 7.9616 - acc: 0.506 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n"
     ]
    }
   ],
   "source": [
    "cnn1_no_drop = Sequential()\n",
    "cnn1_no_drop.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "cnn1_no_drop.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn1_no_drop.add(Flatten())\n",
    "cnn1_no_drop.add(Dense(128, activation=\"relu\"))\n",
    "cnn1_no_drop.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "cnn1_no_drop.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])\n",
    "history1_no_drop = cnn1_no_drop.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "         #batch_size=250,\n",
    "        # verbose=1,\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.300819160461426 0.485\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = cnn1_no_drop.evaluate(testX, testY, verbose=2)\n",
    "print(model_loss, model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with 3 convolutional layers\n",
    "cnn3 = Sequential()\n",
    "cnn3.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "cnn3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn3.add(Dropout(0.25))\n",
    "\n",
    "cnn3.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "cnn3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn3.add(Dropout(0.25))\n",
    "\n",
    "cnn3.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn3.add(Dropout(0.4))\n",
    "\n",
    "cnn3.add(Flatten())\n",
    "\n",
    "cnn3.add(Dense(128, activation=\"relu\"))\n",
    "cnn3.add(Dropout(0.3))\n",
    "cnn3.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "cnn3.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - ETA: 50s - loss: 7.9842 - acc: 0.45 - ETA: 37s - loss: 7.8642 - acc: 0.48 - ETA: 31s - loss: 7.9712 - acc: 0.48 - ETA: 27s - loss: 7.6468 - acc: 0.51 - ETA: 23s - loss: 7.7545 - acc: 0.50 - ETA: 19s - loss: 7.8052 - acc: 0.50 - ETA: 16s - loss: 7.7785 - acc: 0.51 - ETA: 12s - loss: 7.8529 - acc: 0.50 - ETA: 9s - loss: 7.8339 - acc: 0.5082 - ETA: 5s - loss: 7.8312 - acc: 0.509 - ETA: 2s - loss: 7.9092 - acc: 0.504 - 43s 14ms/step - loss: 7.9291 - acc: 0.5037 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 8.1850 - acc: 0.49 - ETA: 30s - loss: 7.9961 - acc: 0.50 - ETA: 26s - loss: 7.9751 - acc: 0.50 - ETA: 23s - loss: 8.0591 - acc: 0.50 - ETA: 20s - loss: 8.0842 - acc: 0.49 - ETA: 17s - loss: 8.1010 - acc: 0.49 - ETA: 14s - loss: 7.9421 - acc: 0.50 - ETA: 11s - loss: 7.9725 - acc: 0.50 - ETA: 8s - loss: 7.9751 - acc: 0.5052 - ETA: 5s - loss: 7.9079 - acc: 0.509 - ETA: 2s - loss: 7.9503 - acc: 0.506 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 7.6813 - acc: 0.52 - ETA: 29s - loss: 7.4294 - acc: 0.53 - ETA: 27s - loss: 7.8702 - acc: 0.51 - ETA: 23s - loss: 7.9016 - acc: 0.50 - ETA: 20s - loss: 8.0842 - acc: 0.49 - ETA: 17s - loss: 8.0171 - acc: 0.50 - ETA: 14s - loss: 8.0950 - acc: 0.49 - ETA: 11s - loss: 8.0669 - acc: 0.49 - ETA: 8s - loss: 8.0730 - acc: 0.4991 - ETA: 5s - loss: 8.0087 - acc: 0.503 - ETA: 2s - loss: 7.9789 - acc: 0.505 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - ETA: 32s - loss: 7.3035 - acc: 0.54 - ETA: 30s - loss: 7.8387 - acc: 0.51 - ETA: 27s - loss: 7.7652 - acc: 0.51 - ETA: 23s - loss: 7.7285 - acc: 0.52 - ETA: 20s - loss: 7.8450 - acc: 0.51 - ETA: 17s - loss: 7.8387 - acc: 0.51 - ETA: 14s - loss: 7.9151 - acc: 0.50 - ETA: 11s - loss: 7.9725 - acc: 0.50 - ETA: 8s - loss: 7.9891 - acc: 0.5043 - ETA: 5s - loss: 7.9898 - acc: 0.504 - ETA: 2s - loss: 8.0018 - acc: 0.503 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 7.6183 - acc: 0.52 - ETA: 29s - loss: 7.2720 - acc: 0.54 - ETA: 26s - loss: 7.4294 - acc: 0.53 - ETA: 23s - loss: 7.6813 - acc: 0.52 - ETA: 20s - loss: 7.8198 - acc: 0.51 - ETA: 17s - loss: 7.7967 - acc: 0.51 - ETA: 14s - loss: 7.8432 - acc: 0.51 - ETA: 11s - loss: 7.8780 - acc: 0.51 - ETA: 8s - loss: 7.9051 - acc: 0.5095 - ETA: 5s - loss: 7.9520 - acc: 0.506 - ETA: 2s - loss: 7.9617 - acc: 0.506 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 8.5627 - acc: 0.46 - ETA: 30s - loss: 7.8702 - acc: 0.51 - ETA: 27s - loss: 8.1430 - acc: 0.49 - ETA: 23s - loss: 8.0276 - acc: 0.50 - ETA: 20s - loss: 8.0465 - acc: 0.50 - ETA: 17s - loss: 8.0276 - acc: 0.50 - ETA: 14s - loss: 8.0231 - acc: 0.50 - ETA: 11s - loss: 8.0905 - acc: 0.49 - ETA: 8s - loss: 7.9821 - acc: 0.5048 - ETA: 5s - loss: 8.0150 - acc: 0.502 - ETA: 2s - loss: 7.9846 - acc: 0.504 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - ETA: 32s - loss: 7.2406 - acc: 0.55 - ETA: 30s - loss: 7.4294 - acc: 0.53 - ETA: 26s - loss: 7.8282 - acc: 0.51 - ETA: 24s - loss: 8.0276 - acc: 0.50 - ETA: 21s - loss: 8.0087 - acc: 0.50 - ETA: 17s - loss: 7.9961 - acc: 0.50 - ETA: 14s - loss: 8.0321 - acc: 0.50 - ETA: 11s - loss: 8.0591 - acc: 0.50 - ETA: 8s - loss: 8.0451 - acc: 0.5009 - ETA: 5s - loss: 7.9205 - acc: 0.508 - ETA: 2s - loss: 7.9217 - acc: 0.508 - 41s 14ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 8.1220 - acc: 0.49 - ETA: 30s - loss: 7.7757 - acc: 0.51 - ETA: 27s - loss: 7.9331 - acc: 0.50 - ETA: 24s - loss: 7.9016 - acc: 0.50 - ETA: 21s - loss: 7.8450 - acc: 0.51 - ETA: 18s - loss: 7.8597 - acc: 0.51 - ETA: 14s - loss: 7.9421 - acc: 0.50 - ETA: 11s - loss: 7.9725 - acc: 0.50 - ETA: 8s - loss: 7.9471 - acc: 0.5069 - ETA: 5s - loss: 7.9520 - acc: 0.506 - ETA: 2s - loss: 7.9732 - acc: 0.505 - 41s 14ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - ETA: 33s - loss: 8.4368 - acc: 0.47 - ETA: 30s - loss: 8.4053 - acc: 0.47 - ETA: 27s - loss: 8.0171 - acc: 0.50 - ETA: 23s - loss: 8.0591 - acc: 0.50 - ETA: 20s - loss: 7.9457 - acc: 0.50 - ETA: 17s - loss: 7.8912 - acc: 0.51 - ETA: 14s - loss: 7.8792 - acc: 0.51 - ETA: 11s - loss: 7.8938 - acc: 0.51 - ETA: 8s - loss: 7.8702 - acc: 0.5117 - ETA: 5s - loss: 7.9205 - acc: 0.508 - ETA: 2s - loss: 7.9617 - acc: 0.506 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - ETA: 32s - loss: 8.3109 - acc: 0.48 - ETA: 29s - loss: 8.4998 - acc: 0.47 - ETA: 26s - loss: 8.2899 - acc: 0.48 - ETA: 23s - loss: 8.1063 - acc: 0.49 - ETA: 20s - loss: 8.1220 - acc: 0.49 - ETA: 17s - loss: 7.9751 - acc: 0.50 - ETA: 14s - loss: 8.0051 - acc: 0.50 - ETA: 11s - loss: 7.9567 - acc: 0.50 - ETA: 8s - loss: 7.9191 - acc: 0.5087 - ETA: 5s - loss: 7.9457 - acc: 0.507 - ETA: 2s - loss: 7.9732 - acc: 0.505 - 40s 13ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n"
     ]
    }
   ],
   "source": [
    "history2 = cnn3.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "         batch_size=256,\n",
    "         verbose=1,\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.300819160461426 0.485\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = cnn3.evaluate(testX, testY, verbose=2)\n",
    "print(model_loss, model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cnn3, to_file=\"cnn3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120, 120, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 120, 120, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 120, 120, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 60, 60, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 30, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 15, 15, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 38,915,138\n",
      "Trainable params: 38,915,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# VGG-like Model Time\n",
    "conv3 = partial(layers.Conv2D,\n",
    "               kernel_size=3,\n",
    "               strides=1,\n",
    "               padding=\"same\",\n",
    "               activation=\"relu\")\n",
    "def block(in_tensor, filters, n_convs):\n",
    "    conv_block = in_tensor\n",
    "    for _ in range(n_convs):\n",
    "        conv_block = conv3(filters=filters)(conv_block)\n",
    "    return conv_block\n",
    "def _vgg(in_shape=(img_size,img_size, 3),\n",
    "        n_classes=1000,\n",
    "        opt=\"sgd\",\n",
    "        n_stages_per_blocks = [2, 2, 3, 3, 3]):\n",
    "    in_layer = layers.Input(in_shape)\n",
    "\n",
    "    block1 = block(in_layer, 64, n_stages_per_blocks[0])\n",
    "    pool1 = layers.MaxPool2D()(block1)\n",
    "    block2 = block(pool1, 128, n_stages_per_blocks[1])\n",
    "    pool2 = layers.MaxPool2D()(block2)\n",
    "    block3 = block(pool2, 256, n_stages_per_blocks[2])\n",
    "    pool3 = layers.MaxPool2D()(block3)\n",
    "    block4 = block(pool3, 512, n_stages_per_blocks[3])\n",
    "    pool4 = layers.MaxPool2D()(block4)\n",
    "    block5 = block(pool4, 512, n_stages_per_blocks[4])\n",
    "    pool5 = layers.MaxPool2D()(block5)\n",
    "    flattened = layers.GlobalAvgPool2D()(pool5)\n",
    "\n",
    "    dense1 = layers.Dense(4096, activation='relu')(flattened)\n",
    "    dense2 = layers.Dense(4096, activation='relu')(dense1)\n",
    "    preds = layers.Dense(2, activation='softmax')(dense2)\n",
    "\n",
    "    vgglike = Model(in_layer, preds)\n",
    "    vgglike.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\t              metrics=[\"accuracy\"])\n",
    "    return vgglike\n",
    "\n",
    "def vgg16(in_shape=(img_size,img_size,3), n_classes=1000, opt='sgd'):\n",
    "    return _vgg(in_shape, n_classes, opt)\n",
    "\n",
    "def vgg19(in_shape=(img_size,img_size,3), n_classes=1000, opt='sgd'):\n",
    "    return _vgg(in_shape, n_classes, opt, [2, 2, 4, 4, 4])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    vgglike = vgg19()\n",
    "    print(vgglike.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model using accuracy to measure model performance\n",
    "vgglike.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - ETA: 18:14 - loss: 0.6905 - acc: 0.65 - ETA: 15:28 - loss: 3.6193 - acc: 0.62 - ETA: 14:24 - loss: 4.9313 - acc: 0.59 - ETA: 13:49 - loss: 5.7132 - acc: 0.57 - ETA: 13:25 - loss: 5.6787 - acc: 0.58 - ETA: 13:06 - loss: 5.6557 - acc: 0.59 - ETA: 12:51 - loss: 5.8551 - acc: 0.59 - ETA: 12:36 - loss: 6.3824 - acc: 0.56 - ETA: 12:24 - loss: 6.5128 - acc: 0.56 - ETA: 12:12 - loss: 6.7178 - acc: 0.55 - ETA: 12:01 - loss: 6.7939 - acc: 0.55 - ETA: 11:50 - loss: 6.9833 - acc: 0.54 - ETA: 11:40 - loss: 7.1435 - acc: 0.53 - ETA: 11:30 - loss: 7.3169 - acc: 0.52 - ETA: 11:20 - loss: 7.4335 - acc: 0.51 - ETA: 11:10 - loss: 7.5356 - acc: 0.51 - ETA: 11:00 - loss: 7.5071 - acc: 0.51 - ETA: 10:51 - loss: 7.5098 - acc: 0.51 - ETA: 10:42 - loss: 7.5652 - acc: 0.51 - ETA: 10:33 - loss: 7.6654 - acc: 0.50 - ETA: 10:23 - loss: 7.8041 - acc: 0.50 - ETA: 10:15 - loss: 7.7241 - acc: 0.50 - ETA: 10:06 - loss: 7.7387 - acc: 0.50 - ETA: 9:57 - loss: 7.7940 - acc: 0.5039 - ETA: 9:48 - loss: 7.9053 - acc: 0.497 - ETA: 9:39 - loss: 7.9306 - acc: 0.496 - ETA: 9:30 - loss: 7.9913 - acc: 0.493 - ETA: 9:22 - loss: 7.9938 - acc: 0.493 - ETA: 9:15 - loss: 8.0481 - acc: 0.490 - ETA: 9:10 - loss: 8.0317 - acc: 0.491 - ETA: 9:03 - loss: 8.0163 - acc: 0.492 - ETA: 8:55 - loss: 8.0177 - acc: 0.493 - ETA: 8:47 - loss: 8.0952 - acc: 0.488 - ETA: 8:39 - loss: 8.1831 - acc: 0.483 - ETA: 8:31 - loss: 8.1507 - acc: 0.485 - ETA: 8:23 - loss: 8.1202 - acc: 0.487 - ETA: 8:15 - loss: 8.1186 - acc: 0.488 - ETA: 8:07 - loss: 8.0507 - acc: 0.492 - ETA: 8:00 - loss: 8.0251 - acc: 0.494 - ETA: 7:53 - loss: 8.0133 - acc: 0.495 - ETA: 7:45 - loss: 8.0022 - acc: 0.496 - ETA: 7:37 - loss: 7.9915 - acc: 0.497 - ETA: 7:29 - loss: 7.9697 - acc: 0.498 - ETA: 7:20 - loss: 7.9832 - acc: 0.497 - ETA: 7:12 - loss: 7.9625 - acc: 0.499 - ETA: 7:03 - loss: 7.9974 - acc: 0.497 - ETA: 6:54 - loss: 7.9666 - acc: 0.499 - ETA: 6:45 - loss: 7.9580 - acc: 0.500 - ETA: 6:36 - loss: 7.9703 - acc: 0.499 - ETA: 6:28 - loss: 7.9923 - acc: 0.498 - ETA: 6:19 - loss: 7.9738 - acc: 0.499 - ETA: 6:10 - loss: 7.9755 - acc: 0.499 - ETA: 6:01 - loss: 7.9865 - acc: 0.498 - ETA: 5:52 - loss: 7.9599 - acc: 0.500 - ETA: 5:43 - loss: 7.9892 - acc: 0.498 - ETA: 5:35 - loss: 7.9994 - acc: 0.498 - ETA: 5:26 - loss: 8.0270 - acc: 0.496 - ETA: 5:17 - loss: 8.0362 - acc: 0.496 - ETA: 5:08 - loss: 8.0025 - acc: 0.498 - ETA: 4:59 - loss: 7.9950 - acc: 0.499 - ETA: 4:51 - loss: 8.0126 - acc: 0.498 - ETA: 4:42 - loss: 8.0052 - acc: 0.498 - ETA: 4:33 - loss: 8.0060 - acc: 0.498 - ETA: 4:24 - loss: 8.0305 - acc: 0.497 - ETA: 4:15 - loss: 7.9999 - acc: 0.499 - ETA: 4:06 - loss: 8.0008 - acc: 0.499 - ETA: 3:57 - loss: 8.0092 - acc: 0.498 - ETA: 3:49 - loss: 7.9877 - acc: 0.500 - ETA: 3:40 - loss: 7.9888 - acc: 0.500 - ETA: 3:31 - loss: 7.9754 - acc: 0.500 - ETA: 3:22 - loss: 7.9765 - acc: 0.500 - ETA: 3:13 - loss: 7.9567 - acc: 0.502 - ETA: 3:04 - loss: 7.9650 - acc: 0.501 - ETA: 2:55 - loss: 7.9595 - acc: 0.502 - ETA: 2:46 - loss: 7.9541 - acc: 0.502 - ETA: 2:37 - loss: 7.9555 - acc: 0.502 - ETA: 2:29 - loss: 7.9699 - acc: 0.501 - ETA: 2:20 - loss: 7.9646 - acc: 0.502 - ETA: 2:11 - loss: 7.9913 - acc: 0.500 - ETA: 2:02 - loss: 7.9858 - acc: 0.500 - ETA: 1:53 - loss: 8.0303 - acc: 0.498 - ETA: 1:44 - loss: 8.0675 - acc: 0.495 - ETA: 1:35 - loss: 8.0916 - acc: 0.494 - ETA: 1:26 - loss: 8.0673 - acc: 0.495 - ETA: 1:17 - loss: 8.0494 - acc: 0.497 - ETA: 1:09 - loss: 8.0378 - acc: 0.497 - ETA: 1:00 - loss: 8.0438 - acc: 0.497 - ETA: 51s - loss: 7.9982 - acc: 0.500 - ETA: 42s - loss: 7.9649 - acc: 0.50 - ETA: 33s - loss: 7.9548 - acc: 0.50 - ETA: 24s - loss: 7.9670 - acc: 0.50 - ETA: 15s - loss: 7.9297 - acc: 0.50 - ETA: 6s - loss: 7.9365 - acc: 0.5044 - 953s 318ms/step - loss: 7.9267 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - ETA: 12:52 - loss: 9.5701 - acc: 0.40 - ETA: 12:46 - loss: 8.8146 - acc: 0.45 - ETA: 12:42 - loss: 8.7306 - acc: 0.45 - ETA: 12:35 - loss: 8.5627 - acc: 0.46 - ETA: 12:30 - loss: 8.1598 - acc: 0.49 - ETA: 12:25 - loss: 8.2269 - acc: 0.48 - ETA: 12:16 - loss: 8.4188 - acc: 0.47 - ETA: 12:08 - loss: 8.1850 - acc: 0.49 - ETA: 11:58 - loss: 8.1710 - acc: 0.49 - ETA: 11:51 - loss: 8.0087 - acc: 0.50 - ETA: 11:43 - loss: 8.0133 - acc: 0.50 - ETA: 11:34 - loss: 7.7233 - acc: 0.52 - ETA: 11:27 - loss: 7.8653 - acc: 0.51 - ETA: 11:19 - loss: 7.8792 - acc: 0.51 - ETA: 11:10 - loss: 7.7233 - acc: 0.52 - ETA: 11:02 - loss: 7.8387 - acc: 0.51 - ETA: 10:53 - loss: 7.8516 - acc: 0.51 - ETA: 10:44 - loss: 7.8912 - acc: 0.51 - ETA: 10:36 - loss: 7.8735 - acc: 0.51 - ETA: 10:28 - loss: 7.9583 - acc: 0.50 - ETA: 10:19 - loss: 7.9871 - acc: 0.50 - ETA: 10:10 - loss: 7.8988 - acc: 0.50 - ETA: 10:01 - loss: 8.0590 - acc: 0.50 - ETA: 9:53 - loss: 8.1010 - acc: 0.4974 - ETA: 9:44 - loss: 8.0792 - acc: 0.498 - ETA: 9:36 - loss: 8.0397 - acc: 0.501 - ETA: 9:27 - loss: 8.0964 - acc: 0.497 - ETA: 9:19 - loss: 8.0770 - acc: 0.498 - ETA: 9:11 - loss: 8.0069 - acc: 0.503 - ETA: 9:02 - loss: 7.9247 - acc: 0.508 - ETA: 8:54 - loss: 7.9616 - acc: 0.506 - ETA: 8:45 - loss: 7.9803 - acc: 0.504 - ETA: 8:37 - loss: 7.9827 - acc: 0.504 - ETA: 8:28 - loss: 8.0146 - acc: 0.502 - ETA: 8:20 - loss: 7.9727 - acc: 0.505 - ETA: 8:11 - loss: 7.9891 - acc: 0.504 - ETA: 8:03 - loss: 7.9774 - acc: 0.505 - ETA: 7:54 - loss: 8.0856 - acc: 0.498 - ETA: 7:45 - loss: 8.1107 - acc: 0.496 - ETA: 7:37 - loss: 8.2102 - acc: 0.490 - ETA: 7:28 - loss: 8.1328 - acc: 0.495 - ETA: 7:20 - loss: 8.1310 - acc: 0.495 - ETA: 7:12 - loss: 8.0825 - acc: 0.498 - ETA: 7:03 - loss: 8.0590 - acc: 0.500 - ETA: 6:54 - loss: 8.0702 - acc: 0.499 - ETA: 6:46 - loss: 8.0371 - acc: 0.501 - ETA: 6:37 - loss: 8.0269 - acc: 0.502 - ETA: 6:29 - loss: 8.0486 - acc: 0.500 - ETA: 6:21 - loss: 8.0488 - acc: 0.500 - ETA: 6:12 - loss: 8.0490 - acc: 0.500 - ETA: 6:04 - loss: 8.0195 - acc: 0.502 - ETA: 5:55 - loss: 7.9719 - acc: 0.505 - ETA: 5:46 - loss: 7.9450 - acc: 0.507 - ETA: 5:38 - loss: 7.9564 - acc: 0.506 - ETA: 5:29 - loss: 7.9858 - acc: 0.504 - ETA: 5:21 - loss: 7.9781 - acc: 0.505 - ETA: 5:13 - loss: 8.0149 - acc: 0.502 - ETA: 5:04 - loss: 8.0417 - acc: 0.501 - ETA: 4:56 - loss: 8.0420 - acc: 0.501 - ETA: 4:47 - loss: 8.0423 - acc: 0.501 - ETA: 4:39 - loss: 8.0425 - acc: 0.501 - ETA: 4:30 - loss: 8.0509 - acc: 0.500 - ETA: 4:22 - loss: 8.0431 - acc: 0.501 - ETA: 4:13 - loss: 8.0512 - acc: 0.500 - ETA: 4:05 - loss: 8.0203 - acc: 0.502 - ETA: 3:56 - loss: 8.0133 - acc: 0.502 - ETA: 3:48 - loss: 7.9764 - acc: 0.505 - ETA: 3:39 - loss: 7.9998 - acc: 0.503 - ETA: 3:31 - loss: 7.9860 - acc: 0.504 - ETA: 3:22 - loss: 8.0015 - acc: 0.503 - ETA: 3:13 - loss: 7.9810 - acc: 0.504 - ETA: 3:05 - loss: 7.9891 - acc: 0.504 - ETA: 2:56 - loss: 7.9831 - acc: 0.504 - ETA: 2:48 - loss: 8.0046 - acc: 0.503 - ETA: 2:39 - loss: 8.0120 - acc: 0.502 - ETA: 2:31 - loss: 8.0590 - acc: 0.500 - ETA: 2:22 - loss: 8.0852 - acc: 0.498 - ETA: 2:14 - loss: 8.0913 - acc: 0.498 - ETA: 2:05 - loss: 8.0909 - acc: 0.498 - ETA: 1:57 - loss: 8.0905 - acc: 0.498 - ETA: 1:48 - loss: 8.0901 - acc: 0.498 - ETA: 1:40 - loss: 8.0836 - acc: 0.498 - ETA: 1:31 - loss: 8.0712 - acc: 0.499 - ETA: 1:23 - loss: 8.0650 - acc: 0.499 - ETA: 1:14 - loss: 8.0413 - acc: 0.501 - ETA: 1:06 - loss: 8.0590 - acc: 0.500 - ETA: 57s - loss: 8.0475 - acc: 0.500 - ETA: 49s - loss: 8.0533 - acc: 0.50 - ETA: 40s - loss: 8.0477 - acc: 0.50 - ETA: 31s - loss: 8.0367 - acc: 0.50 - ETA: 23s - loss: 8.0314 - acc: 0.50 - ETA: 14s - loss: 8.0098 - acc: 0.50 - ETA: 6s - loss: 7.9778 - acc: 0.5050 - 920s 307ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 13:35 - loss: 9.0664 - acc: 0.43 - ETA: 13:35 - loss: 8.0590 - acc: 0.50 - ETA: 13:28 - loss: 7.8912 - acc: 0.51 - ETA: 13:20 - loss: 8.3109 - acc: 0.48 - ETA: 13:11 - loss: 7.8576 - acc: 0.51 - ETA: 13:03 - loss: 7.7233 - acc: 0.52 - ETA: 12:55 - loss: 7.7712 - acc: 0.51 - ETA: 12:49 - loss: 7.8072 - acc: 0.51 - ETA: 12:40 - loss: 7.5554 - acc: 0.53 - ETA: 12:32 - loss: 7.9583 - acc: 0.50 - ETA: 12:24 - loss: 7.7843 - acc: 0.51 - ETA: 12:15 - loss: 7.7652 - acc: 0.51 - ETA: 12:05 - loss: 7.9428 - acc: 0.50 - ETA: 11:55 - loss: 8.0231 - acc: 0.50 - ETA: 11:44 - loss: 7.9919 - acc: 0.50 - ETA: 11:34 - loss: 7.9961 - acc: 0.50 - ETA: 11:23 - loss: 8.1479 - acc: 0.49 - ETA: 11:13 - loss: 8.0870 - acc: 0.49 - ETA: 11:04 - loss: 8.0060 - acc: 0.50 - ETA: 10:54 - loss: 7.9331 - acc: 0.50 - ETA: 10:43 - loss: 7.8672 - acc: 0.51 - ETA: 10:33 - loss: 7.8530 - acc: 0.51 - ETA: 10:24 - loss: 7.8182 - acc: 0.51 - ETA: 10:14 - loss: 7.8492 - acc: 0.51 - ETA: 10:05 - loss: 7.7971 - acc: 0.51 - ETA: 9:55 - loss: 7.8266 - acc: 0.5144 - ETA: 9:45 - loss: 7.8352 - acc: 0.513 - ETA: 9:37 - loss: 7.7892 - acc: 0.516 - ETA: 9:28 - loss: 7.9027 - acc: 0.509 - ETA: 9:19 - loss: 7.8576 - acc: 0.512 - ETA: 9:10 - loss: 7.9128 - acc: 0.509 - ETA: 9:00 - loss: 7.8544 - acc: 0.512 - ETA: 8:51 - loss: 7.8148 - acc: 0.515 - ETA: 8:42 - loss: 7.7924 - acc: 0.516 - ETA: 8:33 - loss: 7.7856 - acc: 0.517 - ETA: 8:24 - loss: 7.8912 - acc: 0.510 - ETA: 8:15 - loss: 7.8821 - acc: 0.511 - ETA: 8:06 - loss: 7.9265 - acc: 0.508 - ETA: 7:57 - loss: 7.9686 - acc: 0.505 - ETA: 7:48 - loss: 7.9709 - acc: 0.505 - ETA: 7:39 - loss: 7.9731 - acc: 0.505 - ETA: 7:30 - loss: 7.9631 - acc: 0.506 - ETA: 7:21 - loss: 7.9771 - acc: 0.505 - ETA: 7:13 - loss: 8.0247 - acc: 0.502 - ETA: 7:04 - loss: 8.0255 - acc: 0.502 - ETA: 6:55 - loss: 8.0481 - acc: 0.500 - ETA: 6:46 - loss: 8.0590 - acc: 0.500 - ETA: 6:37 - loss: 8.0486 - acc: 0.500 - ETA: 6:28 - loss: 7.9871 - acc: 0.504 - ETA: 6:20 - loss: 7.9382 - acc: 0.507 - ETA: 6:11 - loss: 7.9603 - acc: 0.506 - ETA: 6:02 - loss: 7.9719 - acc: 0.505 - ETA: 5:53 - loss: 7.9545 - acc: 0.506 - ETA: 5:44 - loss: 7.9378 - acc: 0.507 - ETA: 5:36 - loss: 7.9217 - acc: 0.508 - ETA: 5:27 - loss: 7.8522 - acc: 0.512 - ETA: 5:18 - loss: 7.8293 - acc: 0.514 - ETA: 5:09 - loss: 7.7725 - acc: 0.517 - ETA: 5:00 - loss: 7.7688 - acc: 0.518 - ETA: 4:52 - loss: 7.7904 - acc: 0.516 - ETA: 4:43 - loss: 7.7948 - acc: 0.516 - ETA: 4:34 - loss: 7.7828 - acc: 0.517 - ETA: 4:26 - loss: 7.8112 - acc: 0.515 - ETA: 4:17 - loss: 7.8466 - acc: 0.513 - ETA: 4:08 - loss: 7.8343 - acc: 0.513 - ETA: 4:00 - loss: 7.8530 - acc: 0.512 - ETA: 3:51 - loss: 7.8410 - acc: 0.513 - ETA: 3:42 - loss: 7.8442 - acc: 0.513 - ETA: 3:34 - loss: 7.8620 - acc: 0.512 - ETA: 3:25 - loss: 7.8504 - acc: 0.512 - ETA: 3:16 - loss: 7.8959 - acc: 0.510 - ETA: 3:08 - loss: 7.9331 - acc: 0.507 - ETA: 2:59 - loss: 7.9486 - acc: 0.506 - ETA: 2:50 - loss: 7.9365 - acc: 0.507 - ETA: 2:42 - loss: 7.9046 - acc: 0.509 - ETA: 2:33 - loss: 7.9066 - acc: 0.509 - ETA: 2:24 - loss: 7.8824 - acc: 0.511 - ETA: 2:16 - loss: 7.8718 - acc: 0.511 - ETA: 2:07 - loss: 7.8933 - acc: 0.510 - ETA: 1:58 - loss: 7.8953 - acc: 0.510 - ETA: 1:50 - loss: 7.9036 - acc: 0.509 - ETA: 1:41 - loss: 7.8871 - acc: 0.510 - ETA: 1:32 - loss: 7.8952 - acc: 0.510 - ETA: 1:24 - loss: 7.8971 - acc: 0.510 - ETA: 1:15 - loss: 7.9168 - acc: 0.508 - ETA: 1:06 - loss: 7.9302 - acc: 0.508 - ETA: 58s - loss: 7.9027 - acc: 0.509 - ETA: 49s - loss: 7.8931 - acc: 0.51 - ETA: 40s - loss: 7.9006 - acc: 0.50 - ETA: 32s - loss: 7.9303 - acc: 0.50 - ETA: 23s - loss: 7.9539 - acc: 0.50 - ETA: 15s - loss: 7.9714 - acc: 0.50 - ETA: 6s - loss: 7.9941 - acc: 0.5040 - 928s 309ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - ETA: 13:28 - loss: 11.0812 - acc: 0.312 - ETA: 13:36 - loss: 10.5775 - acc: 0.343 - ETA: 13:31 - loss: 10.0738 - acc: 0.375 - ETA: 13:20 - loss: 9.4442 - acc: 0.414 - ETA: 13:15 - loss: 8.9657 - acc: 0.44 - ETA: 13:07 - loss: 8.8985 - acc: 0.44 - ETA: 12:56 - loss: 8.7066 - acc: 0.45 - ETA: 12:47 - loss: 8.5627 - acc: 0.46 - ETA: 12:39 - loss: 8.5627 - acc: 0.46 - ETA: 12:30 - loss: 8.4116 - acc: 0.47 - ETA: 12:21 - loss: 8.1964 - acc: 0.49 - ETA: 12:13 - loss: 8.2269 - acc: 0.48 - ETA: 12:05 - loss: 8.2528 - acc: 0.48 - ETA: 11:56 - loss: 8.2749 - acc: 0.48 - ETA: 11:46 - loss: 8.3948 - acc: 0.47 - ETA: 11:37 - loss: 8.3739 - acc: 0.48 - ETA: 11:27 - loss: 8.5331 - acc: 0.47 - ETA: 11:18 - loss: 8.5348 - acc: 0.47 - ETA: 11:10 - loss: 8.3241 - acc: 0.48 - ETA: 11:01 - loss: 8.3613 - acc: 0.48 - ETA: 10:51 - loss: 8.3709 - acc: 0.48 - ETA: 10:42 - loss: 8.4941 - acc: 0.47 - ETA: 10:32 - loss: 8.4970 - acc: 0.47 - ETA: 10:23 - loss: 8.4158 - acc: 0.47 - ETA: 10:14 - loss: 8.3814 - acc: 0.48 - ETA: 10:05 - loss: 8.3496 - acc: 0.48 - ETA: 9:56 - loss: 8.3948 - acc: 0.4792 - ETA: 9:47 - loss: 8.3828 - acc: 0.479 - ETA: 9:39 - loss: 8.3543 - acc: 0.481 - ETA: 9:30 - loss: 8.3445 - acc: 0.482 - ETA: 9:21 - loss: 8.3028 - acc: 0.484 - ETA: 9:12 - loss: 8.2794 - acc: 0.486 - ETA: 9:03 - loss: 8.3185 - acc: 0.483 - ETA: 8:54 - loss: 8.2961 - acc: 0.485 - ETA: 8:45 - loss: 8.2174 - acc: 0.490 - ETA: 8:37 - loss: 8.1710 - acc: 0.493 - ETA: 8:27 - loss: 8.1407 - acc: 0.494 - ETA: 8:18 - loss: 8.1253 - acc: 0.495 - ETA: 8:09 - loss: 8.1365 - acc: 0.495 - ETA: 8:01 - loss: 8.1094 - acc: 0.496 - ETA: 7:52 - loss: 8.0468 - acc: 0.500 - ETA: 7:43 - loss: 8.0351 - acc: 0.501 - ETA: 7:33 - loss: 8.1293 - acc: 0.495 - ETA: 7:24 - loss: 8.1506 - acc: 0.494 - ETA: 7:15 - loss: 8.1486 - acc: 0.494 - ETA: 7:06 - loss: 8.1466 - acc: 0.494 - ETA: 6:57 - loss: 8.1448 - acc: 0.494 - ETA: 6:48 - loss: 8.1430 - acc: 0.494 - ETA: 6:39 - loss: 8.1721 - acc: 0.493 - ETA: 6:31 - loss: 8.1699 - acc: 0.493 - ETA: 6:22 - loss: 8.2072 - acc: 0.490 - ETA: 6:13 - loss: 8.1947 - acc: 0.491 - ETA: 6:04 - loss: 8.1731 - acc: 0.492 - ETA: 5:55 - loss: 8.1617 - acc: 0.493 - ETA: 5:46 - loss: 8.1873 - acc: 0.492 - ETA: 5:37 - loss: 8.1580 - acc: 0.493 - ETA: 5:28 - loss: 8.1739 - acc: 0.492 - ETA: 5:19 - loss: 8.0851 - acc: 0.498 - ETA: 5:10 - loss: 8.1017 - acc: 0.497 - ETA: 5:01 - loss: 8.0842 - acc: 0.498 - ETA: 4:52 - loss: 8.1003 - acc: 0.497 - ETA: 4:43 - loss: 8.0672 - acc: 0.499 - ETA: 4:34 - loss: 8.0910 - acc: 0.498 - ETA: 4:25 - loss: 8.0669 - acc: 0.499 - ETA: 4:16 - loss: 8.0590 - acc: 0.500 - ETA: 4:07 - loss: 8.0667 - acc: 0.499 - ETA: 3:58 - loss: 8.0440 - acc: 0.500 - ETA: 3:50 - loss: 8.0590 - acc: 0.500 - ETA: 3:41 - loss: 8.0663 - acc: 0.499 - ETA: 3:32 - loss: 8.0303 - acc: 0.501 - ETA: 3:23 - loss: 8.0236 - acc: 0.502 - ETA: 3:14 - loss: 8.0101 - acc: 0.503 - ETA: 3:05 - loss: 7.9900 - acc: 0.504 - ETA: 2:56 - loss: 8.0182 - acc: 0.502 - ETA: 2:47 - loss: 8.0120 - acc: 0.502 - ETA: 2:38 - loss: 8.0259 - acc: 0.502 - ETA: 2:29 - loss: 8.0067 - acc: 0.503 - ETA: 2:20 - loss: 8.0009 - acc: 0.503 - ETA: 2:11 - loss: 8.0144 - acc: 0.502 - ETA: 2:02 - loss: 8.0150 - acc: 0.502 - ETA: 1:53 - loss: 8.0155 - acc: 0.502 - ETA: 1:44 - loss: 8.0038 - acc: 0.503 - ETA: 1:35 - loss: 7.9741 - acc: 0.505 - ETA: 1:26 - loss: 7.9931 - acc: 0.504 - ETA: 1:17 - loss: 7.9879 - acc: 0.504 - ETA: 1:09 - loss: 7.9888 - acc: 0.504 - ETA: 1:00 - loss: 7.9896 - acc: 0.504 - ETA: 51s - loss: 7.9732 - acc: 0.505 - ETA: 42s - loss: 7.9855 - acc: 0.50 - ETA: 33s - loss: 8.0031 - acc: 0.50 - ETA: 24s - loss: 7.9816 - acc: 0.50 - ETA: 15s - loss: 7.9933 - acc: 0.50 - ETA: 6s - loss: 7.9832 - acc: 0.5047 - 949s 316ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 13:01 - loss: 7.5554 - acc: 0.53 - ETA: 12:56 - loss: 7.3035 - acc: 0.54 - ETA: 12:49 - loss: 7.3875 - acc: 0.54 - ETA: 12:39 - loss: 8.0590 - acc: 0.50 - ETA: 12:31 - loss: 7.3539 - acc: 0.54 - ETA: 12:23 - loss: 7.2196 - acc: 0.55 - ETA: 12:14 - loss: 7.1956 - acc: 0.55 - ETA: 12:06 - loss: 7.3035 - acc: 0.54 - ETA: 11:56 - loss: 7.4994 - acc: 0.53 - ETA: 11:47 - loss: 7.4043 - acc: 0.54 - ETA: 11:39 - loss: 7.4180 - acc: 0.53 - ETA: 11:30 - loss: 7.5554 - acc: 0.53 - ETA: 11:22 - loss: 7.7491 - acc: 0.51 - ETA: 11:13 - loss: 7.7712 - acc: 0.51 - ETA: 11:05 - loss: 7.7904 - acc: 0.51 - ETA: 10:57 - loss: 7.9331 - acc: 0.50 - ETA: 10:48 - loss: 7.7035 - acc: 0.52 - ETA: 10:40 - loss: 7.6673 - acc: 0.52 - ETA: 10:31 - loss: 7.6349 - acc: 0.52 - ETA: 10:23 - loss: 7.6813 - acc: 0.52 - ETA: 10:15 - loss: 7.5314 - acc: 0.53 - ETA: 10:06 - loss: 7.6011 - acc: 0.52 - ETA: 9:58 - loss: 7.6430 - acc: 0.5258 - ETA: 9:49 - loss: 7.7023 - acc: 0.522 - ETA: 9:40 - loss: 7.7367 - acc: 0.520 - ETA: 9:32 - loss: 7.7491 - acc: 0.519 - ETA: 9:23 - loss: 7.7792 - acc: 0.517 - ETA: 9:15 - loss: 7.8252 - acc: 0.514 - ETA: 9:06 - loss: 7.7811 - acc: 0.517 - ETA: 8:58 - loss: 7.7736 - acc: 0.517 - ETA: 8:50 - loss: 7.8153 - acc: 0.515 - ETA: 8:41 - loss: 7.8072 - acc: 0.515 - ETA: 8:33 - loss: 7.8606 - acc: 0.512 - ETA: 8:25 - loss: 7.9850 - acc: 0.504 - ETA: 8:16 - loss: 8.0447 - acc: 0.500 - ETA: 8:08 - loss: 7.9611 - acc: 0.506 - ETA: 7:59 - loss: 7.9365 - acc: 0.507 - ETA: 7:51 - loss: 7.9000 - acc: 0.509 - ETA: 7:42 - loss: 7.9428 - acc: 0.507 - ETA: 7:34 - loss: 7.9583 - acc: 0.506 - ETA: 7:25 - loss: 7.9239 - acc: 0.508 - ETA: 7:17 - loss: 7.9391 - acc: 0.507 - ETA: 7:09 - loss: 7.9302 - acc: 0.508 - ETA: 7:00 - loss: 7.9675 - acc: 0.505 - ETA: 6:52 - loss: 8.0143 - acc: 0.502 - ETA: 6:43 - loss: 8.0371 - acc: 0.501 - ETA: 6:35 - loss: 8.0376 - acc: 0.501 - ETA: 6:26 - loss: 8.0066 - acc: 0.503 - ETA: 6:18 - loss: 7.9974 - acc: 0.503 - ETA: 6:10 - loss: 7.9785 - acc: 0.505 - ETA: 6:01 - loss: 7.9998 - acc: 0.503 - ETA: 5:53 - loss: 8.0397 - acc: 0.501 - ETA: 5:44 - loss: 8.0971 - acc: 0.497 - ETA: 5:36 - loss: 8.1243 - acc: 0.495 - ETA: 5:27 - loss: 8.1232 - acc: 0.496 - ETA: 5:19 - loss: 8.1490 - acc: 0.494 - ETA: 5:11 - loss: 8.1121 - acc: 0.496 - ETA: 5:02 - loss: 8.1198 - acc: 0.496 - ETA: 4:54 - loss: 8.1359 - acc: 0.495 - ETA: 4:45 - loss: 8.1010 - acc: 0.497 - ETA: 4:37 - loss: 8.1003 - acc: 0.497 - ETA: 4:28 - loss: 8.1159 - acc: 0.496 - ETA: 4:20 - loss: 8.1230 - acc: 0.496 - ETA: 4:11 - loss: 8.1063 - acc: 0.497 - ETA: 4:03 - loss: 8.1210 - acc: 0.496 - ETA: 3:55 - loss: 8.0972 - acc: 0.497 - ETA: 3:46 - loss: 8.0666 - acc: 0.499 - ETA: 3:38 - loss: 8.0590 - acc: 0.500 - ETA: 3:29 - loss: 8.0590 - acc: 0.500 - ETA: 3:21 - loss: 8.0375 - acc: 0.501 - ETA: 3:12 - loss: 8.0094 - acc: 0.503 - ETA: 3:04 - loss: 7.9961 - acc: 0.503 - ETA: 2:55 - loss: 7.9969 - acc: 0.503 - ETA: 2:47 - loss: 8.0114 - acc: 0.503 - ETA: 2:38 - loss: 8.0120 - acc: 0.502 - ETA: 2:30 - loss: 8.0127 - acc: 0.502 - ETA: 2:21 - loss: 8.0198 - acc: 0.502 - ETA: 2:13 - loss: 7.9880 - acc: 0.504 - ETA: 2:05 - loss: 7.9762 - acc: 0.505 - ETA: 1:56 - loss: 7.9898 - acc: 0.504 - ETA: 1:48 - loss: 8.0093 - acc: 0.503 - ETA: 1:39 - loss: 7.9976 - acc: 0.503 - ETA: 1:31 - loss: 7.9802 - acc: 0.504 - ETA: 1:22 - loss: 7.9991 - acc: 0.503 - ETA: 1:14 - loss: 7.9998 - acc: 0.503 - ETA: 1:05 - loss: 7.9771 - acc: 0.505 - ETA: 57s - loss: 7.9317 - acc: 0.507 - ETA: 48s - loss: 7.9331 - acc: 0.50 - ETA: 40s - loss: 7.9685 - acc: 0.50 - ETA: 31s - loss: 7.9583 - acc: 0.50 - ETA: 23s - loss: 7.9760 - acc: 0.50 - ETA: 14s - loss: 7.9660 - acc: 0.50 - ETA: 6s - loss: 7.9616 - acc: 0.5060 - 913s 304ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - ETA: 13:03 - loss: 8.5627 - acc: 0.46 - ETA: 12:56 - loss: 7.5554 - acc: 0.53 - ETA: 12:44 - loss: 7.3875 - acc: 0.54 - ETA: 12:38 - loss: 7.0517 - acc: 0.56 - ETA: 12:29 - loss: 7.3539 - acc: 0.54 - ETA: 12:21 - loss: 7.3875 - acc: 0.54 - ETA: 12:14 - loss: 7.1956 - acc: 0.55 - ETA: 12:05 - loss: 7.4294 - acc: 0.53 - ETA: 11:58 - loss: 7.3875 - acc: 0.54 - ETA: 11:50 - loss: 7.3035 - acc: 0.54 - ETA: 11:40 - loss: 7.2806 - acc: 0.54 - ETA: 11:32 - loss: 7.3875 - acc: 0.54 - ETA: 11:24 - loss: 7.3229 - acc: 0.54 - ETA: 11:16 - loss: 7.3755 - acc: 0.54 - ETA: 11:07 - loss: 7.4546 - acc: 0.53 - ETA: 10:59 - loss: 7.4924 - acc: 0.53 - ETA: 10:50 - loss: 7.5257 - acc: 0.53 - ETA: 10:43 - loss: 7.4994 - acc: 0.53 - ETA: 10:34 - loss: 7.4228 - acc: 0.53 - ETA: 10:26 - loss: 7.4043 - acc: 0.54 - ETA: 10:17 - loss: 7.4594 - acc: 0.53 - ETA: 10:09 - loss: 7.6469 - acc: 0.52 - ETA: 10:00 - loss: 7.7963 - acc: 0.51 - ETA: 9:52 - loss: 7.8702 - acc: 0.5117 - ETA: 9:43 - loss: 7.8777 - acc: 0.511 - ETA: 9:35 - loss: 7.8266 - acc: 0.514 - ETA: 9:26 - loss: 7.8912 - acc: 0.510 - ETA: 9:18 - loss: 7.8971 - acc: 0.510 - ETA: 9:09 - loss: 7.9375 - acc: 0.507 - ETA: 9:00 - loss: 7.9751 - acc: 0.505 - ETA: 8:52 - loss: 7.9291 - acc: 0.508 - ETA: 8:43 - loss: 7.8702 - acc: 0.511 - ETA: 8:35 - loss: 7.8454 - acc: 0.513 - ETA: 8:27 - loss: 7.8220 - acc: 0.514 - ETA: 8:18 - loss: 7.8720 - acc: 0.511 - ETA: 8:10 - loss: 7.8912 - acc: 0.510 - ETA: 8:01 - loss: 7.9774 - acc: 0.505 - ETA: 7:53 - loss: 7.9795 - acc: 0.504 - ETA: 7:44 - loss: 8.0203 - acc: 0.502 - ETA: 7:36 - loss: 8.0339 - acc: 0.501 - ETA: 7:27 - loss: 8.0713 - acc: 0.499 - ETA: 7:19 - loss: 8.0710 - acc: 0.499 - ETA: 7:10 - loss: 8.0356 - acc: 0.501 - ETA: 7:02 - loss: 8.0476 - acc: 0.500 - ETA: 6:53 - loss: 8.0814 - acc: 0.498 - ETA: 6:45 - loss: 8.0919 - acc: 0.498 - ETA: 6:36 - loss: 8.1233 - acc: 0.496 - ETA: 6:28 - loss: 8.0486 - acc: 0.500 - ETA: 6:19 - loss: 8.0385 - acc: 0.501 - ETA: 6:11 - loss: 8.0389 - acc: 0.501 - ETA: 6:02 - loss: 8.0097 - acc: 0.503 - ETA: 5:54 - loss: 8.0300 - acc: 0.501 - ETA: 5:45 - loss: 8.0020 - acc: 0.503 - ETA: 5:37 - loss: 7.9938 - acc: 0.504 - ETA: 5:29 - loss: 7.9766 - acc: 0.505 - ETA: 5:20 - loss: 8.0231 - acc: 0.502 - ETA: 5:11 - loss: 8.0060 - acc: 0.503 - ETA: 5:03 - loss: 7.9722 - acc: 0.505 - ETA: 4:54 - loss: 7.9822 - acc: 0.504 - ETA: 4:46 - loss: 7.9499 - acc: 0.506 - ETA: 4:38 - loss: 7.9187 - acc: 0.508 - ETA: 4:29 - loss: 7.9291 - acc: 0.508 - ETA: 4:21 - loss: 7.9151 - acc: 0.508 - ETA: 4:12 - loss: 7.8938 - acc: 0.510 - ETA: 4:04 - loss: 7.9118 - acc: 0.509 - ETA: 3:55 - loss: 7.8912 - acc: 0.510 - ETA: 3:47 - loss: 7.8636 - acc: 0.512 - ETA: 3:38 - loss: 7.8813 - acc: 0.511 - ETA: 3:30 - loss: 7.9350 - acc: 0.507 - ETA: 3:21 - loss: 7.9511 - acc: 0.506 - ETA: 3:13 - loss: 7.9739 - acc: 0.505 - ETA: 3:04 - loss: 7.9751 - acc: 0.505 - ETA: 2:56 - loss: 7.9762 - acc: 0.505 - ETA: 2:47 - loss: 7.9706 - acc: 0.505 - ETA: 2:39 - loss: 7.9583 - acc: 0.506 - ETA: 2:30 - loss: 7.9398 - acc: 0.507 - ETA: 2:22 - loss: 7.9675 - acc: 0.505 - ETA: 2:13 - loss: 7.9880 - acc: 0.504 - ETA: 2:05 - loss: 7.9889 - acc: 0.504 - ETA: 1:56 - loss: 8.0150 - acc: 0.502 - ETA: 1:48 - loss: 8.0404 - acc: 0.501 - ETA: 1:39 - loss: 8.0468 - acc: 0.500 - ETA: 1:31 - loss: 8.0408 - acc: 0.501 - ETA: 1:22 - loss: 8.0351 - acc: 0.501 - ETA: 1:14 - loss: 8.0413 - acc: 0.501 - ETA: 1:05 - loss: 8.0298 - acc: 0.501 - ETA: 57s - loss: 8.0069 - acc: 0.503 - ETA: 48s - loss: 8.0075 - acc: 0.50 - ETA: 40s - loss: 7.9911 - acc: 0.50 - ETA: 31s - loss: 7.9863 - acc: 0.50 - ETA: 23s - loss: 7.9926 - acc: 0.50 - ETA: 14s - loss: 7.9879 - acc: 0.50 - ETA: 6s - loss: 7.9832 - acc: 0.5047 - 913s 304ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 13:02 - loss: 6.5480 - acc: 0.59 - ETA: 12:52 - loss: 6.2961 - acc: 0.60 - ETA: 12:41 - loss: 7.3875 - acc: 0.54 - ETA: 12:33 - loss: 7.5554 - acc: 0.53 - ETA: 12:25 - loss: 8.1598 - acc: 0.49 - ETA: 12:18 - loss: 7.9751 - acc: 0.50 - ETA: 12:11 - loss: 7.6993 - acc: 0.52 - ETA: 12:04 - loss: 8.1220 - acc: 0.49 - ETA: 11:56 - loss: 8.1150 - acc: 0.49 - ETA: 11:47 - loss: 8.1094 - acc: 0.49 - ETA: 11:40 - loss: 8.0590 - acc: 0.50 - ETA: 11:31 - loss: 8.1010 - acc: 0.49 - ETA: 11:23 - loss: 8.0978 - acc: 0.49 - ETA: 11:14 - loss: 7.9871 - acc: 0.50 - ETA: 11:06 - loss: 8.0255 - acc: 0.50 - ETA: 10:57 - loss: 7.9646 - acc: 0.50 - ETA: 10:58 - loss: 7.9109 - acc: 0.50 - ETA: 10:51 - loss: 7.9471 - acc: 0.50 - ETA: 10:42 - loss: 7.8470 - acc: 0.51 - ETA: 10:33 - loss: 7.7316 - acc: 0.52 - ETA: 10:23 - loss: 7.6993 - acc: 0.52 - ETA: 10:14 - loss: 7.7156 - acc: 0.52 - ETA: 10:05 - loss: 7.6868 - acc: 0.52 - ETA: 9:56 - loss: 7.7023 - acc: 0.5221 - ETA: 9:48 - loss: 7.7770 - acc: 0.517 - ETA: 9:39 - loss: 7.8072 - acc: 0.515 - ETA: 9:29 - loss: 7.7979 - acc: 0.516 - ETA: 9:20 - loss: 7.8612 - acc: 0.512 - ETA: 9:11 - loss: 7.7811 - acc: 0.517 - ETA: 9:03 - loss: 7.7904 - acc: 0.516 - ETA: 8:54 - loss: 7.7828 - acc: 0.517 - ETA: 8:45 - loss: 7.7915 - acc: 0.516 - ETA: 8:36 - loss: 7.7538 - acc: 0.518 - ETA: 8:27 - loss: 7.7183 - acc: 0.521 - ETA: 8:19 - loss: 7.8000 - acc: 0.516 - ETA: 8:10 - loss: 7.7233 - acc: 0.520 - ETA: 8:01 - loss: 7.8140 - acc: 0.515 - ETA: 7:52 - loss: 7.7939 - acc: 0.516 - ETA: 7:44 - loss: 7.7620 - acc: 0.518 - ETA: 7:35 - loss: 7.7694 - acc: 0.518 - ETA: 7:27 - loss: 7.8133 - acc: 0.515 - ETA: 7:18 - loss: 7.8072 - acc: 0.515 - ETA: 7:09 - loss: 7.8248 - acc: 0.514 - ETA: 7:01 - loss: 7.8873 - acc: 0.510 - ETA: 6:52 - loss: 7.8912 - acc: 0.510 - ETA: 6:44 - loss: 7.8948 - acc: 0.510 - ETA: 6:35 - loss: 7.8769 - acc: 0.511 - ETA: 6:27 - loss: 7.8912 - acc: 0.510 - ETA: 6:18 - loss: 7.9460 - acc: 0.507 - ETA: 6:10 - loss: 7.9382 - acc: 0.507 - ETA: 6:01 - loss: 7.9010 - acc: 0.509 - ETA: 5:53 - loss: 7.9428 - acc: 0.507 - ETA: 5:44 - loss: 7.9830 - acc: 0.504 - ETA: 5:36 - loss: 7.9285 - acc: 0.508 - ETA: 5:27 - loss: 7.9492 - acc: 0.506 - ETA: 5:19 - loss: 7.9151 - acc: 0.508 - ETA: 5:10 - loss: 7.9000 - acc: 0.509 - ETA: 5:02 - loss: 7.9288 - acc: 0.508 - ETA: 4:53 - loss: 7.9481 - acc: 0.506 - ETA: 4:45 - loss: 7.9331 - acc: 0.507 - ETA: 4:36 - loss: 7.9104 - acc: 0.509 - ETA: 4:28 - loss: 7.9128 - acc: 0.509 - ETA: 4:19 - loss: 7.8832 - acc: 0.510 - ETA: 4:11 - loss: 7.8780 - acc: 0.511 - ETA: 4:02 - loss: 7.8576 - acc: 0.512 - ETA: 3:54 - loss: 7.8606 - acc: 0.512 - ETA: 3:45 - loss: 7.8561 - acc: 0.512 - ETA: 3:37 - loss: 7.8294 - acc: 0.514 - ETA: 3:29 - loss: 7.8401 - acc: 0.513 - ETA: 3:20 - loss: 7.8144 - acc: 0.515 - ETA: 3:12 - loss: 7.8107 - acc: 0.515 - ETA: 3:03 - loss: 7.8492 - acc: 0.513 - ETA: 2:55 - loss: 7.8452 - acc: 0.513 - ETA: 2:46 - loss: 7.8344 - acc: 0.513 - ETA: 2:38 - loss: 7.8441 - acc: 0.513 - ETA: 2:29 - loss: 7.8470 - acc: 0.513 - ETA: 2:21 - loss: 7.8563 - acc: 0.512 - ETA: 2:12 - loss: 7.8847 - acc: 0.510 - ETA: 2:04 - loss: 7.8869 - acc: 0.510 - ETA: 1:55 - loss: 7.8828 - acc: 0.510 - ETA: 1:47 - loss: 7.8787 - acc: 0.511 - ETA: 1:39 - loss: 7.8809 - acc: 0.511 - ETA: 1:30 - loss: 7.9013 - acc: 0.509 - ETA: 1:22 - loss: 7.8732 - acc: 0.511 - ETA: 1:13 - loss: 7.8813 - acc: 0.511 - ETA: 1:05 - loss: 7.8951 - acc: 0.510 - ETA: 56s - loss: 7.9085 - acc: 0.509 - ETA: 48s - loss: 7.9102 - acc: 0.50 - ETA: 40s - loss: 7.9119 - acc: 0.50 - ETA: 31s - loss: 7.9471 - acc: 0.50 - ETA: 23s - loss: 7.9539 - acc: 0.50 - ETA: 14s - loss: 7.9660 - acc: 0.50 - ETA: 6s - loss: 7.9616 - acc: 0.5060 - 907s 302ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - ETA: 12:52 - loss: 6.5480 - acc: 0.59 - ETA: 12:40 - loss: 7.0517 - acc: 0.56 - ETA: 12:34 - loss: 7.0517 - acc: 0.56 - ETA: 12:28 - loss: 6.9257 - acc: 0.57 - ETA: 12:20 - loss: 6.3465 - acc: 0.60 - ETA: 12:14 - loss: 6.3801 - acc: 0.60 - ETA: 12:06 - loss: 6.6199 - acc: 0.58 - ETA: 11:59 - loss: 6.7369 - acc: 0.58 - ETA: 11:51 - loss: 6.9957 - acc: 0.56 - ETA: 11:42 - loss: 7.0517 - acc: 0.56 - ETA: 11:33 - loss: 6.9601 - acc: 0.56 - ETA: 11:24 - loss: 7.0517 - acc: 0.56 - ETA: 11:16 - loss: 7.0129 - acc: 0.56 - ETA: 11:07 - loss: 7.3035 - acc: 0.54 - ETA: 10:59 - loss: 7.2867 - acc: 0.54 - ETA: 10:51 - loss: 7.3980 - acc: 0.54 - ETA: 10:43 - loss: 7.4368 - acc: 0.53 - ETA: 10:35 - loss: 7.4714 - acc: 0.53 - ETA: 10:27 - loss: 7.4228 - acc: 0.53 - ETA: 10:19 - loss: 7.5805 - acc: 0.52 - ETA: 10:11 - loss: 7.6513 - acc: 0.52 - ETA: 10:03 - loss: 7.6240 - acc: 0.52 - ETA: 9:56 - loss: 7.6649 - acc: 0.5245 - ETA: 9:48 - loss: 7.7862 - acc: 0.516 - ETA: 9:40 - loss: 7.7971 - acc: 0.516 - ETA: 9:32 - loss: 7.9234 - acc: 0.508 - ETA: 9:23 - loss: 7.9471 - acc: 0.506 - ETA: 9:14 - loss: 7.9691 - acc: 0.505 - ETA: 9:06 - loss: 8.0069 - acc: 0.503 - ETA: 8:57 - loss: 8.0255 - acc: 0.502 - ETA: 8:49 - loss: 8.1078 - acc: 0.497 - ETA: 8:40 - loss: 8.0748 - acc: 0.499 - ETA: 8:32 - loss: 8.0438 - acc: 0.500 - ETA: 8:23 - loss: 8.0442 - acc: 0.500 - ETA: 8:14 - loss: 7.9583 - acc: 0.506 - ETA: 8:06 - loss: 7.9471 - acc: 0.506 - ETA: 7:57 - loss: 7.8957 - acc: 0.510 - ETA: 7:49 - loss: 7.9000 - acc: 0.509 - ETA: 7:40 - loss: 7.8524 - acc: 0.512 - ETA: 7:32 - loss: 7.8576 - acc: 0.512 - ETA: 7:23 - loss: 7.9116 - acc: 0.509 - ETA: 7:15 - loss: 7.9151 - acc: 0.508 - ETA: 7:06 - loss: 7.8951 - acc: 0.510 - ETA: 6:58 - loss: 7.8988 - acc: 0.509 - ETA: 6:50 - loss: 7.9135 - acc: 0.509 - ETA: 6:41 - loss: 7.8948 - acc: 0.510 - ETA: 6:33 - loss: 7.9304 - acc: 0.508 - ETA: 6:24 - loss: 7.8702 - acc: 0.511 - ETA: 6:16 - loss: 7.8535 - acc: 0.512 - ETA: 6:07 - loss: 7.8676 - acc: 0.511 - ETA: 5:59 - loss: 7.8813 - acc: 0.511 - ETA: 5:50 - loss: 7.9041 - acc: 0.509 - ETA: 5:42 - loss: 7.9070 - acc: 0.509 - ETA: 5:34 - loss: 7.8818 - acc: 0.511 - ETA: 5:25 - loss: 7.8759 - acc: 0.511 - ETA: 5:17 - loss: 7.8702 - acc: 0.511 - ETA: 5:08 - loss: 7.9088 - acc: 0.509 - ETA: 5:00 - loss: 7.9027 - acc: 0.509 - ETA: 4:51 - loss: 7.8712 - acc: 0.511 - ETA: 4:43 - loss: 7.8576 - acc: 0.512 - ETA: 4:35 - loss: 7.8939 - acc: 0.510 - ETA: 4:26 - loss: 7.8803 - acc: 0.511 - ETA: 4:18 - loss: 7.8672 - acc: 0.511 - ETA: 4:09 - loss: 7.8702 - acc: 0.511 - ETA: 4:01 - loss: 7.8731 - acc: 0.511 - ETA: 3:53 - loss: 7.9064 - acc: 0.509 - ETA: 3:44 - loss: 7.9087 - acc: 0.509 - ETA: 3:36 - loss: 7.9035 - acc: 0.509 - ETA: 3:27 - loss: 7.8693 - acc: 0.511 - ETA: 3:19 - loss: 7.8792 - acc: 0.511 - ETA: 3:10 - loss: 7.9101 - acc: 0.509 - ETA: 3:02 - loss: 7.8981 - acc: 0.510 - ETA: 2:54 - loss: 7.9349 - acc: 0.507 - ETA: 2:45 - loss: 7.9706 - acc: 0.505 - ETA: 2:37 - loss: 7.9583 - acc: 0.506 - ETA: 2:28 - loss: 7.9398 - acc: 0.507 - ETA: 2:20 - loss: 7.9348 - acc: 0.507 - ETA: 2:12 - loss: 7.9041 - acc: 0.509 - ETA: 2:03 - loss: 7.9060 - acc: 0.509 - ETA: 1:55 - loss: 7.9142 - acc: 0.509 - ETA: 1:46 - loss: 7.9409 - acc: 0.507 - ETA: 1:38 - loss: 7.9239 - acc: 0.508 - ETA: 1:30 - loss: 7.9013 - acc: 0.509 - ETA: 1:21 - loss: 7.9211 - acc: 0.508 - ETA: 1:13 - loss: 7.9346 - acc: 0.507 - ETA: 1:05 - loss: 7.9595 - acc: 0.506 - ETA: 56s - loss: 7.9780 - acc: 0.505 - ETA: 48s - loss: 7.9961 - acc: 0.50 - ETA: 39s - loss: 8.0025 - acc: 0.50 - ETA: 31s - loss: 7.9975 - acc: 0.50 - ETA: 23s - loss: 7.9982 - acc: 0.50 - ETA: 14s - loss: 7.9824 - acc: 0.50 - ETA: 6s - loss: 7.9778 - acc: 0.5050 - 902s 301ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - ETA: 12:55 - loss: 5.0369 - acc: 0.68 - ETA: 12:41 - loss: 6.0443 - acc: 0.62 - ETA: 12:34 - loss: 7.5554 - acc: 0.53 - ETA: 12:28 - loss: 7.8072 - acc: 0.51 - ETA: 12:19 - loss: 7.5554 - acc: 0.53 - ETA: 12:11 - loss: 7.7233 - acc: 0.52 - ETA: 12:02 - loss: 7.6993 - acc: 0.52 - ETA: 11:55 - loss: 7.7442 - acc: 0.51 - ETA: 11:47 - loss: 7.6673 - acc: 0.52 - ETA: 11:40 - loss: 7.7065 - acc: 0.52 - ETA: 11:32 - loss: 7.7843 - acc: 0.51 - ETA: 11:23 - loss: 7.7652 - acc: 0.51 - ETA: 11:15 - loss: 7.7491 - acc: 0.51 - ETA: 11:06 - loss: 7.7352 - acc: 0.52 - ETA: 10:58 - loss: 7.8240 - acc: 0.51 - ETA: 10:50 - loss: 7.7757 - acc: 0.51 - ETA: 10:41 - loss: 7.7331 - acc: 0.52 - ETA: 10:33 - loss: 7.8352 - acc: 0.51 - ETA: 10:24 - loss: 7.9530 - acc: 0.50 - ETA: 10:16 - loss: 7.8828 - acc: 0.51 - ETA: 10:08 - loss: 7.8192 - acc: 0.51 - ETA: 10:00 - loss: 7.7843 - acc: 0.51 - ETA: 9:51 - loss: 7.7525 - acc: 0.5190 - ETA: 9:43 - loss: 7.8072 - acc: 0.515 - ETA: 9:34 - loss: 7.8374 - acc: 0.513 - ETA: 9:26 - loss: 7.7878 - acc: 0.516 - ETA: 9:18 - loss: 7.8538 - acc: 0.512 - ETA: 9:09 - loss: 7.8432 - acc: 0.513 - ETA: 9:01 - loss: 7.8506 - acc: 0.512 - ETA: 8:52 - loss: 7.8072 - acc: 0.515 - ETA: 8:44 - loss: 7.7828 - acc: 0.517 - ETA: 8:35 - loss: 7.8544 - acc: 0.512 - ETA: 8:27 - loss: 7.8606 - acc: 0.512 - ETA: 8:18 - loss: 7.8665 - acc: 0.511 - ETA: 8:10 - loss: 7.8576 - acc: 0.512 - ETA: 8:02 - loss: 7.7652 - acc: 0.518 - ETA: 7:53 - loss: 7.7868 - acc: 0.516 - ETA: 7:45 - loss: 7.7939 - acc: 0.516 - ETA: 7:36 - loss: 7.8007 - acc: 0.516 - ETA: 7:28 - loss: 7.8072 - acc: 0.515 - ETA: 7:20 - loss: 7.7642 - acc: 0.518 - ETA: 7:11 - loss: 7.7712 - acc: 0.517 - ETA: 7:03 - loss: 7.8248 - acc: 0.514 - ETA: 6:55 - loss: 7.8873 - acc: 0.510 - ETA: 6:46 - loss: 7.9023 - acc: 0.509 - ETA: 6:38 - loss: 7.8948 - acc: 0.510 - ETA: 6:30 - loss: 7.8554 - acc: 0.512 - ETA: 6:21 - loss: 7.8807 - acc: 0.511 - ETA: 6:13 - loss: 7.8843 - acc: 0.510 - ETA: 6:05 - loss: 7.9079 - acc: 0.509 - ETA: 5:56 - loss: 7.9307 - acc: 0.508 - ETA: 5:48 - loss: 7.9138 - acc: 0.509 - ETA: 5:40 - loss: 7.9545 - acc: 0.506 - ETA: 5:31 - loss: 7.9751 - acc: 0.505 - ETA: 5:23 - loss: 7.9858 - acc: 0.504 - ETA: 5:15 - loss: 7.9781 - acc: 0.505 - ETA: 5:06 - loss: 7.9795 - acc: 0.504 - ETA: 4:58 - loss: 8.0069 - acc: 0.503 - ETA: 4:50 - loss: 8.0164 - acc: 0.502 - ETA: 4:41 - loss: 7.9919 - acc: 0.504 - ETA: 4:33 - loss: 7.9600 - acc: 0.506 - ETA: 4:25 - loss: 7.9291 - acc: 0.508 - ETA: 4:16 - loss: 7.9791 - acc: 0.505 - ETA: 4:08 - loss: 7.9961 - acc: 0.503 - ETA: 4:00 - loss: 7.9506 - acc: 0.506 - ETA: 3:51 - loss: 7.9827 - acc: 0.504 - ETA: 3:43 - loss: 8.0215 - acc: 0.502 - ETA: 3:35 - loss: 8.0146 - acc: 0.502 - ETA: 3:26 - loss: 8.0079 - acc: 0.503 - ETA: 3:18 - loss: 8.0519 - acc: 0.500 - ETA: 3:10 - loss: 8.0803 - acc: 0.498 - ETA: 3:01 - loss: 8.0870 - acc: 0.498 - ETA: 2:53 - loss: 8.0797 - acc: 0.498 - ETA: 2:45 - loss: 8.0727 - acc: 0.499 - ETA: 2:36 - loss: 8.0456 - acc: 0.500 - ETA: 2:28 - loss: 8.0458 - acc: 0.500 - ETA: 2:19 - loss: 8.0852 - acc: 0.498 - ETA: 2:11 - loss: 8.0720 - acc: 0.499 - ETA: 2:03 - loss: 8.0846 - acc: 0.498 - ETA: 1:54 - loss: 8.0968 - acc: 0.497 - ETA: 1:46 - loss: 8.0777 - acc: 0.498 - ETA: 1:38 - loss: 8.0406 - acc: 0.501 - ETA: 1:29 - loss: 8.0469 - acc: 0.500 - ETA: 1:21 - loss: 8.0291 - acc: 0.501 - ETA: 1:13 - loss: 8.0116 - acc: 0.502 - ETA: 1:04 - loss: 8.0063 - acc: 0.503 - ETA: 56s - loss: 8.0301 - acc: 0.501 - ETA: 48s - loss: 8.0419 - acc: 0.50 - ETA: 39s - loss: 8.0364 - acc: 0.50 - ETA: 31s - loss: 8.0479 - acc: 0.50 - ETA: 22s - loss: 8.0203 - acc: 0.50 - ETA: 14s - loss: 8.0043 - acc: 0.50 - ETA: 6s - loss: 7.9995 - acc: 0.5037 - 899s 300ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - ETA: 12:45 - loss: 7.0517 - acc: 0.56 - ETA: 12:41 - loss: 6.5480 - acc: 0.59 - ETA: 12:33 - loss: 7.5554 - acc: 0.53 - ETA: 12:26 - loss: 7.4294 - acc: 0.53 - ETA: 12:20 - loss: 7.7568 - acc: 0.51 - ETA: 12:12 - loss: 7.7233 - acc: 0.52 - ETA: 12:04 - loss: 7.6273 - acc: 0.52 - ETA: 11:56 - loss: 7.6183 - acc: 0.52 - ETA: 11:49 - loss: 7.4434 - acc: 0.53 - ETA: 11:40 - loss: 7.5554 - acc: 0.53 - ETA: 11:32 - loss: 7.6469 - acc: 0.52 - ETA: 11:23 - loss: 7.6393 - acc: 0.52 - ETA: 11:14 - loss: 7.8266 - acc: 0.51 - ETA: 11:06 - loss: 7.8072 - acc: 0.51 - ETA: 10:57 - loss: 7.8912 - acc: 0.51 - ETA: 10:49 - loss: 7.8702 - acc: 0.51 - ETA: 10:41 - loss: 7.9702 - acc: 0.50 - ETA: 10:32 - loss: 8.1430 - acc: 0.49 - ETA: 10:24 - loss: 8.2446 - acc: 0.48 - ETA: 10:15 - loss: 8.1598 - acc: 0.49 - ETA: 10:07 - loss: 8.1310 - acc: 0.49 - ETA: 9:58 - loss: 8.0819 - acc: 0.4986 - ETA: 9:50 - loss: 7.9933 - acc: 0.504 - ETA: 9:41 - loss: 7.9541 - acc: 0.506 - ETA: 9:33 - loss: 7.8979 - acc: 0.510 - ETA: 9:25 - loss: 7.8459 - acc: 0.513 - ETA: 9:16 - loss: 7.8912 - acc: 0.510 - ETA: 9:08 - loss: 7.8971 - acc: 0.510 - ETA: 8:59 - loss: 7.9027 - acc: 0.509 - ETA: 8:51 - loss: 7.9247 - acc: 0.508 - ETA: 8:42 - loss: 7.9778 - acc: 0.505 - ETA: 8:34 - loss: 7.9803 - acc: 0.504 - ETA: 8:26 - loss: 7.9980 - acc: 0.503 - ETA: 8:18 - loss: 8.0146 - acc: 0.502 - ETA: 8:09 - loss: 7.9871 - acc: 0.504 - ETA: 8:01 - loss: 7.9471 - acc: 0.506 - ETA: 7:53 - loss: 7.9638 - acc: 0.505 - ETA: 7:44 - loss: 7.9000 - acc: 0.509 - ETA: 7:36 - loss: 7.9170 - acc: 0.508 - ETA: 7:27 - loss: 7.9457 - acc: 0.507 - ETA: 7:19 - loss: 7.9608 - acc: 0.506 - ETA: 7:11 - loss: 7.9751 - acc: 0.505 - ETA: 7:02 - loss: 7.9653 - acc: 0.505 - ETA: 6:54 - loss: 7.9560 - acc: 0.506 - ETA: 6:46 - loss: 7.9807 - acc: 0.504 - ETA: 6:37 - loss: 7.9386 - acc: 0.507 - ETA: 6:29 - loss: 7.9519 - acc: 0.506 - ETA: 6:21 - loss: 7.9856 - acc: 0.504 - ETA: 6:12 - loss: 7.9871 - acc: 0.504 - ETA: 6:04 - loss: 7.9986 - acc: 0.503 - ETA: 5:56 - loss: 7.9998 - acc: 0.503 - ETA: 5:47 - loss: 8.0009 - acc: 0.503 - ETA: 5:39 - loss: 8.0495 - acc: 0.500 - ETA: 5:31 - loss: 8.0497 - acc: 0.500 - ETA: 5:23 - loss: 8.0316 - acc: 0.501 - ETA: 5:14 - loss: 8.0770 - acc: 0.498 - ETA: 5:06 - loss: 8.0590 - acc: 0.500 - ETA: 4:57 - loss: 8.0677 - acc: 0.499 - ETA: 4:49 - loss: 8.0932 - acc: 0.497 - ETA: 4:41 - loss: 8.0758 - acc: 0.499 - ETA: 4:33 - loss: 8.0756 - acc: 0.499 - ETA: 4:24 - loss: 8.0509 - acc: 0.500 - ETA: 4:16 - loss: 8.0351 - acc: 0.501 - ETA: 4:08 - loss: 8.0197 - acc: 0.502 - ETA: 3:59 - loss: 8.0126 - acc: 0.502 - ETA: 3:51 - loss: 8.0209 - acc: 0.502 - ETA: 3:42 - loss: 7.9989 - acc: 0.503 - ETA: 3:34 - loss: 8.0146 - acc: 0.502 - ETA: 3:26 - loss: 7.9933 - acc: 0.504 - ETA: 3:17 - loss: 7.9943 - acc: 0.504 - ETA: 3:09 - loss: 8.0236 - acc: 0.502 - ETA: 3:01 - loss: 8.0311 - acc: 0.501 - ETA: 2:52 - loss: 8.0245 - acc: 0.502 - ETA: 2:44 - loss: 8.0250 - acc: 0.502 - ETA: 2:36 - loss: 8.0389 - acc: 0.501 - ETA: 2:27 - loss: 8.0392 - acc: 0.501 - ETA: 2:19 - loss: 8.0263 - acc: 0.502 - ETA: 2:11 - loss: 8.0526 - acc: 0.500 - ETA: 2:02 - loss: 8.0335 - acc: 0.501 - ETA: 1:54 - loss: 8.0402 - acc: 0.501 - ETA: 1:46 - loss: 8.0342 - acc: 0.501 - ETA: 1:37 - loss: 8.0160 - acc: 0.502 - ETA: 1:29 - loss: 7.9984 - acc: 0.503 - ETA: 1:21 - loss: 8.0171 - acc: 0.502 - ETA: 1:12 - loss: 8.0057 - acc: 0.503 - ETA: 1:04 - loss: 8.0415 - acc: 0.501 - ETA: 56s - loss: 8.0069 - acc: 0.503 - ETA: 47s - loss: 8.0133 - acc: 0.50 - ETA: 39s - loss: 8.0025 - acc: 0.50 - ETA: 31s - loss: 8.0087 - acc: 0.50 - ETA: 22s - loss: 7.9926 - acc: 0.50 - ETA: 14s - loss: 7.9824 - acc: 0.50 - ETA: 6s - loss: 7.9724 - acc: 0.5054 - 897s 299ms/step - loss: 7.9785 - acc: 0.5050 - val_loss: 8.3008 - val_acc: 0.4850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e290f6a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgglike.fit(trainX, trainY, validation_data=(testX, testY), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.300819160461426 0.485\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = vgglike.evaluate(testX, testY, verbose=2)\n",
    "print(model_loss, model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vgglike, to_file=\"vgglike.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
